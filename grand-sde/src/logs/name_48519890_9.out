[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 2.5
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.316142, Loss 2.955181, forward nfe 76, backward nfe 0, Train: 0.5143, Val: 0.3676, Test: 0.3645, Best time: 1.0000
Epoch: 002, Runtime 14.429969, Loss 3.412835, forward nfe 372, backward nfe 0, Train: 0.5143, Val: 0.3676, Test: 0.3645, Best time: 18.2948
Epoch: 003, Runtime 14.387014, Loss 2.492993, forward nfe 668, backward nfe 0, Train: 0.5286, Val: 0.4140, Test: 0.3929, Best time: 1.0000
Epoch: 004, Runtime 13.859361, Loss 2.526402, forward nfe 964, backward nfe 0, Train: 0.6000, Val: 0.5169, Test: 0.4863, Best time: 3.0000
Epoch: 005, Runtime 13.633476, Loss 2.345345, forward nfe 1260, backward nfe 0, Train: 0.6857, Val: 0.5632, Test: 0.5482, Best time: 5.0000
Epoch: 006, Runtime 13.229836, Loss 1.914432, forward nfe 1556, backward nfe 0, Train: 0.6857, Val: 0.5632, Test: 0.5482, Best time: 18.2948
Epoch: 007, Runtime 13.812643, Loss 2.069394, forward nfe 1852, backward nfe 0, Train: 0.6857, Val: 0.5632, Test: 0.5482, Best time: 18.2948
Epoch: 008, Runtime 13.509798, Loss 1.870137, forward nfe 2148, backward nfe 0, Train: 0.6857, Val: 0.5632, Test: 0.5482, Best time: 18.2948
Epoch: 009, Runtime 13.773010, Loss 1.753824, forward nfe 2444, backward nfe 0, Train: 0.7500, Val: 0.5860, Test: 0.5340, Best time: 6.0000
Epoch: 010, Runtime 13.094280, Loss 1.649962, forward nfe 2740, backward nfe 0, Train: 0.7714, Val: 0.6162, Test: 0.5685, Best time: 7.0000
Epoch: 011, Runtime 12.991368, Loss 1.427885, forward nfe 3036, backward nfe 0, Train: 0.8143, Val: 0.6890, Test: 0.6497, Best time: 10.0000
Epoch: 012, Runtime 13.207932, Loss 1.372039, forward nfe 3332, backward nfe 0, Train: 0.8357, Val: 0.7265, Test: 0.7025, Best time: 24.0000
Epoch: 013, Runtime 13.408468, Loss 1.264377, forward nfe 3628, backward nfe 0, Train: 0.8643, Val: 0.7434, Test: 0.7117, Best time: 6.0000
Epoch: 014, Runtime 13.368846, Loss 1.108189, forward nfe 3924, backward nfe 0, Train: 0.8643, Val: 0.7434, Test: 0.7117, Best time: 18.2948
Epoch: 015, Runtime 13.755111, Loss 1.049666, forward nfe 4220, backward nfe 0, Train: 0.8643, Val: 0.7434, Test: 0.7117, Best time: 18.2948
Epoch: 016, Runtime 14.334270, Loss 1.060587, forward nfe 4516, backward nfe 0, Train: 0.9000, Val: 0.7588, Test: 0.7574, Best time: 22.0000
Epoch: 017, Runtime 13.609174, Loss 0.884095, forward nfe 4812, backward nfe 0, Train: 0.9143, Val: 0.7765, Test: 0.7675, Best time: 22.0000
Epoch: 018, Runtime 13.929239, Loss 0.872112, forward nfe 5108, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 22.0000
Epoch: 019, Runtime 13.776608, Loss 0.885785, forward nfe 5404, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 020, Runtime 14.423817, Loss 0.746456, forward nfe 5700, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 021, Runtime 14.299508, Loss 0.703108, forward nfe 5996, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 022, Runtime 14.247733, Loss 0.835779, forward nfe 6292, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 023, Runtime 15.074132, Loss 0.758322, forward nfe 6588, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 024, Runtime 15.008632, Loss 0.684997, forward nfe 6884, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 025, Runtime 15.846180, Loss 0.641110, forward nfe 7180, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 026, Runtime 15.208343, Loss 0.581363, forward nfe 7476, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 027, Runtime 15.493699, Loss 0.643244, forward nfe 7772, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 028, Runtime 15.779387, Loss 0.705823, forward nfe 8068, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 029, Runtime 15.725347, Loss 0.771115, forward nfe 8364, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 030, Runtime 15.950963, Loss 0.652433, forward nfe 8660, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 031, Runtime 16.404197, Loss 0.664979, forward nfe 8956, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 032, Runtime 16.576054, Loss 0.645198, forward nfe 9252, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 033, Runtime 16.859364, Loss 0.565426, forward nfe 9548, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 034, Runtime 17.076871, Loss 0.642030, forward nfe 9844, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 035, Runtime 16.879029, Loss 0.659131, forward nfe 10140, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 036, Runtime 17.372320, Loss 0.652454, forward nfe 10436, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 037, Runtime 17.743844, Loss 0.644678, forward nfe 10732, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 038, Runtime 16.914613, Loss 0.770731, forward nfe 11028, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 039, Runtime 17.045535, Loss 0.685047, forward nfe 11324, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 040, Runtime 17.580850, Loss 0.562671, forward nfe 11620, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 041, Runtime 17.746436, Loss 0.674804, forward nfe 11916, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 042, Runtime 17.618817, Loss 0.446807, forward nfe 12212, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 043, Runtime 17.446669, Loss 0.637324, forward nfe 12508, backward nfe 0, Train: 0.9071, Val: 0.7824, Test: 0.7716, Best time: 18.2948
Epoch: 044, Runtime 17.640771, Loss 0.578287, forward nfe 12804, backward nfe 0, Train: 0.9071, Val: 0.7912, Test: 0.7807, Best time: 18.2948
Epoch: 045, Runtime 13.671507, Loss 0.573004, forward nfe 13100, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 41.0000
Epoch: 046, Runtime 14.079314, Loss 0.567122, forward nfe 13396, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 047, Runtime 14.239298, Loss 0.556480, forward nfe 13692, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 048, Runtime 14.181213, Loss 0.614397, forward nfe 13988, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 049, Runtime 14.142535, Loss 0.600072, forward nfe 14284, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 050, Runtime 14.025846, Loss 0.392487, forward nfe 14580, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 051, Runtime 14.191707, Loss 0.499983, forward nfe 14876, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 052, Runtime 14.184483, Loss 0.605729, forward nfe 15172, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 053, Runtime 14.898853, Loss 0.563191, forward nfe 15468, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 054, Runtime 14.963760, Loss 0.622099, forward nfe 15764, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 055, Runtime 15.118606, Loss 0.482081, forward nfe 16060, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 056, Runtime 15.050806, Loss 0.548794, forward nfe 16356, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 057, Runtime 15.139309, Loss 0.566718, forward nfe 16652, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 058, Runtime 15.579844, Loss 0.474988, forward nfe 16948, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 059, Runtime 15.839766, Loss 0.542058, forward nfe 17244, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 060, Runtime 15.699732, Loss 0.388922, forward nfe 17540, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 061, Runtime 16.079376, Loss 0.463067, forward nfe 17836, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 062, Runtime 15.719117, Loss 0.521656, forward nfe 18132, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 063, Runtime 16.059043, Loss 0.615516, forward nfe 18428, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 064, Runtime 16.170375, Loss 0.532697, forward nfe 18724, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7797, Best time: 18.2948
Epoch: 065, Runtime 16.333709, Loss 0.458065, forward nfe 19020, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 066, Runtime 13.609093, Loss 0.444377, forward nfe 19316, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 067, Runtime 13.889512, Loss 0.535052, forward nfe 19612, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 068, Runtime 14.356083, Loss 0.556014, forward nfe 19908, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 069, Runtime 14.185637, Loss 0.513081, forward nfe 20204, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 070, Runtime 14.380921, Loss 0.451800, forward nfe 20500, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 071, Runtime 14.722768, Loss 0.459153, forward nfe 20796, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 072, Runtime 14.994318, Loss 0.404654, forward nfe 21092, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 073, Runtime 14.948091, Loss 0.457097, forward nfe 21388, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 074, Runtime 15.104441, Loss 0.575882, forward nfe 21684, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 075, Runtime 14.958501, Loss 0.484160, forward nfe 21980, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 076, Runtime 15.220719, Loss 0.408822, forward nfe 22276, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 077, Runtime 15.167964, Loss 0.577704, forward nfe 22572, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 078, Runtime 15.620222, Loss 0.401751, forward nfe 22868, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 079, Runtime 16.185019, Loss 0.364315, forward nfe 23164, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 080, Runtime 15.769918, Loss 0.362317, forward nfe 23460, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 081, Runtime 16.229276, Loss 0.461126, forward nfe 23756, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 082, Runtime 16.244832, Loss 0.459399, forward nfe 24052, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 083, Runtime 16.366863, Loss 0.457038, forward nfe 24348, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 084, Runtime 16.981520, Loss 0.450054, forward nfe 24644, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 085, Runtime 16.497615, Loss 0.513446, forward nfe 24940, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 086, Runtime 16.714493, Loss 0.578565, forward nfe 25236, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 087, Runtime 16.703972, Loss 0.385304, forward nfe 25532, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 088, Runtime 16.676312, Loss 0.496689, forward nfe 25828, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 089, Runtime 16.698868, Loss 0.395516, forward nfe 26124, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 090, Runtime 17.280986, Loss 0.365379, forward nfe 26420, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 091, Runtime 16.764132, Loss 0.359145, forward nfe 26716, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 092, Runtime 16.397781, Loss 0.488623, forward nfe 27012, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 093, Runtime 16.942295, Loss 0.388592, forward nfe 27308, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 094, Runtime 16.732738, Loss 0.512442, forward nfe 27604, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 095, Runtime 16.563105, Loss 0.413511, forward nfe 27900, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 096, Runtime 17.017424, Loss 0.431369, forward nfe 28196, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 097, Runtime 16.967273, Loss 0.321754, forward nfe 28492, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 098, Runtime 17.059645, Loss 0.370969, forward nfe 28788, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
Epoch: 099, Runtime 17.307624, Loss 0.315229, forward nfe 29084, backward nfe 0, Train: 0.9357, Val: 0.8022, Test: 0.7756, Best time: 18.2948
best val accuracy 0.802206 with test accuracy 0.775635 at epoch 65 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.7888324873096447
Entropy Threshold: 2 Test accuracy: 0.7888324873096447
Entropy Threshold: 1.6 Test accuracy: 0.7873855544252288
Entropy Threshold: 1.5 Test accuracy: 0.7930327868852459
Entropy Threshold: 1.4 Test accuracy: 0.8010309278350516
Entropy Threshold: 1.3 Test accuracy: 0.8041884816753927
Entropy Threshold: 1.2 Test accuracy: 0.8191489361702128
Entropy Threshold: 1.1 Test accuracy: 0.8144104803493449
Entropy Threshold: 0.9 Test accuracy: 0.839766081871345
Entropy Threshold: 0.8 Test accuracy: 0.8546583850931677
Entropy Threshold: 0.7 Test accuracy: 0.8697916666666666
Entropy Threshold: 0.6 Test accuracy: 0.8896457765667575
Entropy Threshold: 0.5 Test accuracy: 0.9077380952380952
Entropy Threshold: 0.4 Test accuracy: 0.9205607476635514
Entropy Threshold: 0.3 Test accuracy: 0.9282051282051282
Entropy Threshold: 0.2 Test accuracy: 0.9416195856873822
Entropy Threshold: 0.1 Test accuracy: 0.9407894736842105
