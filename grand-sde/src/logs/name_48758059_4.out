[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 7.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 11.364916, Loss 5.912804, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.1434, Test: 0.1695, Best time: 1.0000
Epoch: 002, Runtime 11.062613, Loss 5.723578, forward nfe 372, backward nfe 0, Train: 0.5500, Val: 0.3875, Test: 0.4020, Best time: 1.0000
Epoch: 003, Runtime 10.596498, Loss 4.793647, forward nfe 668, backward nfe 0, Train: 0.5786, Val: 0.5632, Test: 0.5949, Best time: 15.0000
Epoch: 004, Runtime 10.741480, Loss 4.279282, forward nfe 964, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 49.0000
Epoch: 005, Runtime 10.483045, Loss 3.792522, forward nfe 1260, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 18.2948
Epoch: 006, Runtime 11.133538, Loss 3.369777, forward nfe 1556, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 18.2948
Epoch: 007, Runtime 11.188878, Loss 3.396037, forward nfe 1852, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 18.2948
Epoch: 008, Runtime 11.288402, Loss 3.025919, forward nfe 2148, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 18.2948
Epoch: 009, Runtime 11.242613, Loss 2.949850, forward nfe 2444, backward nfe 0, Train: 0.6429, Val: 0.6213, Test: 0.6152, Best time: 18.2948
Epoch: 010, Runtime 11.334145, Loss 2.345261, forward nfe 2740, backward nfe 0, Train: 0.7929, Val: 0.6515, Test: 0.6457, Best time: 21.0000
Epoch: 011, Runtime 10.921685, Loss 2.433017, forward nfe 3036, backward nfe 0, Train: 0.8214, Val: 0.7029, Test: 0.6934, Best time: 25.0000
Epoch: 012, Runtime 11.102623, Loss 2.186723, forward nfe 3332, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 16.0000
Epoch: 013, Runtime 11.304385, Loss 2.306796, forward nfe 3628, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 014, Runtime 11.295253, Loss 1.988983, forward nfe 3924, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 015, Runtime 10.946990, Loss 2.096526, forward nfe 4220, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 016, Runtime 11.265058, Loss 2.001773, forward nfe 4516, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 017, Runtime 11.162852, Loss 1.962024, forward nfe 4812, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 018, Runtime 11.576469, Loss 1.829644, forward nfe 5108, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 019, Runtime 11.756238, Loss 1.926027, forward nfe 5404, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 020, Runtime 12.101334, Loss 1.784931, forward nfe 5700, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 021, Runtime 12.332829, Loss 2.002291, forward nfe 5996, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 022, Runtime 12.049486, Loss 1.983230, forward nfe 6292, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 023, Runtime 12.253922, Loss 1.781674, forward nfe 6588, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 024, Runtime 12.537385, Loss 1.708222, forward nfe 6884, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 025, Runtime 12.713430, Loss 1.755488, forward nfe 7180, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 026, Runtime 13.411214, Loss 1.631166, forward nfe 7476, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 027, Runtime 13.608206, Loss 1.515787, forward nfe 7772, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 028, Runtime 13.595111, Loss 1.619850, forward nfe 8068, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 029, Runtime 13.743443, Loss 1.583758, forward nfe 8364, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 030, Runtime 14.326982, Loss 1.462260, forward nfe 8660, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 031, Runtime 14.404282, Loss 1.591924, forward nfe 8956, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 032, Runtime 14.630082, Loss 1.528522, forward nfe 9252, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 033, Runtime 14.908641, Loss 1.372948, forward nfe 9548, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 034, Runtime 14.916916, Loss 1.422770, forward nfe 9844, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 035, Runtime 15.175364, Loss 1.429509, forward nfe 10140, backward nfe 0, Train: 0.8286, Val: 0.7294, Test: 0.7299, Best time: 18.2948
Epoch: 036, Runtime 15.378172, Loss 1.386510, forward nfe 10436, backward nfe 0, Train: 0.8786, Val: 0.7566, Test: 0.7543, Best time: 6.0000
Epoch: 037, Runtime 11.575649, Loss 1.335589, forward nfe 10732, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 7.0000
Epoch: 038, Runtime 11.729490, Loss 1.235276, forward nfe 11028, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 18.2948
Epoch: 039, Runtime 11.905345, Loss 1.462059, forward nfe 11324, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 18.2948
Epoch: 040, Runtime 12.127562, Loss 1.391244, forward nfe 11620, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 18.2948
Epoch: 041, Runtime 12.400414, Loss 1.149762, forward nfe 11916, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 18.2948
Epoch: 042, Runtime 11.967253, Loss 1.524242, forward nfe 12212, backward nfe 0, Train: 0.9071, Val: 0.7640, Test: 0.7706, Best time: 18.2948
Epoch: 043, Runtime 12.172230, Loss 1.303651, forward nfe 12508, backward nfe 0, Train: 0.8929, Val: 0.7684, Test: 0.7563, Best time: 7.0000
Epoch: 044, Runtime 11.092957, Loss 1.424461, forward nfe 12804, backward nfe 0, Train: 0.9071, Val: 0.7816, Test: 0.7675, Best time: 9.0000
Epoch: 045, Runtime 11.072998, Loss 1.324712, forward nfe 13100, backward nfe 0, Train: 0.8857, Val: 0.7904, Test: 0.7624, Best time: 10.0000
Epoch: 046, Runtime 11.214452, Loss 1.081739, forward nfe 13396, backward nfe 0, Train: 0.8929, Val: 0.8051, Test: 0.7848, Best time: 14.0000
Epoch: 047, Runtime 11.238535, Loss 1.259132, forward nfe 13692, backward nfe 0, Train: 0.8929, Val: 0.8169, Test: 0.8041, Best time: 35.0000
Epoch: 048, Runtime 11.727831, Loss 1.262291, forward nfe 13988, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 24.0000
Epoch: 049, Runtime 11.078112, Loss 0.997069, forward nfe 14284, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 050, Runtime 11.184272, Loss 1.015609, forward nfe 14580, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 051, Runtime 11.443157, Loss 1.255494, forward nfe 14876, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 052, Runtime 11.577137, Loss 1.172297, forward nfe 15172, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 053, Runtime 11.770657, Loss 1.168759, forward nfe 15468, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 054, Runtime 12.347306, Loss 1.158226, forward nfe 15764, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 055, Runtime 12.470820, Loss 0.940046, forward nfe 16060, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 056, Runtime 12.669414, Loss 1.064982, forward nfe 16356, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 057, Runtime 12.933917, Loss 1.101039, forward nfe 16652, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 058, Runtime 13.019310, Loss 1.116281, forward nfe 16948, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 059, Runtime 13.304835, Loss 1.098371, forward nfe 17244, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 060, Runtime 13.376116, Loss 1.126794, forward nfe 17540, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 061, Runtime 13.619848, Loss 0.880819, forward nfe 17836, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 062, Runtime 13.737462, Loss 0.874790, forward nfe 18132, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 063, Runtime 14.242423, Loss 0.870896, forward nfe 18428, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 064, Runtime 14.359324, Loss 0.894919, forward nfe 18724, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 065, Runtime 14.526727, Loss 1.115906, forward nfe 19020, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 066, Runtime 15.440215, Loss 1.074868, forward nfe 19316, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8081, Best time: 18.2948
Epoch: 067, Runtime 15.092148, Loss 0.845141, forward nfe 19612, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 39.0000
Epoch: 068, Runtime 11.206760, Loss 0.994379, forward nfe 19908, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 069, Runtime 11.450390, Loss 0.783616, forward nfe 20204, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 070, Runtime 11.664717, Loss 0.856638, forward nfe 20500, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 071, Runtime 11.930831, Loss 0.796692, forward nfe 20796, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 072, Runtime 12.209548, Loss 0.904515, forward nfe 21092, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 073, Runtime 12.474882, Loss 0.889783, forward nfe 21388, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 074, Runtime 12.442897, Loss 0.897383, forward nfe 21684, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 075, Runtime 12.709540, Loss 0.916293, forward nfe 21980, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 076, Runtime 12.824392, Loss 0.881148, forward nfe 22276, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 077, Runtime 13.113548, Loss 0.985051, forward nfe 22572, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 078, Runtime 13.214436, Loss 0.974590, forward nfe 22868, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 079, Runtime 13.466353, Loss 0.751949, forward nfe 23164, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 080, Runtime 13.878467, Loss 0.773481, forward nfe 23460, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 081, Runtime 14.284450, Loss 0.855614, forward nfe 23756, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 082, Runtime 14.205108, Loss 0.806554, forward nfe 24052, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 083, Runtime 14.522288, Loss 0.781852, forward nfe 24348, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 084, Runtime 14.522810, Loss 0.689444, forward nfe 24644, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 085, Runtime 14.836992, Loss 0.836584, forward nfe 24940, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 086, Runtime 14.693080, Loss 0.711439, forward nfe 25236, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 087, Runtime 14.809871, Loss 0.788205, forward nfe 25532, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 088, Runtime 15.160438, Loss 0.979161, forward nfe 25828, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 089, Runtime 15.827489, Loss 0.731102, forward nfe 26124, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 090, Runtime 15.531313, Loss 0.702231, forward nfe 26420, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 091, Runtime 15.610617, Loss 0.679697, forward nfe 26716, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 092, Runtime 15.554093, Loss 0.672895, forward nfe 27012, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 093, Runtime 15.815159, Loss 0.848757, forward nfe 27308, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 094, Runtime 15.358030, Loss 0.842666, forward nfe 27604, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 095, Runtime 15.483877, Loss 0.694612, forward nfe 27900, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 096, Runtime 15.632001, Loss 0.833498, forward nfe 28196, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 097, Runtime 15.937112, Loss 0.817024, forward nfe 28492, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 098, Runtime 15.997834, Loss 0.671998, forward nfe 28788, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
Epoch: 099, Runtime 16.128486, Loss 0.766135, forward nfe 29084, backward nfe 0, Train: 0.9000, Val: 0.8301, Test: 0.8122, Best time: 18.2948
best val accuracy 0.830147 with test accuracy 0.812183 at epoch 67 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8294416243654822
Entropy Threshold: 2 Test accuracy: 0.8203045685279188
Entropy Threshold: 1.6 Test accuracy: 0.8313891834570519
Entropy Threshold: 1.5 Test accuracy: 0.8324324324324325
Entropy Threshold: 1.4 Test accuracy: 0.8489932885906041
Entropy Threshold: 1.3 Test accuracy: 0.8640661938534279
Entropy Threshold: 1.2 Test accuracy: 0.8776529338327091
Entropy Threshold: 1.1 Test accuracy: 0.8793565683646113
Entropy Threshold: 0.9 Test accuracy: 0.9191290824261276
Entropy Threshold: 0.8 Test accuracy: 0.9253731343283582
Entropy Threshold: 0.7 Test accuracy: 0.9412844036697248
Entropy Threshold: 0.6 Test accuracy: 0.9539078156312625
Entropy Threshold: 0.5 Test accuracy: 0.9550321199143469
Entropy Threshold: 0.4 Test accuracy: 0.9556650246305419
Entropy Threshold: 0.3 Test accuracy: 0.9754768392370572
Entropy Threshold: 0.2 Test accuracy: 0.9672131147540983
Entropy Threshold: 0.1 Test accuracy: 0.9768339768339769
