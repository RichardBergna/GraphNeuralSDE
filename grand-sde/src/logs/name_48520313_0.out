[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 12.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 62.807772, Loss 26.390741, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.1382, Test: 0.1411, Best time: 40.0000
Epoch: 002, Runtime 101.713785, Loss 189.640305, forward nfe 372, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 1.0000
Epoch: 003, Runtime 29.817973, Loss 5.553296, forward nfe 668, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 004, Runtime 29.419462, Loss 4.589594, forward nfe 964, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 005, Runtime 31.357435, Loss 4.444434, forward nfe 1260, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 006, Runtime 32.754734, Loss 4.484423, forward nfe 1556, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 007, Runtime 34.407561, Loss 4.070983, forward nfe 1852, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 008, Runtime 35.145457, Loss 4.380352, forward nfe 2148, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 009, Runtime 37.359008, Loss 4.404786, forward nfe 2444, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 010, Runtime 38.035890, Loss 4.459027, forward nfe 2740, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 011, Runtime 38.663066, Loss 4.364363, forward nfe 3036, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 012, Runtime 39.686694, Loss 4.431493, forward nfe 3332, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 013, Runtime 39.615124, Loss 4.074614, forward nfe 3628, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 014, Runtime 41.367195, Loss 3.935503, forward nfe 3924, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 015, Runtime 41.542027, Loss 4.110903, forward nfe 4220, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 016, Runtime 37.927202, Loss 3.938249, forward nfe 4516, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 017, Runtime 29.127543, Loss 3.336672, forward nfe 4812, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 018, Runtime 30.505563, Loss 3.513872, forward nfe 5108, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 019, Runtime 31.844651, Loss 3.490198, forward nfe 5404, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 020, Runtime 33.613874, Loss 3.094611, forward nfe 5700, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 021, Runtime 34.644741, Loss 3.588263, forward nfe 5996, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 022, Runtime 36.601926, Loss 3.522272, forward nfe 6292, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 023, Runtime 37.492989, Loss 3.588222, forward nfe 6588, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 024, Runtime 37.523638, Loss 3.493872, forward nfe 6884, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 025, Runtime 37.901578, Loss 3.325568, forward nfe 7180, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 026, Runtime 38.437246, Loss 3.621997, forward nfe 7476, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 027, Runtime 39.247356, Loss 3.570860, forward nfe 7772, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 028, Runtime 40.569682, Loss 3.314722, forward nfe 8068, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 029, Runtime 40.707613, Loss 3.914026, forward nfe 8364, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 030, Runtime 41.502122, Loss 3.497926, forward nfe 8660, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 031, Runtime 28.926841, Loss 3.335947, forward nfe 8956, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 032, Runtime 28.303853, Loss 3.613926, forward nfe 9252, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 033, Runtime 29.505412, Loss 3.674442, forward nfe 9548, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 034, Runtime 30.635324, Loss 3.790600, forward nfe 9844, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 035, Runtime 31.941229, Loss 3.138852, forward nfe 10140, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 036, Runtime 33.495917, Loss 3.382971, forward nfe 10436, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 037, Runtime 34.205482, Loss 3.413440, forward nfe 10732, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 038, Runtime 35.116792, Loss 3.223530, forward nfe 11028, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 039, Runtime 36.301390, Loss 3.554999, forward nfe 11324, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 040, Runtime 37.875905, Loss 3.302029, forward nfe 11620, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 041, Runtime 38.491356, Loss 3.225808, forward nfe 11916, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 042, Runtime 31.593819, Loss 3.779993, forward nfe 12212, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 043, Runtime 27.823504, Loss 3.184129, forward nfe 12508, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 044, Runtime 28.843483, Loss 3.293617, forward nfe 12804, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 045, Runtime 30.372517, Loss 3.601927, forward nfe 13100, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 046, Runtime 31.755181, Loss 3.172243, forward nfe 13396, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 047, Runtime 33.123227, Loss 3.427857, forward nfe 13692, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 048, Runtime 34.032786, Loss 3.194460, forward nfe 13988, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 049, Runtime 34.450248, Loss 3.509559, forward nfe 14284, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 050, Runtime 34.578052, Loss 3.697437, forward nfe 14580, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 051, Runtime 35.979427, Loss 3.521743, forward nfe 14876, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 052, Runtime 37.138738, Loss 3.444566, forward nfe 15172, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 053, Runtime 38.084913, Loss 3.544128, forward nfe 15468, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 054, Runtime 38.249719, Loss 3.331424, forward nfe 15764, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 055, Runtime 38.199736, Loss 3.155860, forward nfe 16060, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 056, Runtime 38.380812, Loss 3.557260, forward nfe 16356, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 057, Runtime 38.898351, Loss 3.286333, forward nfe 16652, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 058, Runtime 38.967306, Loss 3.556693, forward nfe 16948, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 059, Runtime 38.488302, Loss 3.089838, forward nfe 17244, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 060, Runtime 40.760118, Loss 3.244749, forward nfe 17540, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 061, Runtime 36.175686, Loss 3.056526, forward nfe 17836, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 062, Runtime 27.014065, Loss 3.658397, forward nfe 18132, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 063, Runtime 27.890296, Loss 3.349305, forward nfe 18428, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 064, Runtime 29.279690, Loss 3.299540, forward nfe 18724, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 065, Runtime 29.052289, Loss 3.138482, forward nfe 19020, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 066, Runtime 29.303022, Loss 3.366441, forward nfe 19316, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 067, Runtime 29.726310, Loss 3.160959, forward nfe 19612, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 068, Runtime 31.325510, Loss 3.149476, forward nfe 19908, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 069, Runtime 33.207139, Loss 3.431758, forward nfe 20204, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 070, Runtime 34.630385, Loss 3.103226, forward nfe 20500, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 071, Runtime 34.870203, Loss 2.985287, forward nfe 20796, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 072, Runtime 35.866779, Loss 3.192872, forward nfe 21092, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 073, Runtime 35.804308, Loss 3.375804, forward nfe 21388, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 074, Runtime 37.613533, Loss 3.391867, forward nfe 21684, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 075, Runtime 37.404401, Loss 3.211744, forward nfe 21980, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 076, Runtime 37.808353, Loss 3.456105, forward nfe 22276, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 077, Runtime 37.452917, Loss 3.405659, forward nfe 22572, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 078, Runtime 36.618278, Loss 3.315040, forward nfe 22868, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 079, Runtime 37.226303, Loss 3.298255, forward nfe 23164, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 080, Runtime 37.683967, Loss 3.037068, forward nfe 23460, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 081, Runtime 37.598627, Loss 3.275595, forward nfe 23756, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 082, Runtime 33.615917, Loss 3.118252, forward nfe 24052, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 083, Runtime 25.150158, Loss 3.249235, forward nfe 24348, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 084, Runtime 26.034273, Loss 2.899948, forward nfe 24644, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 085, Runtime 27.290766, Loss 3.569184, forward nfe 24940, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 086, Runtime 28.639393, Loss 3.260678, forward nfe 25236, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 087, Runtime 29.813392, Loss 3.555224, forward nfe 25532, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 088, Runtime 30.208552, Loss 3.272618, forward nfe 25828, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 089, Runtime 29.993409, Loss 3.129948, forward nfe 26124, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 090, Runtime 31.114757, Loss 2.979957, forward nfe 26420, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 091, Runtime 31.960559, Loss 3.345572, forward nfe 26716, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 092, Runtime 32.796802, Loss 3.467738, forward nfe 27012, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 093, Runtime 33.226548, Loss 3.363898, forward nfe 27308, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 094, Runtime 34.099226, Loss 3.249751, forward nfe 27604, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 095, Runtime 35.118109, Loss 3.282654, forward nfe 27900, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 096, Runtime 35.554834, Loss 3.053645, forward nfe 28196, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 097, Runtime 36.047504, Loss 3.268370, forward nfe 28492, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 098, Runtime 36.340869, Loss 3.035926, forward nfe 28788, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
Epoch: 099, Runtime 36.706739, Loss 3.109589, forward nfe 29084, backward nfe 0, Train: 0.1071, Val: 0.2353, Test: 0.2497, Best time: 18.2948
best val accuracy 0.235294 with test accuracy 0.249746 at epoch 2 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.2984771573604061
Entropy Threshold: 2 Test accuracy: 0.2984771573604061
Entropy Threshold: 1.6 Test accuracy: 0.29746192893401013
Entropy Threshold: 1.5 Test accuracy: 0.29878048780487804
Entropy Threshold: 1.4 Test accuracy: 0.3
Entropy Threshold: 1.3 Test accuracy: 0.3004338394793926
Entropy Threshold: 1.2 Test accuracy: 0.2986857825567503
Entropy Threshold: 1.1 Test accuracy: 0.2804532577903683
Entropy Threshold: 0.9 Test accuracy: 0.29508196721311475
Entropy Threshold: 0.8 Test accuracy: 0.33879781420765026
Entropy Threshold: 0.7 Test accuracy: 0.34408602150537637
Entropy Threshold: 0.6 Test accuracy: 0.3055555555555556
Entropy Threshold: 0.5 Test accuracy: 0.3888888888888889
Entropy Threshold: 0.4 Test accuracy: 0.5
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
