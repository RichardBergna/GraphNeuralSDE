[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 8.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 33.343605, Loss 6.322763, forward nfe 76, backward nfe 0, Train: 0.1357, Val: 0.1500, Test: 0.1655, Best time: 39.0000
Epoch: 002, Runtime 91.553760, Loss 73.002365, forward nfe 372, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 003, Runtime 21.504394, Loss 4.135876, forward nfe 668, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 004, Runtime 22.174344, Loss 4.269722, forward nfe 964, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 005, Runtime 23.291054, Loss 4.407168, forward nfe 1260, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 006, Runtime 24.179697, Loss 4.389468, forward nfe 1556, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 007, Runtime 25.257282, Loss 4.712467, forward nfe 1852, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 008, Runtime 28.570567, Loss 4.287333, forward nfe 2148, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 009, Runtime 30.246429, Loss 4.046419, forward nfe 2444, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 010, Runtime 31.900470, Loss 4.217782, forward nfe 2740, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 011, Runtime 33.318064, Loss 3.984053, forward nfe 3036, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 012, Runtime 34.958955, Loss 4.068297, forward nfe 3332, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 013, Runtime 36.165221, Loss 3.661177, forward nfe 3628, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 014, Runtime 37.017733, Loss 3.714413, forward nfe 3924, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 015, Runtime 37.526341, Loss 3.695889, forward nfe 4220, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 016, Runtime 39.934161, Loss 3.305538, forward nfe 4516, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 017, Runtime 40.511730, Loss 3.132621, forward nfe 4812, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 018, Runtime 41.898413, Loss 3.001479, forward nfe 5108, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 019, Runtime 36.269394, Loss 3.084031, forward nfe 5404, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 020, Runtime 28.081634, Loss 3.140151, forward nfe 5700, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 021, Runtime 30.189944, Loss 3.176638, forward nfe 5996, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 022, Runtime 31.485430, Loss 3.141516, forward nfe 6292, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 023, Runtime 32.359824, Loss 3.165023, forward nfe 6588, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 024, Runtime 33.505066, Loss 3.208694, forward nfe 6884, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 025, Runtime 34.788942, Loss 3.194126, forward nfe 7180, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 026, Runtime 35.841277, Loss 3.116589, forward nfe 7476, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 027, Runtime 37.170057, Loss 3.176512, forward nfe 7772, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 028, Runtime 37.353502, Loss 3.209557, forward nfe 8068, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 029, Runtime 38.298908, Loss 3.191518, forward nfe 8364, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 030, Runtime 38.879555, Loss 2.874502, forward nfe 8660, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 031, Runtime 39.617904, Loss 2.774807, forward nfe 8956, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 032, Runtime 39.666175, Loss 3.121722, forward nfe 9252, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 033, Runtime 38.810429, Loss 3.061446, forward nfe 9548, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 034, Runtime 40.115442, Loss 3.042465, forward nfe 9844, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 035, Runtime 39.645588, Loss 3.067213, forward nfe 10140, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 036, Runtime 30.854670, Loss 3.053712, forward nfe 10436, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 037, Runtime 26.185029, Loss 2.894190, forward nfe 10732, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 038, Runtime 26.669649, Loss 2.836486, forward nfe 11028, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 039, Runtime 27.762048, Loss 2.880194, forward nfe 11324, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 040, Runtime 28.556777, Loss 2.661081, forward nfe 11620, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 041, Runtime 29.195664, Loss 3.072339, forward nfe 11916, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 042, Runtime 30.104385, Loss 2.903206, forward nfe 12212, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 043, Runtime 31.161110, Loss 2.874788, forward nfe 12508, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 044, Runtime 31.603425, Loss 3.021409, forward nfe 12804, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 045, Runtime 32.376944, Loss 2.849433, forward nfe 13100, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 046, Runtime 33.189534, Loss 3.072156, forward nfe 13396, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 047, Runtime 33.581082, Loss 2.726868, forward nfe 13692, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 048, Runtime 33.755653, Loss 2.990536, forward nfe 13988, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 049, Runtime 33.821782, Loss 2.866643, forward nfe 14284, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 050, Runtime 33.969423, Loss 3.093062, forward nfe 14580, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 051, Runtime 34.660121, Loss 2.925679, forward nfe 14876, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 052, Runtime 34.602238, Loss 2.801453, forward nfe 15172, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 053, Runtime 34.710083, Loss 2.958794, forward nfe 15468, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 054, Runtime 35.481443, Loss 2.842691, forward nfe 15764, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 055, Runtime 31.077172, Loss 2.843340, forward nfe 16060, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 056, Runtime 23.131659, Loss 2.954581, forward nfe 16356, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 057, Runtime 24.415794, Loss 3.064640, forward nfe 16652, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 058, Runtime 24.859991, Loss 3.040523, forward nfe 16948, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 059, Runtime 25.284390, Loss 2.873935, forward nfe 17244, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 060, Runtime 25.369593, Loss 2.979637, forward nfe 17540, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 061, Runtime 25.859327, Loss 2.964548, forward nfe 17836, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 062, Runtime 26.696356, Loss 2.917799, forward nfe 18132, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 063, Runtime 27.673750, Loss 2.960255, forward nfe 18428, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 064, Runtime 27.918180, Loss 3.014938, forward nfe 18724, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 065, Runtime 27.973403, Loss 2.758579, forward nfe 19020, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 066, Runtime 28.742183, Loss 2.771214, forward nfe 19316, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 067, Runtime 27.913555, Loss 2.809429, forward nfe 19612, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 068, Runtime 28.518430, Loss 2.868550, forward nfe 19908, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 069, Runtime 29.263601, Loss 2.942491, forward nfe 20204, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 070, Runtime 29.778341, Loss 2.991137, forward nfe 20500, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 071, Runtime 29.813133, Loss 2.667276, forward nfe 20796, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 072, Runtime 30.133540, Loss 2.945541, forward nfe 21092, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 073, Runtime 30.572265, Loss 3.151943, forward nfe 21388, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 074, Runtime 30.920902, Loss 3.016530, forward nfe 21684, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 075, Runtime 31.429983, Loss 2.882216, forward nfe 21980, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 076, Runtime 31.102029, Loss 2.672621, forward nfe 22276, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 077, Runtime 31.181155, Loss 2.864799, forward nfe 22572, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 078, Runtime 31.267311, Loss 2.865965, forward nfe 22868, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 079, Runtime 31.903228, Loss 2.831097, forward nfe 23164, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 080, Runtime 29.115587, Loss 2.782967, forward nfe 23460, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 081, Runtime 21.195065, Loss 2.921294, forward nfe 23756, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 082, Runtime 21.414037, Loss 2.834354, forward nfe 24052, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 083, Runtime 22.056492, Loss 2.912332, forward nfe 24348, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 084, Runtime 23.081352, Loss 2.785884, forward nfe 24644, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 085, Runtime 24.172160, Loss 2.757819, forward nfe 24940, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 086, Runtime 25.145784, Loss 2.794277, forward nfe 25236, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 087, Runtime 25.998241, Loss 2.869256, forward nfe 25532, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 088, Runtime 25.963398, Loss 2.708844, forward nfe 25828, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 089, Runtime 26.604450, Loss 2.938171, forward nfe 26124, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 090, Runtime 27.579141, Loss 2.794562, forward nfe 26420, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 091, Runtime 28.494367, Loss 2.822341, forward nfe 26716, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 092, Runtime 29.123467, Loss 2.844181, forward nfe 27012, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 093, Runtime 29.809996, Loss 2.882037, forward nfe 27308, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 094, Runtime 29.669689, Loss 2.718780, forward nfe 27604, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 095, Runtime 29.883393, Loss 2.737029, forward nfe 27900, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 096, Runtime 30.841269, Loss 2.742872, forward nfe 28196, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 097, Runtime 31.017845, Loss 2.692525, forward nfe 28492, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 098, Runtime 30.761212, Loss 2.765411, forward nfe 28788, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
Epoch: 099, Runtime 31.427228, Loss 2.813719, forward nfe 29084, backward nfe 0, Train: 0.1786, Val: 0.2316, Test: 0.1990, Best time: 18.2948
best val accuracy 0.231618 with test accuracy 0.198985 at epoch 2 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.22030456852791877
Entropy Threshold: 2 Test accuracy: 0.24060913705583756
Entropy Threshold: 1.6 Test accuracy: 0.20752797558494404
Entropy Threshold: 1.5 Test accuracy: 0.2098635886673662
Entropy Threshold: 1.4 Test accuracy: 0.2445961319681456
Entropy Threshold: 1.3 Test accuracy: 0.2202852614896989
Entropy Threshold: 1.2 Test accuracy: 0.24019607843137256
Entropy Threshold: 1.1 Test accuracy: 0.23636363636363636
Entropy Threshold: 0.9 Test accuracy: 0.05
Entropy Threshold: 0.8 Test accuracy: 0.1111111111111111
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
