[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.516476, Loss 2.128445, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.3125, Test: 0.3056, Best time: 32.0000
Epoch: 002, Runtime 15.941091, Loss 2.611274, forward nfe 372, backward nfe 0, Train: 0.6071, Val: 0.4750, Test: 0.4751, Best time: 1.0000
Epoch: 003, Runtime 13.745960, Loss 2.130415, forward nfe 668, backward nfe 0, Train: 0.5786, Val: 0.4985, Test: 0.4995, Best time: 2.0000
Epoch: 004, Runtime 12.934674, Loss 2.030724, forward nfe 964, backward nfe 0, Train: 0.5786, Val: 0.5132, Test: 0.5107, Best time: 2.0000
Epoch: 005, Runtime 13.079388, Loss 2.066491, forward nfe 1260, backward nfe 0, Train: 0.6643, Val: 0.5787, Test: 0.5919, Best time: 2.0000
Epoch: 006, Runtime 12.905813, Loss 2.058326, forward nfe 1556, backward nfe 0, Train: 0.7000, Val: 0.6176, Test: 0.6345, Best time: 8.0000
Epoch: 007, Runtime 12.721337, Loss 1.935686, forward nfe 1852, backward nfe 0, Train: 0.7000, Val: 0.6176, Test: 0.6345, Best time: 18.2948
Epoch: 008, Runtime 13.306938, Loss 1.810329, forward nfe 2148, backward nfe 0, Train: 0.7000, Val: 0.6176, Test: 0.6345, Best time: 18.2948
Epoch: 009, Runtime 13.680831, Loss 1.844673, forward nfe 2444, backward nfe 0, Train: 0.7286, Val: 0.6426, Test: 0.6711, Best time: 18.0000
Epoch: 010, Runtime 12.926712, Loss 1.678089, forward nfe 2740, backward nfe 0, Train: 0.7429, Val: 0.6684, Test: 0.6812, Best time: 8.0000
Epoch: 011, Runtime 12.941037, Loss 1.510417, forward nfe 3036, backward nfe 0, Train: 0.7286, Val: 0.6831, Test: 0.6893, Best time: 14.0000
Epoch: 012, Runtime 13.010448, Loss 1.358360, forward nfe 3332, backward nfe 0, Train: 0.7357, Val: 0.6860, Test: 0.6853, Best time: 14.0000
Epoch: 013, Runtime 13.062180, Loss 1.263938, forward nfe 3628, backward nfe 0, Train: 0.7643, Val: 0.6882, Test: 0.6904, Best time: 14.0000
Epoch: 014, Runtime 13.011422, Loss 1.106420, forward nfe 3924, backward nfe 0, Train: 0.8000, Val: 0.7044, Test: 0.7076, Best time: 19.0000
Epoch: 015, Runtime 13.117979, Loss 1.020641, forward nfe 4220, backward nfe 0, Train: 0.7929, Val: 0.7235, Test: 0.7279, Best time: 39.0000
Epoch: 016, Runtime 13.029400, Loss 0.970610, forward nfe 4516, backward nfe 0, Train: 0.8000, Val: 0.7353, Test: 0.7523, Best time: 30.0000
Epoch: 017, Runtime 13.143811, Loss 0.928882, forward nfe 4812, backward nfe 0, Train: 0.8214, Val: 0.7500, Test: 0.7635, Best time: 22.0000
Epoch: 018, Runtime 13.104143, Loss 0.939220, forward nfe 5108, backward nfe 0, Train: 0.8286, Val: 0.7515, Test: 0.7635, Best time: 19.0000
Epoch: 019, Runtime 13.109923, Loss 0.914083, forward nfe 5404, backward nfe 0, Train: 0.8286, Val: 0.7515, Test: 0.7635, Best time: 18.2948
Epoch: 020, Runtime 13.852677, Loss 0.855292, forward nfe 5700, backward nfe 0, Train: 0.8286, Val: 0.7515, Test: 0.7635, Best time: 18.2948
Epoch: 021, Runtime 13.408330, Loss 0.825341, forward nfe 5996, backward nfe 0, Train: 0.8286, Val: 0.7515, Test: 0.7635, Best time: 18.2948
Epoch: 022, Runtime 13.902704, Loss 0.785511, forward nfe 6292, backward nfe 0, Train: 0.8286, Val: 0.7515, Test: 0.7635, Best time: 18.2948
Epoch: 023, Runtime 13.596137, Loss 0.771765, forward nfe 6588, backward nfe 0, Train: 0.8214, Val: 0.7684, Test: 0.7574, Best time: 18.2948
Epoch: 024, Runtime 13.244845, Loss 0.661158, forward nfe 6884, backward nfe 0, Train: 0.8714, Val: 0.7728, Test: 0.7777, Best time: 18.2948
Epoch: 025, Runtime 12.888740, Loss 0.754264, forward nfe 7180, backward nfe 0, Train: 0.9071, Val: 0.7794, Test: 0.7888, Best time: 22.0000
Epoch: 026, Runtime 13.099309, Loss 0.713100, forward nfe 7476, backward nfe 0, Train: 0.9000, Val: 0.7801, Test: 0.7898, Best time: 30.0000
Epoch: 027, Runtime 12.709651, Loss 0.631399, forward nfe 7772, backward nfe 0, Train: 0.9000, Val: 0.7801, Test: 0.7898, Best time: 18.2948
Epoch: 028, Runtime 13.290769, Loss 0.665261, forward nfe 8068, backward nfe 0, Train: 0.9000, Val: 0.7801, Test: 0.7898, Best time: 18.2948
Epoch: 029, Runtime 12.764480, Loss 0.623400, forward nfe 8364, backward nfe 0, Train: 0.9000, Val: 0.7801, Test: 0.7898, Best time: 18.2948
Epoch: 030, Runtime 13.040246, Loss 0.632303, forward nfe 8660, backward nfe 0, Train: 0.9000, Val: 0.7801, Test: 0.7898, Best time: 18.2948
Epoch: 031, Runtime 14.186813, Loss 0.580134, forward nfe 8956, backward nfe 0, Train: 0.9214, Val: 0.7904, Test: 0.7980, Best time: 33.0000
Epoch: 032, Runtime 13.137799, Loss 0.557409, forward nfe 9252, backward nfe 0, Train: 0.9286, Val: 0.8059, Test: 0.8132, Best time: 42.0000
Epoch: 033, Runtime 13.105044, Loss 0.614091, forward nfe 9548, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 37.0000
Epoch: 034, Runtime 12.719316, Loss 0.542186, forward nfe 9844, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 035, Runtime 13.428296, Loss 0.511087, forward nfe 10140, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 036, Runtime 12.772262, Loss 0.511435, forward nfe 10436, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 037, Runtime 13.069448, Loss 0.519632, forward nfe 10732, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 038, Runtime 13.773247, Loss 0.474583, forward nfe 11028, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 039, Runtime 13.851950, Loss 0.503570, forward nfe 11324, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 040, Runtime 13.605453, Loss 0.542499, forward nfe 11620, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 041, Runtime 14.360724, Loss 0.388448, forward nfe 11916, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 042, Runtime 14.034273, Loss 0.447111, forward nfe 12212, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 043, Runtime 14.350464, Loss 0.487846, forward nfe 12508, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 044, Runtime 14.808410, Loss 0.440272, forward nfe 12804, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 045, Runtime 14.508536, Loss 0.423590, forward nfe 13100, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 046, Runtime 14.908153, Loss 0.402312, forward nfe 13396, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 047, Runtime 14.941060, Loss 0.474022, forward nfe 13692, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 048, Runtime 15.131996, Loss 0.545281, forward nfe 13988, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 049, Runtime 14.976379, Loss 0.388039, forward nfe 14284, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 050, Runtime 15.243077, Loss 0.480070, forward nfe 14580, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 051, Runtime 15.374225, Loss 0.371792, forward nfe 14876, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 052, Runtime 15.009044, Loss 0.400906, forward nfe 15172, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 053, Runtime 15.635792, Loss 0.452459, forward nfe 15468, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 054, Runtime 15.556687, Loss 0.325194, forward nfe 15764, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 055, Runtime 15.423193, Loss 0.417412, forward nfe 16060, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 056, Runtime 15.940359, Loss 0.314603, forward nfe 16356, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 057, Runtime 15.732590, Loss 0.329290, forward nfe 16652, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 058, Runtime 15.837099, Loss 0.402060, forward nfe 16948, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 059, Runtime 16.122741, Loss 0.282790, forward nfe 17244, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 060, Runtime 15.660776, Loss 0.294820, forward nfe 17540, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 061, Runtime 15.923451, Loss 0.299217, forward nfe 17836, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 062, Runtime 16.144949, Loss 0.314173, forward nfe 18132, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 063, Runtime 15.835036, Loss 0.372916, forward nfe 18428, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 064, Runtime 16.197964, Loss 0.310499, forward nfe 18724, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 065, Runtime 16.351562, Loss 0.356364, forward nfe 19020, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 066, Runtime 15.973280, Loss 0.324942, forward nfe 19316, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 067, Runtime 16.453206, Loss 0.314414, forward nfe 19612, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 068, Runtime 16.639292, Loss 0.308716, forward nfe 19908, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 069, Runtime 16.187113, Loss 0.272594, forward nfe 20204, backward nfe 0, Train: 0.9429, Val: 0.8081, Test: 0.8193, Best time: 18.2948
Epoch: 070, Runtime 16.704437, Loss 0.305763, forward nfe 20500, backward nfe 0, Train: 0.9786, Val: 0.8221, Test: 0.8294, Best time: 51.0000
Epoch: 071, Runtime 12.782090, Loss 0.314033, forward nfe 20796, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 52.0000
Epoch: 072, Runtime 12.823593, Loss 0.287745, forward nfe 21092, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 073, Runtime 12.664928, Loss 0.405346, forward nfe 21388, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 074, Runtime 13.039739, Loss 0.290090, forward nfe 21684, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 075, Runtime 13.090035, Loss 0.301804, forward nfe 21980, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 076, Runtime 13.489228, Loss 0.337841, forward nfe 22276, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 077, Runtime 13.551024, Loss 0.291222, forward nfe 22572, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 078, Runtime 13.590640, Loss 0.298188, forward nfe 22868, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 079, Runtime 13.682237, Loss 0.292811, forward nfe 23164, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 080, Runtime 13.464259, Loss 0.395755, forward nfe 23460, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 081, Runtime 13.722424, Loss 0.318704, forward nfe 23756, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 082, Runtime 13.806193, Loss 0.322513, forward nfe 24052, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 083, Runtime 13.913528, Loss 0.277320, forward nfe 24348, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 084, Runtime 13.828373, Loss 0.334663, forward nfe 24644, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 085, Runtime 14.444748, Loss 0.288064, forward nfe 24940, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 086, Runtime 14.362159, Loss 0.327397, forward nfe 25236, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 087, Runtime 14.318569, Loss 0.305449, forward nfe 25532, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 088, Runtime 14.750383, Loss 0.307542, forward nfe 25828, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 089, Runtime 14.380259, Loss 0.299718, forward nfe 26124, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 090, Runtime 14.762374, Loss 0.236619, forward nfe 26420, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 091, Runtime 14.738190, Loss 0.230684, forward nfe 26716, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 092, Runtime 14.803879, Loss 0.251974, forward nfe 27012, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 093, Runtime 14.836746, Loss 0.214723, forward nfe 27308, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 094, Runtime 14.911660, Loss 0.236024, forward nfe 27604, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 095, Runtime 15.230702, Loss 0.200401, forward nfe 27900, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 096, Runtime 14.974348, Loss 0.390534, forward nfe 28196, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 097, Runtime 15.560856, Loss 0.223514, forward nfe 28492, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 098, Runtime 15.253487, Loss 0.230068, forward nfe 28788, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
Epoch: 099, Runtime 14.768165, Loss 0.293130, forward nfe 29084, backward nfe 0, Train: 0.9571, Val: 0.8287, Test: 0.8315, Best time: 18.2948
best val accuracy 0.828676 with test accuracy 0.831472 at epoch 71 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8324873096446701
Entropy Threshold: 2 Test accuracy: 0.8324873096446701
Entropy Threshold: 1.6 Test accuracy: 0.8267074413863404
Entropy Threshold: 1.5 Test accuracy: 0.8372811534500515
Entropy Threshold: 1.4 Test accuracy: 0.8435870698644421
Entropy Threshold: 1.3 Test accuracy: 0.8421610169491526
Entropy Threshold: 1.2 Test accuracy: 0.8587075575027382
Entropy Threshold: 1.1 Test accuracy: 0.8614525139664805
Entropy Threshold: 0.9 Test accuracy: 0.8916256157635468
Entropy Threshold: 0.8 Test accuracy: 0.905422446406053
Entropy Threshold: 0.7 Test accuracy: 0.91268758526603
Entropy Threshold: 0.6 Test accuracy: 0.9284692417739628
Entropy Threshold: 0.5 Test accuracy: 0.926605504587156
Entropy Threshold: 0.4 Test accuracy: 0.941747572815534
Entropy Threshold: 0.3 Test accuracy: 0.9373913043478261
Entropy Threshold: 0.2 Test accuracy: 0.9458413926499033
Entropy Threshold: 0.1 Test accuracy: 0.9314420803782506
