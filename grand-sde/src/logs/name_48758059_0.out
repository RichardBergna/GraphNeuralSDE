[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 7.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 13.677528, Loss 6.060029, forward nfe 76, backward nfe 0, Train: 0.3643, Val: 0.2853, Test: 0.2883, Best time: 1.0000
Epoch: 002, Runtime 13.871808, Loss 6.718798, forward nfe 372, backward nfe 0, Train: 0.3429, Val: 0.2971, Test: 0.2985, Best time: 1.0000
Epoch: 003, Runtime 12.785601, Loss 5.355827, forward nfe 668, backward nfe 0, Train: 0.5071, Val: 0.3875, Test: 0.3777, Best time: 1.0000
Epoch: 004, Runtime 13.328573, Loss 4.728648, forward nfe 964, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 1.0000
Epoch: 005, Runtime 13.043258, Loss 4.752221, forward nfe 1260, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 006, Runtime 13.471797, Loss 4.213050, forward nfe 1556, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 007, Runtime 13.448951, Loss 3.617425, forward nfe 1852, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 008, Runtime 13.773076, Loss 3.473513, forward nfe 2148, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 009, Runtime 13.473153, Loss 3.423486, forward nfe 2444, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 010, Runtime 13.842596, Loss 3.188359, forward nfe 2740, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 011, Runtime 13.380620, Loss 3.284713, forward nfe 3036, backward nfe 0, Train: 0.6000, Val: 0.4235, Test: 0.4071, Best time: 18.2948
Epoch: 012, Runtime 13.913731, Loss 3.027428, forward nfe 3332, backward nfe 0, Train: 0.5786, Val: 0.5294, Test: 0.5076, Best time: 5.0000
Epoch: 013, Runtime 13.349098, Loss 2.613056, forward nfe 3628, backward nfe 0, Train: 0.7786, Val: 0.6625, Test: 0.6579, Best time: 12.0000
Epoch: 014, Runtime 13.372077, Loss 2.731676, forward nfe 3924, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 9.0000
Epoch: 015, Runtime 12.881373, Loss 2.573149, forward nfe 4220, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 016, Runtime 13.406248, Loss 2.492684, forward nfe 4516, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 017, Runtime 13.033053, Loss 2.361134, forward nfe 4812, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 018, Runtime 13.396380, Loss 2.187603, forward nfe 5108, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 019, Runtime 13.140620, Loss 2.060005, forward nfe 5404, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 020, Runtime 13.370823, Loss 2.019122, forward nfe 5700, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 021, Runtime 13.526278, Loss 1.882455, forward nfe 5996, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 022, Runtime 13.859798, Loss 2.129421, forward nfe 6292, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 023, Runtime 14.424268, Loss 1.922178, forward nfe 6588, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 024, Runtime 14.195008, Loss 1.771574, forward nfe 6884, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 025, Runtime 14.362057, Loss 1.946606, forward nfe 7180, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 026, Runtime 14.647500, Loss 2.049750, forward nfe 7476, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 027, Runtime 14.926997, Loss 1.982753, forward nfe 7772, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 028, Runtime 15.302622, Loss 1.776450, forward nfe 8068, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 029, Runtime 14.884461, Loss 1.863361, forward nfe 8364, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 030, Runtime 15.272094, Loss 1.866857, forward nfe 8660, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 031, Runtime 15.205555, Loss 1.690120, forward nfe 8956, backward nfe 0, Train: 0.8286, Val: 0.6978, Test: 0.6985, Best time: 18.2948
Epoch: 032, Runtime 15.514109, Loss 1.834749, forward nfe 9252, backward nfe 0, Train: 0.8357, Val: 0.7007, Test: 0.6904, Best time: 15.0000
Epoch: 033, Runtime 13.178079, Loss 1.602786, forward nfe 9548, backward nfe 0, Train: 0.8857, Val: 0.7331, Test: 0.7127, Best time: 18.0000
Epoch: 034, Runtime 13.112617, Loss 1.681878, forward nfe 9844, backward nfe 0, Train: 0.8929, Val: 0.7434, Test: 0.7320, Best time: 16.0000
Epoch: 035, Runtime 12.983737, Loss 1.710724, forward nfe 10140, backward nfe 0, Train: 0.9071, Val: 0.7632, Test: 0.7492, Best time: 18.0000
Epoch: 036, Runtime 13.049131, Loss 1.707698, forward nfe 10436, backward nfe 0, Train: 0.9000, Val: 0.7750, Test: 0.7553, Best time: 37.0000
Epoch: 037, Runtime 13.067245, Loss 1.505084, forward nfe 10732, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 29.0000
Epoch: 038, Runtime 12.902270, Loss 1.573066, forward nfe 11028, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 039, Runtime 13.405679, Loss 1.749642, forward nfe 11324, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 040, Runtime 13.000796, Loss 1.522983, forward nfe 11620, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 041, Runtime 13.438727, Loss 1.272676, forward nfe 11916, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 042, Runtime 13.703162, Loss 1.624449, forward nfe 12212, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 043, Runtime 13.849853, Loss 1.370570, forward nfe 12508, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 044, Runtime 14.050245, Loss 1.532966, forward nfe 12804, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 045, Runtime 14.367189, Loss 1.491800, forward nfe 13100, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 046, Runtime 14.822083, Loss 1.497947, forward nfe 13396, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 047, Runtime 14.624594, Loss 1.340903, forward nfe 13692, backward nfe 0, Train: 0.9071, Val: 0.7765, Test: 0.7624, Best time: 18.2948
Epoch: 048, Runtime 15.375000, Loss 1.350419, forward nfe 13988, backward nfe 0, Train: 0.9000, Val: 0.7787, Test: 0.7624, Best time: 28.0000
Epoch: 049, Runtime 13.703136, Loss 1.420881, forward nfe 14284, backward nfe 0, Train: 0.9143, Val: 0.7824, Test: 0.7635, Best time: 29.0000
Epoch: 050, Runtime 13.476095, Loss 1.322490, forward nfe 14580, backward nfe 0, Train: 0.9143, Val: 0.7824, Test: 0.7635, Best time: 18.2948
Epoch: 051, Runtime 13.648637, Loss 1.309888, forward nfe 14876, backward nfe 0, Train: 0.9214, Val: 0.7860, Test: 0.7797, Best time: 47.0000
Epoch: 052, Runtime 13.587220, Loss 1.344280, forward nfe 15172, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 31.0000
Epoch: 053, Runtime 13.362911, Loss 1.428992, forward nfe 15468, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 054, Runtime 13.503947, Loss 1.306504, forward nfe 15764, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 055, Runtime 13.846117, Loss 1.357381, forward nfe 16060, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 056, Runtime 14.327488, Loss 1.114378, forward nfe 16356, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 057, Runtime 14.816633, Loss 1.112163, forward nfe 16652, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 058, Runtime 14.868735, Loss 1.226599, forward nfe 16948, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 059, Runtime 15.241501, Loss 1.002334, forward nfe 17244, backward nfe 0, Train: 0.9214, Val: 0.7919, Test: 0.7787, Best time: 18.2948
Epoch: 060, Runtime 15.628567, Loss 1.038642, forward nfe 17540, backward nfe 0, Train: 0.9143, Val: 0.7941, Test: 0.7807, Best time: 47.0000
Epoch: 061, Runtime 13.898613, Loss 0.897287, forward nfe 17836, backward nfe 0, Train: 0.9143, Val: 0.7963, Test: 0.7868, Best time: 52.0000
Epoch: 062, Runtime 14.055146, Loss 0.963338, forward nfe 18132, backward nfe 0, Train: 0.9286, Val: 0.8081, Test: 0.7888, Best time: 37.0000
Epoch: 063, Runtime 14.057105, Loss 1.186610, forward nfe 18428, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 49.0000
Epoch: 064, Runtime 13.951589, Loss 1.142799, forward nfe 18724, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 065, Runtime 14.168027, Loss 1.072807, forward nfe 19020, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 066, Runtime 14.372518, Loss 1.075171, forward nfe 19316, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 067, Runtime 14.706466, Loss 1.015218, forward nfe 19612, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 068, Runtime 14.952570, Loss 1.059290, forward nfe 19908, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 069, Runtime 15.353349, Loss 1.055168, forward nfe 20204, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 070, Runtime 15.673710, Loss 1.094817, forward nfe 20500, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 071, Runtime 15.786661, Loss 1.003946, forward nfe 20796, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 072, Runtime 16.096675, Loss 1.000332, forward nfe 21092, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 073, Runtime 16.704632, Loss 0.957545, forward nfe 21388, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 074, Runtime 16.924561, Loss 0.966371, forward nfe 21684, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 075, Runtime 17.202760, Loss 0.864103, forward nfe 21980, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 076, Runtime 17.383123, Loss 0.859836, forward nfe 22276, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 077, Runtime 17.637212, Loss 0.824652, forward nfe 22572, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 078, Runtime 17.836302, Loss 0.845186, forward nfe 22868, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 079, Runtime 18.063420, Loss 0.719074, forward nfe 23164, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 080, Runtime 18.118210, Loss 1.040226, forward nfe 23460, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 081, Runtime 18.402158, Loss 0.908607, forward nfe 23756, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 082, Runtime 18.920769, Loss 1.127484, forward nfe 24052, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 083, Runtime 19.261134, Loss 0.737945, forward nfe 24348, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 084, Runtime 19.243467, Loss 0.913723, forward nfe 24644, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 085, Runtime 19.428879, Loss 0.875601, forward nfe 24940, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 086, Runtime 19.698499, Loss 0.993807, forward nfe 25236, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 087, Runtime 19.844883, Loss 0.774327, forward nfe 25532, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 088, Runtime 19.799309, Loss 0.775201, forward nfe 25828, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 089, Runtime 19.780009, Loss 0.741790, forward nfe 26124, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 090, Runtime 19.647277, Loss 0.820423, forward nfe 26420, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 091, Runtime 19.743290, Loss 0.725850, forward nfe 26716, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 092, Runtime 19.960404, Loss 0.793762, forward nfe 27012, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 093, Runtime 19.902698, Loss 0.776273, forward nfe 27308, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 094, Runtime 20.119415, Loss 0.802733, forward nfe 27604, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 095, Runtime 19.994955, Loss 0.921280, forward nfe 27900, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 096, Runtime 20.083522, Loss 0.741109, forward nfe 28196, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 097, Runtime 19.844345, Loss 0.904383, forward nfe 28492, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 098, Runtime 19.824448, Loss 0.769137, forward nfe 28788, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
Epoch: 099, Runtime 20.216681, Loss 0.809446, forward nfe 29084, backward nfe 0, Train: 0.9286, Val: 0.8096, Test: 0.7848, Best time: 18.2948
best val accuracy 0.809559 with test accuracy 0.784772 at epoch 63 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.7898477157360406
Entropy Threshold: 2 Test accuracy: 0.8020304568527918
Entropy Threshold: 1.6 Test accuracy: 0.8182807399347116
Entropy Threshold: 1.5 Test accuracy: 0.8321995464852607
Entropy Threshold: 1.4 Test accuracy: 0.84375
Entropy Threshold: 1.3 Test accuracy: 0.8696774193548387
Entropy Threshold: 1.2 Test accuracy: 0.8896457765667575
Entropy Threshold: 1.1 Test accuracy: 0.8852223816355811
Entropy Threshold: 0.9 Test accuracy: 0.912396694214876
Entropy Threshold: 0.8 Test accuracy: 0.9219858156028369
Entropy Threshold: 0.7 Test accuracy: 0.9341317365269461
Entropy Threshold: 0.6 Test accuracy: 0.9517543859649122
Entropy Threshold: 0.5 Test accuracy: 0.964200477326969
Entropy Threshold: 0.4 Test accuracy: 0.9748603351955307
Entropy Threshold: 0.3 Test accuracy: 0.9725609756097561
Entropy Threshold: 0.2 Test accuracy: 0.9763779527559056
Entropy Threshold: 0.1 Test accuracy: 0.9846938775510204
