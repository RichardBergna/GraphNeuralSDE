[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 5.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 17.356470, Loss 4.551171, forward nfe 76, backward nfe 0, Train: 0.3786, Val: 0.1706, Test: 0.1695, Best time: 1.0000
Epoch: 002, Runtime 17.263485, Loss 4.419371, forward nfe 372, backward nfe 0, Train: 0.4143, Val: 0.2537, Test: 0.2508, Best time: 1.0000
Epoch: 003, Runtime 16.961624, Loss 4.033671, forward nfe 668, backward nfe 0, Train: 0.4000, Val: 0.2603, Test: 0.2477, Best time: 1.0000
Epoch: 004, Runtime 16.857877, Loss 3.442032, forward nfe 964, backward nfe 0, Train: 0.5286, Val: 0.3221, Test: 0.3127, Best time: 1.0000
Epoch: 005, Runtime 16.815306, Loss 3.129499, forward nfe 1260, backward nfe 0, Train: 0.5500, Val: 0.3581, Test: 0.3614, Best time: 1.0000
Epoch: 006, Runtime 16.895341, Loss 3.147573, forward nfe 1556, backward nfe 0, Train: 0.5786, Val: 0.3669, Test: 0.3888, Best time: 2.0000
Epoch: 007, Runtime 16.921169, Loss 2.608474, forward nfe 1852, backward nfe 0, Train: 0.6429, Val: 0.4559, Test: 0.4690, Best time: 9.0000
Epoch: 008, Runtime 16.295479, Loss 2.754207, forward nfe 2148, backward nfe 0, Train: 0.7143, Val: 0.5125, Test: 0.5157, Best time: 20.0000
Epoch: 009, Runtime 16.370691, Loss 2.247961, forward nfe 2444, backward nfe 0, Train: 0.7500, Val: 0.5610, Test: 0.5492, Best time: 13.0000
Epoch: 010, Runtime 16.384973, Loss 2.239586, forward nfe 2740, backward nfe 0, Train: 0.7571, Val: 0.5838, Test: 0.5797, Best time: 8.0000
Epoch: 011, Runtime 15.944069, Loss 2.032171, forward nfe 3036, backward nfe 0, Train: 0.7643, Val: 0.5993, Test: 0.6081, Best time: 10.0000
Epoch: 012, Runtime 16.023121, Loss 1.943478, forward nfe 3332, backward nfe 0, Train: 0.7571, Val: 0.6228, Test: 0.6244, Best time: 14.0000
Epoch: 013, Runtime 15.869854, Loss 1.962003, forward nfe 3628, backward nfe 0, Train: 0.8000, Val: 0.6544, Test: 0.6711, Best time: 7.0000
Epoch: 014, Runtime 15.785778, Loss 1.841594, forward nfe 3924, backward nfe 0, Train: 0.8214, Val: 0.6640, Test: 0.6812, Best time: 13.0000
Epoch: 015, Runtime 15.620962, Loss 1.679701, forward nfe 4220, backward nfe 0, Train: 0.8214, Val: 0.6640, Test: 0.6812, Best time: 18.2948
Epoch: 016, Runtime 16.283377, Loss 1.716336, forward nfe 4516, backward nfe 0, Train: 0.8214, Val: 0.6640, Test: 0.6812, Best time: 18.2948
Epoch: 017, Runtime 16.140267, Loss 1.679554, forward nfe 4812, backward nfe 0, Train: 0.8214, Val: 0.6640, Test: 0.6812, Best time: 18.2948
Epoch: 018, Runtime 16.083114, Loss 1.709744, forward nfe 5108, backward nfe 0, Train: 0.8357, Val: 0.6853, Test: 0.7025, Best time: 6.0000
Epoch: 019, Runtime 15.283142, Loss 1.464682, forward nfe 5404, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 8.0000
Epoch: 020, Runtime 15.249098, Loss 1.611163, forward nfe 5700, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 021, Runtime 15.648192, Loss 1.437075, forward nfe 5996, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 022, Runtime 15.778943, Loss 1.520594, forward nfe 6292, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 023, Runtime 16.094297, Loss 1.307721, forward nfe 6588, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 024, Runtime 16.278471, Loss 1.430843, forward nfe 6884, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 025, Runtime 16.765842, Loss 1.243954, forward nfe 7180, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 026, Runtime 17.353439, Loss 1.179834, forward nfe 7476, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 027, Runtime 17.453030, Loss 1.206967, forward nfe 7772, backward nfe 0, Train: 0.8286, Val: 0.6934, Test: 0.6904, Best time: 18.2948
Epoch: 028, Runtime 17.979802, Loss 1.116525, forward nfe 8068, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 4.0000
Epoch: 029, Runtime 16.208590, Loss 1.235486, forward nfe 8364, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 030, Runtime 16.915609, Loss 1.023568, forward nfe 8660, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 031, Runtime 16.179049, Loss 1.229992, forward nfe 8956, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 032, Runtime 17.309162, Loss 1.106621, forward nfe 9252, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 033, Runtime 17.137248, Loss 0.891953, forward nfe 9548, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 034, Runtime 17.115015, Loss 1.042941, forward nfe 9844, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 035, Runtime 17.499838, Loss 1.176567, forward nfe 10140, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 036, Runtime 18.336433, Loss 1.082322, forward nfe 10436, backward nfe 0, Train: 0.8071, Val: 0.7051, Test: 0.7218, Best time: 18.2948
Epoch: 037, Runtime 21.476851, Loss 1.144290, forward nfe 10732, backward nfe 0, Train: 0.8429, Val: 0.7088, Test: 0.7259, Best time: 4.0000
Epoch: 038, Runtime 19.908427, Loss 0.953672, forward nfe 11028, backward nfe 0, Train: 0.8571, Val: 0.7176, Test: 0.7340, Best time: 4.0000
Epoch: 039, Runtime 20.009773, Loss 0.987355, forward nfe 11324, backward nfe 0, Train: 0.8500, Val: 0.7257, Test: 0.7360, Best time: 8.0000
Epoch: 040, Runtime 19.682956, Loss 0.899541, forward nfe 11620, backward nfe 0, Train: 0.8643, Val: 0.7382, Test: 0.7492, Best time: 5.0000
Epoch: 041, Runtime 19.978545, Loss 0.884898, forward nfe 11916, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 6.0000
Epoch: 042, Runtime 19.682523, Loss 1.115019, forward nfe 12212, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 043, Runtime 20.164301, Loss 0.840694, forward nfe 12508, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 044, Runtime 20.287735, Loss 0.893093, forward nfe 12804, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 045, Runtime 20.323852, Loss 0.905180, forward nfe 13100, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 046, Runtime 20.407920, Loss 0.997170, forward nfe 13396, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 047, Runtime 20.897311, Loss 0.885676, forward nfe 13692, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 048, Runtime 20.460365, Loss 0.991664, forward nfe 13988, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 049, Runtime 20.512144, Loss 1.017063, forward nfe 14284, backward nfe 0, Train: 0.8643, Val: 0.7404, Test: 0.7543, Best time: 18.2948
Epoch: 050, Runtime 20.143246, Loss 0.918943, forward nfe 14580, backward nfe 0, Train: 0.8714, Val: 0.7500, Test: 0.7645, Best time: 5.0000
Epoch: 051, Runtime 17.959053, Loss 1.057472, forward nfe 14876, backward nfe 0, Train: 0.8643, Val: 0.7618, Test: 0.7777, Best time: 16.0000
Epoch: 052, Runtime 18.072940, Loss 0.809134, forward nfe 15172, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 16.0000
Epoch: 053, Runtime 17.794253, Loss 0.974021, forward nfe 15468, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 054, Runtime 17.919688, Loss 0.966724, forward nfe 15764, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 055, Runtime 17.576210, Loss 0.791503, forward nfe 16060, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 056, Runtime 17.771035, Loss 0.818607, forward nfe 16356, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 057, Runtime 17.968025, Loss 0.727624, forward nfe 16652, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 058, Runtime 17.698368, Loss 0.770900, forward nfe 16948, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 059, Runtime 16.330990, Loss 0.723182, forward nfe 17244, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 060, Runtime 16.560493, Loss 0.726305, forward nfe 17540, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 061, Runtime 16.828364, Loss 0.953326, forward nfe 17836, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 062, Runtime 16.931051, Loss 0.915317, forward nfe 18132, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 063, Runtime 16.981726, Loss 0.708036, forward nfe 18428, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 064, Runtime 17.244591, Loss 0.837108, forward nfe 18724, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 065, Runtime 16.860121, Loss 0.847205, forward nfe 19020, backward nfe 0, Train: 0.8286, Val: 0.7632, Test: 0.7756, Best time: 18.2948
Epoch: 066, Runtime 17.915189, Loss 0.795170, forward nfe 19316, backward nfe 0, Train: 0.8857, Val: 0.7816, Test: 0.7838, Best time: 20.0000
Epoch: 067, Runtime 14.759693, Loss 0.814448, forward nfe 19612, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 23.0000
Epoch: 068, Runtime 14.209677, Loss 0.625146, forward nfe 19908, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 069, Runtime 14.265206, Loss 0.678366, forward nfe 20204, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 070, Runtime 13.791190, Loss 0.642652, forward nfe 20500, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 071, Runtime 14.487195, Loss 0.739874, forward nfe 20796, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 072, Runtime 14.093069, Loss 0.664636, forward nfe 21092, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 073, Runtime 14.408494, Loss 0.746768, forward nfe 21388, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 074, Runtime 14.697130, Loss 0.677567, forward nfe 21684, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 075, Runtime 14.640580, Loss 0.746769, forward nfe 21980, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 076, Runtime 15.469551, Loss 0.676267, forward nfe 22276, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 077, Runtime 14.605271, Loss 0.754366, forward nfe 22572, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 078, Runtime 15.001703, Loss 0.782999, forward nfe 22868, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 079, Runtime 14.997735, Loss 0.633938, forward nfe 23164, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 080, Runtime 15.675197, Loss 0.606190, forward nfe 23460, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 081, Runtime 16.512273, Loss 0.660827, forward nfe 23756, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 082, Runtime 16.350723, Loss 0.833104, forward nfe 24052, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 083, Runtime 16.732752, Loss 0.783078, forward nfe 24348, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 084, Runtime 16.034535, Loss 0.703931, forward nfe 24644, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 085, Runtime 16.198410, Loss 0.726359, forward nfe 24940, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 086, Runtime 16.695112, Loss 0.717760, forward nfe 25236, backward nfe 0, Train: 0.8857, Val: 0.7868, Test: 0.7827, Best time: 18.2948
Epoch: 087, Runtime 17.725350, Loss 0.628449, forward nfe 25532, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 29.0000
Epoch: 088, Runtime 14.874733, Loss 0.703074, forward nfe 25828, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 089, Runtime 15.326459, Loss 0.745185, forward nfe 26124, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 090, Runtime 15.029026, Loss 0.703600, forward nfe 26420, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 091, Runtime 15.444895, Loss 0.705891, forward nfe 26716, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 092, Runtime 15.421995, Loss 0.726497, forward nfe 27012, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 093, Runtime 15.774410, Loss 0.695779, forward nfe 27308, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 094, Runtime 15.967534, Loss 0.782862, forward nfe 27604, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 095, Runtime 16.332749, Loss 0.619231, forward nfe 27900, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 096, Runtime 16.659688, Loss 0.626048, forward nfe 28196, backward nfe 0, Train: 0.8786, Val: 0.7985, Test: 0.8102, Best time: 18.2948
Epoch: 097, Runtime 16.719945, Loss 0.687205, forward nfe 28492, backward nfe 0, Train: 0.9000, Val: 0.7993, Test: 0.7919, Best time: 20.0000
Epoch: 098, Runtime 15.141470, Loss 0.592409, forward nfe 28788, backward nfe 0, Train: 0.9000, Val: 0.7993, Test: 0.7919, Best time: 18.2948
Epoch: 099, Runtime 15.590552, Loss 0.558922, forward nfe 29084, backward nfe 0, Train: 0.9000, Val: 0.7993, Test: 0.7919, Best time: 18.2948
best val accuracy 0.799265 with test accuracy 0.791878 at epoch 97 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8294416243654822
Entropy Threshold: 2 Test accuracy: 0.8324873096446701
Entropy Threshold: 1.6 Test accuracy: 0.84
Entropy Threshold: 1.5 Test accuracy: 0.8409090909090909
Entropy Threshold: 1.4 Test accuracy: 0.8440463645943098
Entropy Threshold: 1.3 Test accuracy: 0.8490364025695931
Entropy Threshold: 1.2 Test accuracy: 0.8536853685368537
Entropy Threshold: 1.1 Test accuracy: 0.8627450980392157
Entropy Threshold: 0.9 Test accuracy: 0.88875
Entropy Threshold: 0.8 Test accuracy: 0.8929503916449086
Entropy Threshold: 0.7 Test accuracy: 0.9138888888888889
Entropy Threshold: 0.6 Test accuracy: 0.93026706231454
Entropy Threshold: 0.5 Test accuracy: 0.937799043062201
Entropy Threshold: 0.4 Test accuracy: 0.9439728353140917
Entropy Threshold: 0.3 Test accuracy: 0.9457943925233645
Entropy Threshold: 0.2 Test accuracy: 0.955193482688391
Entropy Threshold: 0.1 Test accuracy: 0.9663461538461539
