[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 5.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 44.655013, Loss 3.631582, forward nfe 76, backward nfe 0, Train: 0.1571, Val: 0.1537, Test: 0.1665, Best time: 4.0000
Epoch: 002, Runtime 69.625869, Loss 34.747906, forward nfe 372, backward nfe 0, Train: 0.1571, Val: 0.1537, Test: 0.1665, Best time: 18.2948
Epoch: 003, Runtime 37.185196, Loss 3.291858, forward nfe 668, backward nfe 0, Train: 0.1571, Val: 0.1537, Test: 0.1665, Best time: 18.2948
Epoch: 004, Runtime 38.204703, Loss 3.190564, forward nfe 964, backward nfe 0, Train: 0.1571, Val: 0.1537, Test: 0.1665, Best time: 18.2948
Epoch: 005, Runtime 41.226777, Loss 3.462522, forward nfe 1260, backward nfe 0, Train: 0.1571, Val: 0.1537, Test: 0.1665, Best time: 18.2948
Epoch: 006, Runtime 42.763506, Loss 3.447531, forward nfe 1556, backward nfe 0, Train: 0.1357, Val: 0.1588, Test: 0.1188, Best time: 14.0000
Epoch: 007, Runtime 37.819294, Loss 3.109638, forward nfe 1852, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 14.0000
Epoch: 008, Runtime 38.592063, Loss 3.001055, forward nfe 2148, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 18.2948
Epoch: 009, Runtime 40.346996, Loss 3.028065, forward nfe 2444, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 18.2948
Epoch: 010, Runtime 41.431184, Loss 2.812342, forward nfe 2740, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 18.2948
Epoch: 011, Runtime 44.909030, Loss 2.923157, forward nfe 3036, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 18.2948
Epoch: 012, Runtime 45.856771, Loss 2.610862, forward nfe 3332, backward nfe 0, Train: 0.1571, Val: 0.1640, Test: 0.1401, Best time: 18.2948
Epoch: 013, Runtime 41.825759, Loss 2.508473, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.2265, Test: 0.2081, Best time: 13.0000
Epoch: 014, Runtime 27.148576, Loss 2.828615, forward nfe 3924, backward nfe 0, Train: 0.1714, Val: 0.2522, Test: 0.2579, Best time: 13.0000
Epoch: 015, Runtime 26.697770, Loss 2.699111, forward nfe 4220, backward nfe 0, Train: 0.1571, Val: 0.2596, Test: 0.2822, Best time: 11.0000
Epoch: 016, Runtime 26.300172, Loss 2.676498, forward nfe 4516, backward nfe 0, Train: 0.1500, Val: 0.2676, Test: 0.2893, Best time: 11.0000
Epoch: 017, Runtime 26.336445, Loss 2.876194, forward nfe 4812, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 11.0000
Epoch: 018, Runtime 25.329848, Loss 2.580331, forward nfe 5108, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 019, Runtime 25.169523, Loss 2.655645, forward nfe 5404, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 020, Runtime 26.620898, Loss 2.628133, forward nfe 5700, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 021, Runtime 26.093930, Loss 2.557645, forward nfe 5996, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 022, Runtime 27.737199, Loss 2.651942, forward nfe 6292, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 023, Runtime 27.636723, Loss 2.748694, forward nfe 6588, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 024, Runtime 28.349668, Loss 2.639713, forward nfe 6884, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 025, Runtime 28.354697, Loss 2.695081, forward nfe 7180, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 026, Runtime 27.895068, Loss 2.663178, forward nfe 7476, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 027, Runtime 29.367555, Loss 2.705422, forward nfe 7772, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 028, Runtime 29.164866, Loss 2.670154, forward nfe 8068, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 029, Runtime 27.257384, Loss 2.580144, forward nfe 8364, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 030, Runtime 26.273723, Loss 2.519616, forward nfe 8660, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 031, Runtime 26.212150, Loss 2.372186, forward nfe 8956, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 032, Runtime 25.444185, Loss 2.557927, forward nfe 9252, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 033, Runtime 25.092251, Loss 2.451602, forward nfe 9548, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 034, Runtime 24.860922, Loss 2.601997, forward nfe 9844, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 035, Runtime 25.412689, Loss 2.489589, forward nfe 10140, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 036, Runtime 25.516523, Loss 2.490292, forward nfe 10436, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 037, Runtime 28.922070, Loss 2.513457, forward nfe 10732, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 038, Runtime 31.337298, Loss 2.596158, forward nfe 11028, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 039, Runtime 31.375334, Loss 2.437548, forward nfe 11324, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 040, Runtime 31.404479, Loss 2.287728, forward nfe 11620, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 041, Runtime 31.696874, Loss 2.548346, forward nfe 11916, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 042, Runtime 31.829191, Loss 2.281641, forward nfe 12212, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 043, Runtime 31.945751, Loss 2.459296, forward nfe 12508, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 044, Runtime 32.457687, Loss 2.466821, forward nfe 12804, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 045, Runtime 32.761600, Loss 2.245594, forward nfe 13100, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 046, Runtime 32.785435, Loss 2.402350, forward nfe 13396, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 047, Runtime 33.527874, Loss 2.577347, forward nfe 13692, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 048, Runtime 32.739112, Loss 2.341191, forward nfe 13988, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 049, Runtime 28.817061, Loss 2.331697, forward nfe 14284, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 050, Runtime 22.106955, Loss 2.468239, forward nfe 14580, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 051, Runtime 22.785268, Loss 2.540378, forward nfe 14876, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 052, Runtime 22.919160, Loss 2.671952, forward nfe 15172, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 053, Runtime 24.088285, Loss 2.391619, forward nfe 15468, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 054, Runtime 24.669115, Loss 2.345136, forward nfe 15764, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 055, Runtime 25.104535, Loss 2.302026, forward nfe 16060, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 056, Runtime 25.748710, Loss 2.357367, forward nfe 16356, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 057, Runtime 26.304050, Loss 2.457259, forward nfe 16652, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 058, Runtime 23.668215, Loss 2.401659, forward nfe 16948, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 059, Runtime 25.668363, Loss 2.370207, forward nfe 17244, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 060, Runtime 24.128808, Loss 2.374932, forward nfe 17540, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 061, Runtime 25.112029, Loss 2.499391, forward nfe 17836, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 062, Runtime 28.652857, Loss 2.464154, forward nfe 18132, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 063, Runtime 26.356340, Loss 2.383582, forward nfe 18428, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 064, Runtime 27.570843, Loss 2.196135, forward nfe 18724, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 065, Runtime 29.159528, Loss 2.308366, forward nfe 19020, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 066, Runtime 29.259710, Loss 2.331286, forward nfe 19316, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 067, Runtime 29.742727, Loss 2.261094, forward nfe 19612, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 068, Runtime 29.697564, Loss 2.413271, forward nfe 19908, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 069, Runtime 28.977028, Loss 2.192802, forward nfe 20204, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 070, Runtime 29.982193, Loss 2.379718, forward nfe 20500, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 071, Runtime 30.366513, Loss 2.368014, forward nfe 20796, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 072, Runtime 30.320786, Loss 2.359998, forward nfe 21092, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 073, Runtime 30.915027, Loss 2.245488, forward nfe 21388, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 074, Runtime 31.283075, Loss 2.171585, forward nfe 21684, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 075, Runtime 31.726311, Loss 2.222227, forward nfe 21980, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 076, Runtime 31.100649, Loss 2.377741, forward nfe 22276, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 077, Runtime 32.584655, Loss 2.207579, forward nfe 22572, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 078, Runtime 32.143862, Loss 2.180953, forward nfe 22868, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 079, Runtime 31.529095, Loss 2.318056, forward nfe 23164, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 080, Runtime 31.529099, Loss 2.313794, forward nfe 23460, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 081, Runtime 24.046546, Loss 2.352418, forward nfe 23756, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 082, Runtime 20.778173, Loss 2.381811, forward nfe 24052, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 083, Runtime 20.490320, Loss 2.412997, forward nfe 24348, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 084, Runtime 20.781835, Loss 2.285572, forward nfe 24644, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 085, Runtime 21.238884, Loss 2.258029, forward nfe 24940, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 086, Runtime 21.549580, Loss 2.491452, forward nfe 25236, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 087, Runtime 22.571866, Loss 2.457200, forward nfe 25532, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 088, Runtime 23.244884, Loss 2.258829, forward nfe 25828, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 089, Runtime 23.915262, Loss 2.402035, forward nfe 26124, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 090, Runtime 24.275266, Loss 2.285730, forward nfe 26420, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 091, Runtime 25.036042, Loss 2.244908, forward nfe 26716, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 092, Runtime 25.606987, Loss 2.232314, forward nfe 27012, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 093, Runtime 29.676696, Loss 2.274249, forward nfe 27308, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 094, Runtime 29.923571, Loss 2.293796, forward nfe 27604, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 095, Runtime 27.852948, Loss 2.324202, forward nfe 27900, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 096, Runtime 28.234785, Loss 2.316071, forward nfe 28196, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 097, Runtime 28.378242, Loss 2.198034, forward nfe 28492, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 098, Runtime 29.000105, Loss 2.164279, forward nfe 28788, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
Epoch: 099, Runtime 29.537619, Loss 2.312897, forward nfe 29084, backward nfe 0, Train: 0.1500, Val: 0.2735, Test: 0.2863, Best time: 18.2948
best val accuracy 0.273529 with test accuracy 0.286294 at epoch 17 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.09441624365482233
Entropy Threshold: 2 Test accuracy: 0.10862944162436548
Entropy Threshold: 1.6 Test accuracy: 0.09100418410041841
Entropy Threshold: 1.5 Test accuracy: 0.09497816593886463
Entropy Threshold: 1.4 Test accuracy: 0.09820359281437126
Entropy Threshold: 1.3 Test accuracy: 0.09959623149394348
Entropy Threshold: 1.2 Test accuracy: 0.0899390243902439
Entropy Threshold: 1.1 Test accuracy: 0.10074626865671642
Entropy Threshold: 0.9 Test accuracy: 0.0959409594095941
Entropy Threshold: 0.8 Test accuracy: 0.08152173913043478
Entropy Threshold: 0.7 Test accuracy: 0.07058823529411765
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: 0.0
