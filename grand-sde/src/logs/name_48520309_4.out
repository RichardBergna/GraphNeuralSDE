[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 9.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 39.780607, Loss 8.803253, forward nfe 76, backward nfe 0, Train: 0.1357, Val: 0.1404, Test: 0.1706, Best time: 1.0000
Epoch: 002, Runtime 60.180346, Loss 31.719374, forward nfe 372, backward nfe 0, Train: 0.1357, Val: 0.1404, Test: 0.1706, Best time: 18.2948
Epoch: 003, Runtime 22.905309, Loss 5.714191, forward nfe 668, backward nfe 0, Train: 0.1357, Val: 0.1404, Test: 0.1706, Best time: 18.2948
Epoch: 004, Runtime 23.625587, Loss 5.680428, forward nfe 964, backward nfe 0, Train: 0.1357, Val: 0.1404, Test: 0.1706, Best time: 18.2948
Epoch: 005, Runtime 23.995408, Loss 5.374916, forward nfe 1260, backward nfe 0, Train: 0.1571, Val: 0.1449, Test: 0.1482, Best time: 18.2948
Epoch: 006, Runtime 20.807075, Loss 5.619094, forward nfe 1556, backward nfe 0, Train: 0.1357, Val: 0.1882, Test: 0.2000, Best time: 54.8843
Epoch: 007, Runtime 21.008513, Loss 5.214164, forward nfe 1852, backward nfe 0, Train: 0.1357, Val: 0.1882, Test: 0.2000, Best time: 18.2948
Epoch: 008, Runtime 21.264157, Loss 5.214466, forward nfe 2148, backward nfe 0, Train: 0.1357, Val: 0.1882, Test: 0.2000, Best time: 18.2948
Epoch: 009, Runtime 21.377286, Loss 4.959137, forward nfe 2444, backward nfe 0, Train: 0.1357, Val: 0.1882, Test: 0.2000, Best time: 18.2948
Epoch: 010, Runtime 21.909043, Loss 4.662453, forward nfe 2740, backward nfe 0, Train: 0.1500, Val: 0.2184, Test: 0.2112, Best time: 54.8843
Epoch: 011, Runtime 21.218340, Loss 4.659039, forward nfe 3036, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 54.8843
Epoch: 012, Runtime 21.197729, Loss 4.594617, forward nfe 3332, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 013, Runtime 21.435712, Loss 3.830305, forward nfe 3628, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 014, Runtime 21.699815, Loss 4.155575, forward nfe 3924, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 015, Runtime 22.117557, Loss 4.178988, forward nfe 4220, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 016, Runtime 22.829561, Loss 4.025093, forward nfe 4516, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 017, Runtime 24.447988, Loss 4.313449, forward nfe 4812, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 018, Runtime 25.376287, Loss 4.004782, forward nfe 5108, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 019, Runtime 25.614550, Loss 3.910559, forward nfe 5404, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 020, Runtime 25.311391, Loss 3.720137, forward nfe 5700, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 021, Runtime 25.378889, Loss 3.853491, forward nfe 5996, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 022, Runtime 26.583343, Loss 4.047845, forward nfe 6292, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 023, Runtime 27.549913, Loss 3.564599, forward nfe 6588, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 024, Runtime 28.279848, Loss 3.547686, forward nfe 6884, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 025, Runtime 28.464744, Loss 3.497995, forward nfe 7180, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 026, Runtime 28.470789, Loss 3.589679, forward nfe 7476, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 027, Runtime 28.979279, Loss 3.602138, forward nfe 7772, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 028, Runtime 29.149941, Loss 3.374686, forward nfe 8068, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 029, Runtime 29.692964, Loss 3.395995, forward nfe 8364, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 030, Runtime 30.287448, Loss 3.376786, forward nfe 8660, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 031, Runtime 30.192770, Loss 3.460809, forward nfe 8956, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 032, Runtime 30.566411, Loss 3.203953, forward nfe 9252, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 033, Runtime 30.583362, Loss 3.559344, forward nfe 9548, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 034, Runtime 31.216967, Loss 3.453810, forward nfe 9844, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 035, Runtime 30.995424, Loss 3.297675, forward nfe 10140, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 036, Runtime 31.486186, Loss 3.194744, forward nfe 10436, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 037, Runtime 31.443087, Loss 3.180830, forward nfe 10732, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 038, Runtime 31.433653, Loss 3.356800, forward nfe 11028, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 039, Runtime 27.853484, Loss 3.505633, forward nfe 11324, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 040, Runtime 21.144726, Loss 3.420120, forward nfe 11620, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 041, Runtime 22.405921, Loss 3.177977, forward nfe 11916, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 042, Runtime 23.485384, Loss 3.001737, forward nfe 12212, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 043, Runtime 23.555619, Loss 2.899075, forward nfe 12508, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 044, Runtime 24.185290, Loss 3.113178, forward nfe 12804, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 045, Runtime 24.978651, Loss 3.105795, forward nfe 13100, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 046, Runtime 25.952122, Loss 3.050639, forward nfe 13396, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 047, Runtime 26.479185, Loss 3.151174, forward nfe 13692, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 048, Runtime 26.718929, Loss 3.094123, forward nfe 13988, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 049, Runtime 27.063158, Loss 3.355831, forward nfe 14284, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 050, Runtime 28.137070, Loss 3.045589, forward nfe 14580, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 051, Runtime 28.919022, Loss 3.007723, forward nfe 14876, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 052, Runtime 28.807867, Loss 2.761046, forward nfe 15172, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 053, Runtime 29.273067, Loss 3.023296, forward nfe 15468, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 054, Runtime 29.749674, Loss 2.972884, forward nfe 15764, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 055, Runtime 30.040998, Loss 2.963454, forward nfe 16060, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 056, Runtime 30.369858, Loss 2.826986, forward nfe 16356, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 057, Runtime 30.798303, Loss 3.031588, forward nfe 16652, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 058, Runtime 31.244178, Loss 3.105962, forward nfe 16948, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 059, Runtime 31.692191, Loss 3.035737, forward nfe 17244, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 060, Runtime 31.721057, Loss 2.972209, forward nfe 17540, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 061, Runtime 31.440251, Loss 2.793662, forward nfe 17836, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 062, Runtime 31.540894, Loss 2.636358, forward nfe 18132, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 063, Runtime 32.330341, Loss 3.016141, forward nfe 18428, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 064, Runtime 32.389377, Loss 3.000243, forward nfe 18724, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 065, Runtime 32.451503, Loss 2.872644, forward nfe 19020, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 066, Runtime 28.647798, Loss 2.798527, forward nfe 19316, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 067, Runtime 21.263976, Loss 2.860207, forward nfe 19612, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 068, Runtime 22.183181, Loss 2.975722, forward nfe 19908, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 069, Runtime 23.134825, Loss 2.963693, forward nfe 20204, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 070, Runtime 23.519778, Loss 2.989146, forward nfe 20500, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 071, Runtime 24.084206, Loss 3.022830, forward nfe 20796, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 072, Runtime 24.673717, Loss 3.046939, forward nfe 21092, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 073, Runtime 25.418536, Loss 2.688080, forward nfe 21388, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 074, Runtime 26.440673, Loss 2.933167, forward nfe 21684, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 075, Runtime 27.535736, Loss 2.986760, forward nfe 21980, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 076, Runtime 28.774840, Loss 3.081736, forward nfe 22276, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 077, Runtime 28.572677, Loss 2.791592, forward nfe 22572, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 078, Runtime 30.313902, Loss 3.104041, forward nfe 22868, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 079, Runtime 30.791680, Loss 2.544085, forward nfe 23164, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 080, Runtime 31.709724, Loss 3.125810, forward nfe 23460, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 081, Runtime 31.270131, Loss 2.692855, forward nfe 23756, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 082, Runtime 32.259278, Loss 3.007041, forward nfe 24052, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 083, Runtime 31.427244, Loss 2.928603, forward nfe 24348, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 084, Runtime 31.064277, Loss 2.771116, forward nfe 24644, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 085, Runtime 31.787925, Loss 2.620391, forward nfe 24940, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 086, Runtime 32.277292, Loss 2.685405, forward nfe 25236, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 087, Runtime 22.341993, Loss 3.202743, forward nfe 25532, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 088, Runtime 22.106764, Loss 2.670411, forward nfe 25828, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 089, Runtime 22.239608, Loss 2.781808, forward nfe 26124, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 090, Runtime 23.817317, Loss 2.658162, forward nfe 26420, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 091, Runtime 24.570419, Loss 2.843715, forward nfe 26716, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 092, Runtime 25.770981, Loss 2.808182, forward nfe 27012, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 093, Runtime 25.955951, Loss 2.685683, forward nfe 27308, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 094, Runtime 26.364851, Loss 2.697731, forward nfe 27604, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 095, Runtime 27.020138, Loss 2.924404, forward nfe 27900, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 096, Runtime 28.012316, Loss 2.757704, forward nfe 28196, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 097, Runtime 29.170388, Loss 2.750917, forward nfe 28492, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 098, Runtime 29.942277, Loss 2.846431, forward nfe 28788, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
Epoch: 099, Runtime 29.830064, Loss 2.982843, forward nfe 29084, backward nfe 0, Train: 0.1786, Val: 0.2816, Test: 0.2721, Best time: 18.2948
best val accuracy 0.281618 with test accuracy 0.272081 at epoch 11 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.16040609137055836
Entropy Threshold: 2 Test accuracy: 0.18781725888324874
Entropy Threshold: 1.6 Test accuracy: 0.1956521739130435
Entropy Threshold: 1.5 Test accuracy: 0.1744186046511628
Entropy Threshold: 1.4 Test accuracy: 0.21359223300970873
Entropy Threshold: 1.3 Test accuracy: 0.18421052631578946
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
