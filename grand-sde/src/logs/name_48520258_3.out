[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 6.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 34.516658, Loss 5.007021, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1442, Best time: 18.2948
Epoch: 002, Runtime 51.715176, Loss 14.629883, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1442, Best time: 18.2948
Epoch: 003, Runtime 30.858904, Loss 3.560468, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1442, Best time: 18.2948
Epoch: 004, Runtime 30.728308, Loss 3.799128, forward nfe 964, backward nfe 0, Train: 0.1643, Val: 0.2625, Test: 0.2437, Best time: 1.0000
Epoch: 005, Runtime 28.134228, Loss 3.635115, forward nfe 1260, backward nfe 0, Train: 0.1500, Val: 0.2985, Test: 0.2731, Best time: 1.0000
Epoch: 006, Runtime 28.825469, Loss 3.917462, forward nfe 1556, backward nfe 0, Train: 0.1500, Val: 0.3059, Test: 0.2812, Best time: 1.0000
Epoch: 007, Runtime 29.013626, Loss 3.867881, forward nfe 1852, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 1.0000
Epoch: 008, Runtime 29.043306, Loss 3.533301, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 009, Runtime 29.943345, Loss 3.343484, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 010, Runtime 29.815388, Loss 3.374177, forward nfe 2740, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 011, Runtime 30.334465, Loss 3.258983, forward nfe 3036, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 012, Runtime 31.875486, Loss 2.932870, forward nfe 3332, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 013, Runtime 34.295724, Loss 2.583879, forward nfe 3628, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 014, Runtime 35.344347, Loss 2.583963, forward nfe 3924, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 015, Runtime 36.866011, Loss 2.638172, forward nfe 4220, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 016, Runtime 38.575647, Loss 2.847091, forward nfe 4516, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 017, Runtime 38.368786, Loss 2.824827, forward nfe 4812, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 018, Runtime 38.909983, Loss 3.013080, forward nfe 5108, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 019, Runtime 34.501746, Loss 3.192845, forward nfe 5404, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 020, Runtime 35.069562, Loss 2.869331, forward nfe 5700, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 021, Runtime 34.425949, Loss 2.672955, forward nfe 5996, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 022, Runtime 34.760559, Loss 2.535389, forward nfe 6292, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 023, Runtime 34.198759, Loss 2.726518, forward nfe 6588, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 024, Runtime 35.740102, Loss 2.568393, forward nfe 6884, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 025, Runtime 35.728509, Loss 2.317244, forward nfe 7180, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 026, Runtime 36.690747, Loss 2.653854, forward nfe 7476, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 027, Runtime 35.995501, Loss 2.645217, forward nfe 7772, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 028, Runtime 35.887959, Loss 2.638322, forward nfe 8068, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 029, Runtime 35.025487, Loss 2.513680, forward nfe 8364, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 030, Runtime 34.967868, Loss 2.494589, forward nfe 8660, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 031, Runtime 34.448004, Loss 2.645890, forward nfe 8956, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 032, Runtime 33.240055, Loss 2.334431, forward nfe 9252, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 033, Runtime 33.034355, Loss 2.622796, forward nfe 9548, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 034, Runtime 22.407163, Loss 2.490473, forward nfe 9844, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 035, Runtime 20.376302, Loss 2.508255, forward nfe 10140, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 036, Runtime 20.142621, Loss 2.557654, forward nfe 10436, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 037, Runtime 20.713395, Loss 2.537760, forward nfe 10732, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 038, Runtime 20.826893, Loss 2.395005, forward nfe 11028, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 039, Runtime 20.665561, Loss 2.489214, forward nfe 11324, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 040, Runtime 20.611760, Loss 2.470683, forward nfe 11620, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 041, Runtime 20.791633, Loss 2.556739, forward nfe 11916, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 042, Runtime 21.096281, Loss 2.419233, forward nfe 12212, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 043, Runtime 21.664954, Loss 2.454599, forward nfe 12508, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 044, Runtime 22.327508, Loss 2.392253, forward nfe 12804, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 045, Runtime 23.560748, Loss 2.586854, forward nfe 13100, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 046, Runtime 23.358501, Loss 2.441434, forward nfe 13396, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 047, Runtime 23.557326, Loss 2.405482, forward nfe 13692, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 048, Runtime 23.973063, Loss 2.315188, forward nfe 13988, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 049, Runtime 24.527700, Loss 2.455791, forward nfe 14284, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 050, Runtime 24.961362, Loss 2.460515, forward nfe 14580, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 051, Runtime 25.292234, Loss 2.366003, forward nfe 14876, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 052, Runtime 25.383983, Loss 2.396251, forward nfe 15172, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 053, Runtime 26.032636, Loss 2.499018, forward nfe 15468, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 054, Runtime 26.256338, Loss 2.526750, forward nfe 15764, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 055, Runtime 26.649529, Loss 2.564638, forward nfe 16060, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 056, Runtime 27.083191, Loss 2.526876, forward nfe 16356, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 057, Runtime 27.466742, Loss 2.430061, forward nfe 16652, backward nfe 0, Train: 0.1500, Val: 0.3081, Test: 0.2843, Best time: 18.2948
Epoch: 058, Runtime 27.812038, Loss 2.313537, forward nfe 16948, backward nfe 0, Train: 0.2786, Val: 0.3096, Test: 0.2832, Best time: 1.0000
Epoch: 059, Runtime 18.785195, Loss 2.346353, forward nfe 17244, backward nfe 0, Train: 0.2857, Val: 0.3221, Test: 0.2964, Best time: 1.0000
Epoch: 060, Runtime 18.886383, Loss 2.375816, forward nfe 17540, backward nfe 0, Train: 0.2929, Val: 0.3324, Test: 0.3066, Best time: 3.0000
Epoch: 061, Runtime 18.753975, Loss 2.438056, forward nfe 17836, backward nfe 0, Train: 0.2714, Val: 0.3338, Test: 0.3076, Best time: 2.0000
Epoch: 062, Runtime 18.741205, Loss 2.325344, forward nfe 18132, backward nfe 0, Train: 0.2714, Val: 0.3338, Test: 0.3076, Best time: 18.2948
Epoch: 063, Runtime 19.017986, Loss 2.320690, forward nfe 18428, backward nfe 0, Train: 0.2571, Val: 0.3360, Test: 0.3147, Best time: 6.0000
Epoch: 064, Runtime 18.853767, Loss 2.247928, forward nfe 18724, backward nfe 0, Train: 0.2286, Val: 0.3382, Test: 0.3137, Best time: 6.0000
Epoch: 065, Runtime 18.633324, Loss 2.366181, forward nfe 19020, backward nfe 0, Train: 0.2286, Val: 0.3382, Test: 0.3137, Best time: 18.2948
Epoch: 066, Runtime 19.292731, Loss 2.424532, forward nfe 19316, backward nfe 0, Train: 0.2000, Val: 0.3397, Test: 0.3127, Best time: 7.0000
Epoch: 067, Runtime 19.061507, Loss 2.363883, forward nfe 19612, backward nfe 0, Train: 0.2000, Val: 0.3426, Test: 0.3168, Best time: 7.0000
Epoch: 068, Runtime 18.638781, Loss 2.340292, forward nfe 19908, backward nfe 0, Train: 0.2000, Val: 0.3426, Test: 0.3168, Best time: 18.2948
Epoch: 069, Runtime 18.996200, Loss 2.348727, forward nfe 20204, backward nfe 0, Train: 0.2000, Val: 0.3426, Test: 0.3168, Best time: 18.2948
Epoch: 070, Runtime 20.252499, Loss 2.558957, forward nfe 20500, backward nfe 0, Train: 0.2071, Val: 0.3434, Test: 0.3178, Best time: 9.0000
Epoch: 071, Runtime 19.500404, Loss 2.284474, forward nfe 20796, backward nfe 0, Train: 0.1857, Val: 0.3441, Test: 0.3218, Best time: 9.0000
Epoch: 072, Runtime 19.517313, Loss 2.310345, forward nfe 21092, backward nfe 0, Train: 0.2071, Val: 0.3463, Test: 0.3168, Best time: 10.0000
Epoch: 073, Runtime 19.181482, Loss 2.346960, forward nfe 21388, backward nfe 0, Train: 0.2071, Val: 0.3463, Test: 0.3168, Best time: 18.2948
Epoch: 074, Runtime 19.310365, Loss 2.317127, forward nfe 21684, backward nfe 0, Train: 0.2071, Val: 0.3463, Test: 0.3168, Best time: 18.2948
Epoch: 075, Runtime 20.090946, Loss 2.229917, forward nfe 21980, backward nfe 0, Train: 0.2071, Val: 0.3463, Test: 0.3168, Best time: 18.2948
Epoch: 076, Runtime 21.147359, Loss 2.264923, forward nfe 22276, backward nfe 0, Train: 0.2071, Val: 0.3478, Test: 0.3218, Best time: 10.0000
Epoch: 077, Runtime 19.459147, Loss 2.395980, forward nfe 22572, backward nfe 0, Train: 0.2071, Val: 0.3493, Test: 0.3228, Best time: 10.0000
Epoch: 078, Runtime 19.456996, Loss 2.206479, forward nfe 22868, backward nfe 0, Train: 0.2071, Val: 0.3493, Test: 0.3228, Best time: 18.2948
Epoch: 079, Runtime 19.688388, Loss 2.204137, forward nfe 23164, backward nfe 0, Train: 0.2071, Val: 0.3493, Test: 0.3228, Best time: 18.2948
Epoch: 080, Runtime 20.568881, Loss 2.183547, forward nfe 23460, backward nfe 0, Train: 0.1857, Val: 0.3500, Test: 0.3198, Best time: 8.0000
Epoch: 081, Runtime 19.612806, Loss 2.300705, forward nfe 23756, backward nfe 0, Train: 0.1857, Val: 0.3507, Test: 0.3198, Best time: 8.0000
Epoch: 082, Runtime 19.334995, Loss 2.285239, forward nfe 24052, backward nfe 0, Train: 0.1857, Val: 0.3522, Test: 0.3188, Best time: 7.0000
Epoch: 083, Runtime 18.964111, Loss 2.244858, forward nfe 24348, backward nfe 0, Train: 0.1857, Val: 0.3537, Test: 0.3198, Best time: 7.0000
Epoch: 084, Runtime 18.903531, Loss 2.302963, forward nfe 24644, backward nfe 0, Train: 0.1857, Val: 0.3537, Test: 0.3198, Best time: 18.2948
Epoch: 085, Runtime 19.320961, Loss 2.227328, forward nfe 24940, backward nfe 0, Train: 0.1857, Val: 0.3544, Test: 0.3228, Best time: 7.0000
Epoch: 086, Runtime 19.515203, Loss 2.354844, forward nfe 25236, backward nfe 0, Train: 0.1857, Val: 0.3551, Test: 0.3228, Best time: 6.0000
Epoch: 087, Runtime 19.299676, Loss 2.268361, forward nfe 25532, backward nfe 0, Train: 0.2214, Val: 0.3566, Test: 0.3228, Best time: 11.0000
Epoch: 088, Runtime 19.245492, Loss 2.270241, forward nfe 25828, backward nfe 0, Train: 0.1929, Val: 0.3574, Test: 0.3249, Best time: 7.0000
Epoch: 089, Runtime 19.477427, Loss 2.148501, forward nfe 26124, backward nfe 0, Train: 0.1929, Val: 0.3581, Test: 0.3269, Best time: 7.0000
Epoch: 090, Runtime 19.837316, Loss 2.313511, forward nfe 26420, backward nfe 0, Train: 0.1929, Val: 0.3625, Test: 0.3269, Best time: 7.0000
Epoch: 091, Runtime 19.264778, Loss 2.116462, forward nfe 26716, backward nfe 0, Train: 0.1929, Val: 0.3625, Test: 0.3269, Best time: 18.2948
Epoch: 092, Runtime 19.315768, Loss 2.252914, forward nfe 27012, backward nfe 0, Train: 0.1929, Val: 0.3625, Test: 0.3269, Best time: 18.2948
Epoch: 093, Runtime 20.349101, Loss 2.173217, forward nfe 27308, backward nfe 0, Train: 0.1929, Val: 0.3632, Test: 0.3239, Best time: 6.0000
Epoch: 094, Runtime 20.043217, Loss 2.142606, forward nfe 27604, backward nfe 0, Train: 0.2000, Val: 0.3654, Test: 0.3310, Best time: 8.0000
Epoch: 095, Runtime 20.666110, Loss 2.312279, forward nfe 27900, backward nfe 0, Train: 0.2000, Val: 0.3662, Test: 0.3320, Best time: 8.0000
Epoch: 096, Runtime 20.552846, Loss 2.204485, forward nfe 28196, backward nfe 0, Train: 0.2000, Val: 0.3662, Test: 0.3320, Best time: 18.2948
Epoch: 097, Runtime 20.516459, Loss 2.185341, forward nfe 28492, backward nfe 0, Train: 0.1929, Val: 0.3669, Test: 0.3299, Best time: 5.0000
Epoch: 098, Runtime 20.500297, Loss 2.359952, forward nfe 28788, backward nfe 0, Train: 0.1929, Val: 0.3676, Test: 0.3320, Best time: 5.0000
Epoch: 099, Runtime 21.124792, Loss 2.062494, forward nfe 29084, backward nfe 0, Train: 0.1929, Val: 0.3691, Test: 0.3360, Best time: 6.0000
best val accuracy 0.369118 with test accuracy 0.336041 at epoch 99 and best time 6.000000
best_model.odeblock.t tensor([0., 6.])
Entropy Threshold: inf Test accuracy: 0.1065989847715736
Entropy Threshold: 2 Test accuracy: 0.1116751269035533
Entropy Threshold: 1.6 Test accuracy: 0.09090909090909091
Entropy Threshold: 1.5 Test accuracy: 0.14285714285714285
Entropy Threshold: 1.4 Test accuracy: 0.18181818181818182
Entropy Threshold: 1.3 Test accuracy: 0.14285714285714285
Entropy Threshold: 1.2 Test accuracy: 0.14285714285714285
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
