[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 5.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 29.094156, Loss 3.764642, forward nfe 76, backward nfe 0, Train: 0.1571, Val: 0.1522, Test: 0.1431, Best time: 1.0000
Epoch: 002, Runtime 41.483433, Loss 18.206999, forward nfe 372, backward nfe 0, Train: 0.2500, Val: 0.2000, Test: 0.2010, Best time: 4.0000
Epoch: 003, Runtime 17.675545, Loss 3.790834, forward nfe 668, backward nfe 0, Train: 0.2500, Val: 0.2000, Test: 0.2010, Best time: 18.2948
Epoch: 004, Runtime 17.644497, Loss 4.078377, forward nfe 964, backward nfe 0, Train: 0.2500, Val: 0.2000, Test: 0.2010, Best time: 18.2948
Epoch: 005, Runtime 19.113695, Loss 4.398933, forward nfe 1260, backward nfe 0, Train: 0.2500, Val: 0.2000, Test: 0.2010, Best time: 18.2948
Epoch: 006, Runtime 21.175124, Loss 4.355716, forward nfe 1556, backward nfe 0, Train: 0.2500, Val: 0.2000, Test: 0.2010, Best time: 18.2948
Epoch: 007, Runtime 22.189660, Loss 4.205871, forward nfe 1852, backward nfe 0, Train: 0.1929, Val: 0.2735, Test: 0.2355, Best time: 54.8843
Epoch: 008, Runtime 21.187859, Loss 3.715247, forward nfe 2148, backward nfe 0, Train: 0.1643, Val: 0.3081, Test: 0.2832, Best time: 54.0000
Epoch: 009, Runtime 21.527615, Loss 3.406825, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.3088, Test: 0.2873, Best time: 53.0000
Epoch: 010, Runtime 21.434083, Loss 3.294144, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3125, Test: 0.2853, Best time: 54.0000
Epoch: 011, Runtime 21.153172, Loss 3.308862, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3125, Test: 0.2853, Best time: 18.2948
Epoch: 012, Runtime 21.082740, Loss 3.090812, forward nfe 3332, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 28.0000
Epoch: 013, Runtime 20.981924, Loss 3.091370, forward nfe 3628, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 014, Runtime 20.403514, Loss 2.953945, forward nfe 3924, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 015, Runtime 20.222210, Loss 2.653907, forward nfe 4220, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 016, Runtime 20.544067, Loss 2.601382, forward nfe 4516, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 017, Runtime 20.969311, Loss 2.515659, forward nfe 4812, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 018, Runtime 21.903966, Loss 2.820147, forward nfe 5108, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 019, Runtime 21.942379, Loss 2.724020, forward nfe 5404, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 020, Runtime 22.232702, Loss 2.739370, forward nfe 5700, backward nfe 0, Train: 0.1714, Val: 0.3147, Test: 0.2893, Best time: 18.2948
Epoch: 021, Runtime 22.864648, Loss 2.633648, forward nfe 5996, backward nfe 0, Train: 0.1857, Val: 0.3154, Test: 0.2711, Best time: 46.0000
Epoch: 022, Runtime 18.547169, Loss 2.508369, forward nfe 6292, backward nfe 0, Train: 0.1857, Val: 0.3154, Test: 0.2711, Best time: 18.2948
Epoch: 023, Runtime 18.576648, Loss 2.626346, forward nfe 6588, backward nfe 0, Train: 0.1857, Val: 0.3154, Test: 0.2711, Best time: 18.2948
Epoch: 024, Runtime 19.252409, Loss 2.580122, forward nfe 6884, backward nfe 0, Train: 0.1857, Val: 0.3154, Test: 0.2711, Best time: 18.2948
Epoch: 025, Runtime 20.055925, Loss 2.787340, forward nfe 7180, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 48.0000
Epoch: 026, Runtime 18.131361, Loss 2.795859, forward nfe 7476, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 027, Runtime 18.530547, Loss 2.831150, forward nfe 7772, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 028, Runtime 19.034994, Loss 2.667982, forward nfe 8068, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 029, Runtime 19.542395, Loss 2.772102, forward nfe 8364, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 030, Runtime 18.610133, Loss 2.642396, forward nfe 8660, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 031, Runtime 18.931518, Loss 2.686273, forward nfe 8956, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 032, Runtime 19.738436, Loss 2.758037, forward nfe 9252, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 033, Runtime 20.067816, Loss 2.704573, forward nfe 9548, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 034, Runtime 20.314024, Loss 2.613987, forward nfe 9844, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 035, Runtime 21.054291, Loss 2.637568, forward nfe 10140, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 036, Runtime 21.090621, Loss 2.574027, forward nfe 10436, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 037, Runtime 21.317335, Loss 2.541422, forward nfe 10732, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 038, Runtime 21.904240, Loss 2.523021, forward nfe 11028, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 039, Runtime 22.243667, Loss 2.522122, forward nfe 11324, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 040, Runtime 22.348984, Loss 2.604565, forward nfe 11620, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 041, Runtime 22.784951, Loss 2.482144, forward nfe 11916, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 042, Runtime 23.002146, Loss 2.588364, forward nfe 12212, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 043, Runtime 23.324390, Loss 2.594708, forward nfe 12508, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 044, Runtime 23.794975, Loss 2.461090, forward nfe 12804, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 045, Runtime 23.724861, Loss 2.454597, forward nfe 13100, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 046, Runtime 23.480512, Loss 2.663743, forward nfe 13396, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 047, Runtime 25.555215, Loss 2.508005, forward nfe 13692, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 048, Runtime 25.727347, Loss 2.798126, forward nfe 13988, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 049, Runtime 25.832425, Loss 2.697629, forward nfe 14284, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 050, Runtime 26.387166, Loss 2.351159, forward nfe 14580, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 051, Runtime 26.297837, Loss 2.587215, forward nfe 14876, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 052, Runtime 26.565835, Loss 2.601113, forward nfe 15172, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 053, Runtime 26.801445, Loss 2.542798, forward nfe 15468, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 054, Runtime 26.860603, Loss 2.577761, forward nfe 15764, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 055, Runtime 26.953038, Loss 2.431079, forward nfe 16060, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 056, Runtime 27.243644, Loss 2.662833, forward nfe 16356, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 057, Runtime 27.006501, Loss 2.483921, forward nfe 16652, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 058, Runtime 24.292329, Loss 2.422344, forward nfe 16948, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 059, Runtime 18.258773, Loss 2.551677, forward nfe 17244, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 060, Runtime 18.424507, Loss 2.524763, forward nfe 17540, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 061, Runtime 18.938774, Loss 2.502997, forward nfe 17836, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 062, Runtime 19.653349, Loss 2.470536, forward nfe 18132, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 063, Runtime 19.953534, Loss 2.464161, forward nfe 18428, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 064, Runtime 20.462522, Loss 2.448993, forward nfe 18724, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 065, Runtime 21.290673, Loss 2.400529, forward nfe 19020, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 066, Runtime 21.513688, Loss 2.399639, forward nfe 19316, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 067, Runtime 21.640035, Loss 2.358953, forward nfe 19612, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 068, Runtime 22.351788, Loss 2.380590, forward nfe 19908, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 069, Runtime 22.604248, Loss 2.497491, forward nfe 20204, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 070, Runtime 22.732287, Loss 2.512756, forward nfe 20500, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 071, Runtime 23.363512, Loss 2.506161, forward nfe 20796, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 072, Runtime 23.635794, Loss 2.410327, forward nfe 21092, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 073, Runtime 22.470177, Loss 2.424605, forward nfe 21388, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 074, Runtime 22.684484, Loss 2.380003, forward nfe 21684, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 075, Runtime 22.576323, Loss 2.396389, forward nfe 21980, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 076, Runtime 22.674927, Loss 2.703055, forward nfe 22276, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 077, Runtime 23.003838, Loss 2.515985, forward nfe 22572, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 078, Runtime 22.928730, Loss 2.680044, forward nfe 22868, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 079, Runtime 22.873818, Loss 2.504375, forward nfe 23164, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 080, Runtime 23.268511, Loss 2.436859, forward nfe 23460, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 081, Runtime 23.164476, Loss 2.531121, forward nfe 23756, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 082, Runtime 23.402488, Loss 2.392950, forward nfe 24052, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 083, Runtime 23.356983, Loss 2.401267, forward nfe 24348, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 084, Runtime 23.733278, Loss 2.371035, forward nfe 24644, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 085, Runtime 23.500995, Loss 2.420418, forward nfe 24940, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 086, Runtime 23.402655, Loss 2.453921, forward nfe 25236, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 087, Runtime 23.621358, Loss 2.410811, forward nfe 25532, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 088, Runtime 23.874884, Loss 2.398063, forward nfe 25828, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 089, Runtime 21.287261, Loss 2.452575, forward nfe 26124, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 090, Runtime 16.277176, Loss 2.417730, forward nfe 26420, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 091, Runtime 16.578744, Loss 2.515644, forward nfe 26716, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 092, Runtime 17.117574, Loss 2.358525, forward nfe 27012, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 093, Runtime 17.159403, Loss 2.393033, forward nfe 27308, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 094, Runtime 17.722535, Loss 2.413889, forward nfe 27604, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 095, Runtime 18.461488, Loss 2.455742, forward nfe 27900, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 096, Runtime 18.925544, Loss 2.459264, forward nfe 28196, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 097, Runtime 19.072966, Loss 2.368608, forward nfe 28492, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 098, Runtime 19.564013, Loss 2.451206, forward nfe 28788, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
Epoch: 099, Runtime 19.860173, Loss 2.346103, forward nfe 29084, backward nfe 0, Train: 0.2000, Val: 0.3169, Test: 0.2701, Best time: 18.2948
best val accuracy 0.316912 with test accuracy 0.270051 at epoch 25 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.09949238578680203
Entropy Threshold: 2 Test accuracy: 0.09340101522842639
Entropy Threshold: 1.6 Test accuracy: 0.25
Entropy Threshold: 1.5 Test accuracy: 0.5
Entropy Threshold: 1.4 Test accuracy: 1.0
Entropy Threshold: 1.3 Test accuracy: 1.0
Entropy Threshold: 1.2 Test accuracy: 1.0
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: 1.0
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
