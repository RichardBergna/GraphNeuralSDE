[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 5.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 26.511910, Loss 4.715148, forward nfe 76, backward nfe 0, Train: 0.1357, Val: 0.3125, Test: 0.2832, Best time: 18.2948
Epoch: 002, Runtime 50.321284, Loss 21.712946, forward nfe 372, backward nfe 0, Train: 0.1357, Val: 0.3125, Test: 0.2832, Best time: 18.2948
Epoch: 003, Runtime 22.032622, Loss 3.955902, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 42.0000
Epoch: 004, Runtime 20.123221, Loss 4.288209, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 005, Runtime 21.850374, Loss 4.753592, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 006, Runtime 24.039672, Loss 5.130531, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 007, Runtime 26.900254, Loss 5.008348, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 008, Runtime 28.361155, Loss 4.742666, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 009, Runtime 29.910971, Loss 4.490855, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 010, Runtime 30.365186, Loss 3.939037, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 011, Runtime 30.300822, Loss 3.519302, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 012, Runtime 29.648436, Loss 3.174039, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 013, Runtime 30.433388, Loss 2.824336, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2832, Best time: 18.2948
Epoch: 014, Runtime 31.167554, Loss 2.954731, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 20.0000
Epoch: 015, Runtime 21.805594, Loss 3.058961, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 016, Runtime 23.128072, Loss 2.957337, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 017, Runtime 23.299984, Loss 2.928650, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 018, Runtime 23.785301, Loss 2.837294, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 019, Runtime 24.460847, Loss 2.782266, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 020, Runtime 25.263154, Loss 2.834079, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 021, Runtime 26.476325, Loss 2.848566, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 022, Runtime 27.651140, Loss 2.801436, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 023, Runtime 29.073101, Loss 2.940694, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 024, Runtime 30.154493, Loss 2.809134, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 025, Runtime 31.984769, Loss 2.644550, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 026, Runtime 32.663585, Loss 2.670176, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 027, Runtime 32.641681, Loss 2.699796, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 028, Runtime 32.754439, Loss 2.709146, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 029, Runtime 32.879616, Loss 2.641057, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 030, Runtime 33.004477, Loss 2.690670, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 031, Runtime 33.925865, Loss 2.718802, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 032, Runtime 32.894659, Loss 2.573920, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 033, Runtime 33.278769, Loss 2.760255, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 034, Runtime 34.003534, Loss 2.456181, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 035, Runtime 33.623832, Loss 2.817048, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 036, Runtime 34.428945, Loss 2.545049, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 037, Runtime 33.530362, Loss 2.728502, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 038, Runtime 34.258982, Loss 2.787252, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 039, Runtime 34.516534, Loss 2.571368, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 040, Runtime 30.032207, Loss 2.625401, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 041, Runtime 22.853585, Loss 2.552819, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 042, Runtime 23.569323, Loss 2.599810, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 043, Runtime 23.418300, Loss 2.560606, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 044, Runtime 24.384400, Loss 2.503495, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 045, Runtime 25.566895, Loss 2.539969, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 046, Runtime 24.140103, Loss 2.636898, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 047, Runtime 24.304204, Loss 2.563387, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 048, Runtime 24.514256, Loss 2.499572, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 049, Runtime 25.579710, Loss 2.513722, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 050, Runtime 26.695809, Loss 2.586128, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 051, Runtime 25.994237, Loss 2.538781, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 052, Runtime 26.403823, Loss 2.616641, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 053, Runtime 27.328823, Loss 2.487450, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 054, Runtime 27.423132, Loss 2.648878, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 055, Runtime 27.567765, Loss 2.501206, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 056, Runtime 28.056341, Loss 2.528020, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 057, Runtime 28.286461, Loss 2.568840, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 058, Runtime 28.549367, Loss 2.537591, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 059, Runtime 28.475474, Loss 2.466682, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 060, Runtime 28.338520, Loss 2.693289, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 061, Runtime 28.786355, Loss 2.226703, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 062, Runtime 29.399504, Loss 2.700113, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 063, Runtime 28.805342, Loss 2.391488, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 064, Runtime 29.097098, Loss 2.341451, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 065, Runtime 29.295862, Loss 2.553756, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 066, Runtime 29.411878, Loss 2.474336, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 067, Runtime 29.780778, Loss 2.588447, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 068, Runtime 26.247931, Loss 2.529015, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 069, Runtime 19.352160, Loss 2.550078, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 070, Runtime 20.253739, Loss 2.426821, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 071, Runtime 20.745892, Loss 2.517469, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 072, Runtime 21.139405, Loss 2.496320, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 073, Runtime 21.842136, Loss 2.548432, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 074, Runtime 22.081993, Loss 2.435972, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 075, Runtime 22.507874, Loss 2.562423, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 076, Runtime 23.432679, Loss 2.384970, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 077, Runtime 23.759915, Loss 2.496969, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 078, Runtime 24.459811, Loss 2.513593, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 079, Runtime 25.096415, Loss 2.454917, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 080, Runtime 25.307827, Loss 2.467191, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 081, Runtime 25.427524, Loss 2.419681, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 082, Runtime 25.908734, Loss 2.428166, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 083, Runtime 26.170614, Loss 2.437217, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 084, Runtime 26.597874, Loss 2.405413, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 085, Runtime 26.850132, Loss 2.451122, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 086, Runtime 26.034847, Loss 2.432038, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 087, Runtime 25.475682, Loss 2.601954, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 088, Runtime 25.925705, Loss 2.470943, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 089, Runtime 25.719970, Loss 2.333931, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 090, Runtime 25.501123, Loss 2.553704, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 091, Runtime 24.931128, Loss 2.524905, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 092, Runtime 25.135469, Loss 2.427416, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 093, Runtime 25.270161, Loss 2.556718, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 094, Runtime 25.603363, Loss 2.481231, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 095, Runtime 25.653101, Loss 2.482841, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 096, Runtime 25.924233, Loss 2.452406, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 097, Runtime 26.008203, Loss 2.448582, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 098, Runtime 26.093920, Loss 2.417089, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
Epoch: 099, Runtime 26.281228, Loss 2.414288, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 18.2948
best val accuracy 0.314706 with test accuracy 0.283249 at epoch 14 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1532994923857868
Entropy Threshold: 2 Test accuracy: 0.1532994923857868
Entropy Threshold: 1.6 Test accuracy: 0.1532994923857868
Entropy Threshold: 1.5 Test accuracy: 0.1532994923857868
Entropy Threshold: 1.4 Test accuracy: 0.15345528455284552
Entropy Threshold: 1.3 Test accuracy: 0.1535312180143296
Entropy Threshold: 1.2 Test accuracy: 0.15392561983471073
Entropy Threshold: 1.1 Test accuracy: 0.1529535864978903
Entropy Threshold: 0.9 Test accuracy: 0.1492361927144536
Entropy Threshold: 0.8 Test accuracy: 0.14987405541561713
Entropy Threshold: 0.7 Test accuracy: 0.15
Entropy Threshold: 0.6 Test accuracy: 0.15755627009646303
Entropy Threshold: 0.5 Test accuracy: 0.15700934579439252
Entropy Threshold: 0.4 Test accuracy: 0.17045454545454544
Entropy Threshold: 0.3 Test accuracy: 0.1536144578313253
Entropy Threshold: 0.2 Test accuracy: 0.1956521739130435
Entropy Threshold: 0.1 Test accuracy: 0.19285714285714287
