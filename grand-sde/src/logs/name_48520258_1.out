[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 6.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 29.931471, Loss 3.744597, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 2.0000
Epoch: 002, Runtime 96.195666, Loss 144.778915, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 003, Runtime 22.651330, Loss 3.098176, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 004, Runtime 21.494226, Loss 3.930602, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 005, Runtime 23.590985, Loss 5.141314, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 006, Runtime 26.478052, Loss 6.267990, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 007, Runtime 30.001003, Loss 7.446643, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 008, Runtime 33.763574, Loss 8.487098, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 009, Runtime 38.330415, Loss 8.902652, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 010, Runtime 40.485781, Loss 9.471962, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 011, Runtime 42.038218, Loss 8.382163, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.2949, Test: 0.3147, Best time: 18.2948
Epoch: 012, Runtime 42.988267, Loss 7.833069, forward nfe 3332, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 13.0000
Epoch: 013, Runtime 30.804389, Loss 6.385337, forward nfe 3628, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 014, Runtime 29.885070, Loss 5.156426, forward nfe 3924, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 015, Runtime 30.809583, Loss 4.259740, forward nfe 4220, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 016, Runtime 31.052645, Loss 3.467132, forward nfe 4516, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 017, Runtime 32.554832, Loss 2.955461, forward nfe 4812, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 018, Runtime 31.252518, Loss 2.802731, forward nfe 5108, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 019, Runtime 30.888769, Loss 2.989434, forward nfe 5404, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 020, Runtime 31.002489, Loss 3.140314, forward nfe 5700, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 021, Runtime 31.222015, Loss 3.342005, forward nfe 5996, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 022, Runtime 30.740597, Loss 3.309696, forward nfe 6292, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 023, Runtime 30.936475, Loss 3.386399, forward nfe 6588, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 024, Runtime 29.567920, Loss 3.477236, forward nfe 6884, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 025, Runtime 30.506731, Loss 3.563612, forward nfe 7180, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 026, Runtime 29.874744, Loss 3.481781, forward nfe 7476, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 027, Runtime 30.894411, Loss 3.162623, forward nfe 7772, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 028, Runtime 31.093803, Loss 3.288157, forward nfe 8068, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 029, Runtime 30.713440, Loss 3.309144, forward nfe 8364, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 030, Runtime 32.248748, Loss 3.183350, forward nfe 8660, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 031, Runtime 33.103570, Loss 3.075603, forward nfe 8956, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 032, Runtime 33.290514, Loss 2.842228, forward nfe 9252, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 033, Runtime 33.869588, Loss 2.852529, forward nfe 9548, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 034, Runtime 34.317565, Loss 2.921447, forward nfe 9844, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 035, Runtime 34.263583, Loss 2.830189, forward nfe 10140, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 036, Runtime 34.499610, Loss 3.225606, forward nfe 10436, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 037, Runtime 23.519415, Loss 2.817928, forward nfe 10732, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 038, Runtime 22.843626, Loss 2.857693, forward nfe 11028, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 039, Runtime 23.150414, Loss 2.681409, forward nfe 11324, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 040, Runtime 23.762108, Loss 2.816844, forward nfe 11620, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 041, Runtime 25.060305, Loss 2.526081, forward nfe 11916, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 042, Runtime 25.994668, Loss 2.723382, forward nfe 12212, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 043, Runtime 26.639466, Loss 2.677326, forward nfe 12508, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 044, Runtime 27.354136, Loss 2.707597, forward nfe 12804, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 045, Runtime 28.193432, Loss 2.839414, forward nfe 13100, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 046, Runtime 29.580117, Loss 2.720964, forward nfe 13396, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 047, Runtime 30.623542, Loss 2.642652, forward nfe 13692, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 048, Runtime 31.375115, Loss 2.851023, forward nfe 13988, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 049, Runtime 31.137779, Loss 2.722007, forward nfe 14284, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 050, Runtime 31.518609, Loss 2.794323, forward nfe 14580, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 051, Runtime 31.343685, Loss 2.817217, forward nfe 14876, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 052, Runtime 32.075278, Loss 2.577484, forward nfe 15172, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 053, Runtime 32.385517, Loss 2.853350, forward nfe 15468, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 054, Runtime 32.984915, Loss 2.662823, forward nfe 15764, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 055, Runtime 33.258178, Loss 2.738754, forward nfe 16060, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 056, Runtime 33.307207, Loss 2.710984, forward nfe 16356, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 057, Runtime 30.480167, Loss 2.411007, forward nfe 16652, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 058, Runtime 21.773748, Loss 2.422820, forward nfe 16948, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 059, Runtime 22.186233, Loss 2.920119, forward nfe 17244, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 060, Runtime 22.247927, Loss 2.549310, forward nfe 17540, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 061, Runtime 23.112442, Loss 2.623706, forward nfe 17836, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 062, Runtime 23.678916, Loss 2.567638, forward nfe 18132, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 063, Runtime 24.596431, Loss 2.670538, forward nfe 18428, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 064, Runtime 25.474312, Loss 2.696061, forward nfe 18724, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 065, Runtime 26.592835, Loss 2.489402, forward nfe 19020, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 066, Runtime 27.273337, Loss 2.837719, forward nfe 19316, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 067, Runtime 28.286786, Loss 2.657471, forward nfe 19612, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 068, Runtime 29.160647, Loss 2.648355, forward nfe 19908, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 069, Runtime 29.338636, Loss 2.803210, forward nfe 20204, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 070, Runtime 30.272630, Loss 2.604257, forward nfe 20500, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 071, Runtime 29.892462, Loss 2.937112, forward nfe 20796, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 072, Runtime 30.063826, Loss 2.781210, forward nfe 21092, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 073, Runtime 30.397746, Loss 2.575897, forward nfe 21388, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 074, Runtime 30.630502, Loss 2.678827, forward nfe 21684, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 075, Runtime 31.412953, Loss 2.794677, forward nfe 21980, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 076, Runtime 31.882473, Loss 2.647602, forward nfe 22276, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 077, Runtime 31.928065, Loss 2.631607, forward nfe 22572, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 078, Runtime 31.963252, Loss 2.455948, forward nfe 22868, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 079, Runtime 31.959985, Loss 2.603989, forward nfe 23164, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 080, Runtime 29.116855, Loss 2.608628, forward nfe 23460, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 081, Runtime 21.353825, Loss 2.680564, forward nfe 23756, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 082, Runtime 22.307720, Loss 2.673384, forward nfe 24052, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 083, Runtime 22.243064, Loss 2.625982, forward nfe 24348, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 084, Runtime 22.521352, Loss 2.608124, forward nfe 24644, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 085, Runtime 23.423428, Loss 2.622006, forward nfe 24940, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 086, Runtime 24.092340, Loss 2.762012, forward nfe 25236, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 087, Runtime 25.146495, Loss 2.537021, forward nfe 25532, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 088, Runtime 26.082598, Loss 2.537291, forward nfe 25828, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 089, Runtime 25.946682, Loss 2.573421, forward nfe 26124, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 090, Runtime 26.180560, Loss 2.656501, forward nfe 26420, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 091, Runtime 27.286710, Loss 2.720578, forward nfe 26716, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 092, Runtime 27.649801, Loss 2.485766, forward nfe 27012, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 093, Runtime 28.606171, Loss 2.797621, forward nfe 27308, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 094, Runtime 29.113453, Loss 2.313123, forward nfe 27604, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 095, Runtime 29.548556, Loss 2.609387, forward nfe 27900, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 096, Runtime 29.932835, Loss 2.739895, forward nfe 28196, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 097, Runtime 29.560768, Loss 2.776084, forward nfe 28492, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 098, Runtime 30.680034, Loss 2.776640, forward nfe 28788, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
Epoch: 099, Runtime 31.648225, Loss 2.642870, forward nfe 29084, backward nfe 0, Train: 0.1643, Val: 0.3022, Test: 0.3056, Best time: 18.2948
best val accuracy 0.302206 with test accuracy 0.305584 at epoch 12 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1532994923857868
Entropy Threshold: 2 Test accuracy: 0.1532994923857868
Entropy Threshold: 1.6 Test accuracy: 0.15431472081218275
Entropy Threshold: 1.5 Test accuracy: 0.1532994923857868
Entropy Threshold: 1.4 Test accuracy: 0.15431472081218275
Entropy Threshold: 1.3 Test accuracy: 0.15431472081218275
Entropy Threshold: 1.2 Test accuracy: 0.15219611848825332
Entropy Threshold: 1.1 Test accuracy: 0.15588547189819724
Entropy Threshold: 0.9 Test accuracy: 0.16488222698072805
Entropy Threshold: 0.8 Test accuracy: 0.13978494623655913
Entropy Threshold: 0.7 Test accuracy: 0.1320754716981132
Entropy Threshold: 0.6 Test accuracy: 0.23076923076923078
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
