[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 4.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 20.932024, Loss 3.149630, forward nfe 76, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 50.0000
Epoch: 002, Runtime 34.229206, Loss 13.032520, forward nfe 372, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 003, Runtime 17.870981, Loss 3.750669, forward nfe 668, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 004, Runtime 18.504868, Loss 4.043835, forward nfe 964, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 005, Runtime 19.873996, Loss 4.115606, forward nfe 1260, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 006, Runtime 22.021966, Loss 3.738020, forward nfe 1556, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 007, Runtime 24.481252, Loss 3.387287, forward nfe 1852, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 008, Runtime 25.773298, Loss 2.886339, forward nfe 2148, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 009, Runtime 25.766210, Loss 2.914877, forward nfe 2444, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 010, Runtime 25.934935, Loss 2.900936, forward nfe 2740, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 011, Runtime 25.944812, Loss 2.544663, forward nfe 3036, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 012, Runtime 26.524192, Loss 2.591050, forward nfe 3332, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 013, Runtime 26.684123, Loss 2.666215, forward nfe 3628, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 014, Runtime 26.744864, Loss 2.679870, forward nfe 3924, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 015, Runtime 26.632945, Loss 2.726257, forward nfe 4220, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 016, Runtime 26.965624, Loss 2.767840, forward nfe 4516, backward nfe 0, Train: 0.2429, Val: 0.3787, Test: 0.3919, Best time: 18.2948
Epoch: 017, Runtime 27.229229, Loss 2.451075, forward nfe 4812, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 1.0000
Epoch: 018, Runtime 17.831957, Loss 2.772323, forward nfe 5108, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 019, Runtime 18.117047, Loss 2.697031, forward nfe 5404, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 020, Runtime 18.390246, Loss 2.507823, forward nfe 5700, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 021, Runtime 19.082179, Loss 2.556762, forward nfe 5996, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 022, Runtime 19.375091, Loss 2.642216, forward nfe 6292, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 023, Runtime 20.011560, Loss 2.602989, forward nfe 6588, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 024, Runtime 20.788594, Loss 2.643219, forward nfe 6884, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 025, Runtime 21.196008, Loss 2.727187, forward nfe 7180, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 026, Runtime 21.649644, Loss 2.537855, forward nfe 7476, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 027, Runtime 23.566275, Loss 2.361838, forward nfe 7772, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 028, Runtime 23.007425, Loss 2.534893, forward nfe 8068, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 029, Runtime 23.316412, Loss 2.566233, forward nfe 8364, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 030, Runtime 23.722407, Loss 2.467963, forward nfe 8660, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 031, Runtime 24.246549, Loss 2.493665, forward nfe 8956, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 032, Runtime 24.316472, Loss 2.510896, forward nfe 9252, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 033, Runtime 25.229605, Loss 2.394398, forward nfe 9548, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 034, Runtime 25.452293, Loss 2.419908, forward nfe 9844, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 035, Runtime 25.893429, Loss 2.581151, forward nfe 10140, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 036, Runtime 26.573709, Loss 2.397890, forward nfe 10436, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 037, Runtime 26.894140, Loss 2.377500, forward nfe 10732, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 038, Runtime 26.701883, Loss 2.395072, forward nfe 11028, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 039, Runtime 26.945139, Loss 2.330901, forward nfe 11324, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 040, Runtime 27.284712, Loss 2.429045, forward nfe 11620, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 041, Runtime 27.776037, Loss 2.442609, forward nfe 11916, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 042, Runtime 28.818455, Loss 2.398248, forward nfe 12212, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 043, Runtime 30.455161, Loss 2.402744, forward nfe 12508, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 044, Runtime 30.613616, Loss 2.414204, forward nfe 12804, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 045, Runtime 31.235407, Loss 2.370272, forward nfe 13100, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 046, Runtime 31.249357, Loss 2.327946, forward nfe 13396, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 047, Runtime 31.844110, Loss 2.358924, forward nfe 13692, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 048, Runtime 28.314425, Loss 2.285526, forward nfe 13988, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 049, Runtime 21.560582, Loss 2.367049, forward nfe 14284, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 050, Runtime 21.711319, Loss 2.342042, forward nfe 14580, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 051, Runtime 22.053998, Loss 2.204281, forward nfe 14876, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 052, Runtime 22.687415, Loss 2.305864, forward nfe 15172, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 053, Runtime 24.196693, Loss 2.216248, forward nfe 15468, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 054, Runtime 24.332051, Loss 2.327509, forward nfe 15764, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 055, Runtime 24.768756, Loss 2.370046, forward nfe 16060, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 056, Runtime 25.238725, Loss 2.381933, forward nfe 16356, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 057, Runtime 26.440284, Loss 2.248791, forward nfe 16652, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 058, Runtime 26.566299, Loss 2.449934, forward nfe 16948, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 059, Runtime 27.001309, Loss 2.259523, forward nfe 17244, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 060, Runtime 27.251985, Loss 2.135973, forward nfe 17540, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 061, Runtime 28.653780, Loss 2.162471, forward nfe 17836, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 062, Runtime 29.578716, Loss 2.201844, forward nfe 18132, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 063, Runtime 30.259706, Loss 2.319167, forward nfe 18428, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 064, Runtime 30.917482, Loss 2.302177, forward nfe 18724, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 065, Runtime 30.345809, Loss 2.214931, forward nfe 19020, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 066, Runtime 30.550340, Loss 2.350307, forward nfe 19316, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 067, Runtime 31.054363, Loss 2.252002, forward nfe 19612, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 068, Runtime 32.391275, Loss 2.286143, forward nfe 19908, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 069, Runtime 32.513878, Loss 2.257791, forward nfe 20204, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 070, Runtime 33.054200, Loss 2.275517, forward nfe 20500, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 071, Runtime 34.059278, Loss 2.272971, forward nfe 20796, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 072, Runtime 34.290767, Loss 2.225603, forward nfe 21092, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 073, Runtime 34.938704, Loss 2.244166, forward nfe 21388, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 074, Runtime 35.673667, Loss 2.200040, forward nfe 21684, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 075, Runtime 28.378714, Loss 2.380027, forward nfe 21980, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 076, Runtime 23.397567, Loss 2.240779, forward nfe 22276, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 077, Runtime 25.082105, Loss 2.277261, forward nfe 22572, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 078, Runtime 25.993767, Loss 2.108600, forward nfe 22868, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 079, Runtime 27.123726, Loss 2.195259, forward nfe 23164, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 080, Runtime 28.598692, Loss 2.153932, forward nfe 23460, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 081, Runtime 29.987669, Loss 2.154845, forward nfe 23756, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 082, Runtime 31.047260, Loss 2.254148, forward nfe 24052, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 083, Runtime 32.079926, Loss 2.169128, forward nfe 24348, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 084, Runtime 31.821739, Loss 2.265643, forward nfe 24644, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 085, Runtime 33.035203, Loss 2.120127, forward nfe 24940, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 086, Runtime 33.282504, Loss 2.200456, forward nfe 25236, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 087, Runtime 34.028012, Loss 2.143078, forward nfe 25532, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 088, Runtime 34.785468, Loss 2.200636, forward nfe 25828, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 089, Runtime 35.484165, Loss 2.130797, forward nfe 26124, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 090, Runtime 36.435286, Loss 2.261939, forward nfe 26420, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 091, Runtime 37.356895, Loss 2.172428, forward nfe 26716, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 092, Runtime 38.279769, Loss 2.214415, forward nfe 27012, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 093, Runtime 34.283535, Loss 2.245714, forward nfe 27308, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 094, Runtime 25.084308, Loss 2.088777, forward nfe 27604, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 095, Runtime 25.302975, Loss 2.124922, forward nfe 27900, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 096, Runtime 25.815598, Loss 2.160630, forward nfe 28196, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 097, Runtime 26.787705, Loss 2.131153, forward nfe 28492, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 098, Runtime 28.406485, Loss 2.223310, forward nfe 28788, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
Epoch: 099, Runtime 29.395018, Loss 2.166981, forward nfe 29084, backward nfe 0, Train: 0.2643, Val: 0.3846, Test: 0.3970, Best time: 18.2948
best val accuracy 0.384559 with test accuracy 0.396954 at epoch 17 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.23553299492385787
Entropy Threshold: 2 Test accuracy: 0.25583756345177666
Entropy Threshold: 1.6 Test accuracy: 0.30952380952380953
Entropy Threshold: 1.5 Test accuracy: 0.3333333333333333
Entropy Threshold: 1.4 Test accuracy: None
Entropy Threshold: 1.3 Test accuracy: None
Entropy Threshold: 1.2 Test accuracy: None
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
