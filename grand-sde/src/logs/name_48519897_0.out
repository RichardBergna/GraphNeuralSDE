[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.01
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 5.141409, Loss 1.956529, forward nfe 76, backward nfe 0, Train: 0.5429, Val: 0.3882, Test: 0.3827, Best time: 1.0000
Epoch: 002, Runtime 4.637585, Loss 1.880437, forward nfe 372, backward nfe 0, Train: 0.7714, Val: 0.5596, Test: 0.5756, Best time: 1.0000
Epoch: 003, Runtime 5.002906, Loss 1.732316, forward nfe 668, backward nfe 0, Train: 0.8571, Val: 0.7007, Test: 0.7168, Best time: 7.0000
Epoch: 004, Runtime 5.035224, Loss 1.490965, forward nfe 964, backward nfe 0, Train: 0.8714, Val: 0.7618, Test: 0.7777, Best time: 16.0000
Epoch: 005, Runtime 5.168669, Loss 1.188365, forward nfe 1260, backward nfe 0, Train: 0.9143, Val: 0.8007, Test: 0.8112, Best time: 11.0000
Epoch: 006, Runtime 4.896612, Loss 0.887048, forward nfe 1556, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8234, Best time: 6.0000
Epoch: 007, Runtime 5.091385, Loss 0.631680, forward nfe 1852, backward nfe 0, Train: 0.9571, Val: 0.8412, Test: 0.8376, Best time: 11.0000
Epoch: 008, Runtime 4.753829, Loss 0.443150, forward nfe 2148, backward nfe 0, Train: 0.9571, Val: 0.8412, Test: 0.8376, Best time: 18.2948
Epoch: 009, Runtime 4.750326, Loss 0.332752, forward nfe 2444, backward nfe 0, Train: 0.9571, Val: 0.8412, Test: 0.8376, Best time: 18.2948
Epoch: 010, Runtime 4.833707, Loss 0.268894, forward nfe 2740, backward nfe 0, Train: 0.9857, Val: 0.8419, Test: 0.8355, Best time: 32.0000
Epoch: 011, Runtime 5.091021, Loss 0.211926, forward nfe 3036, backward nfe 0, Train: 0.9857, Val: 0.8471, Test: 0.8437, Best time: 17.0000
Epoch: 012, Runtime 4.896595, Loss 0.182162, forward nfe 3332, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 9.0000
Epoch: 013, Runtime 4.692701, Loss 0.140864, forward nfe 3628, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 014, Runtime 4.748038, Loss 0.167569, forward nfe 3924, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 015, Runtime 4.784525, Loss 0.178493, forward nfe 4220, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 016, Runtime 4.907506, Loss 0.161842, forward nfe 4516, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 017, Runtime 4.901177, Loss 0.167337, forward nfe 4812, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 018, Runtime 4.913574, Loss 0.129522, forward nfe 5108, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 019, Runtime 4.917621, Loss 0.158581, forward nfe 5404, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 020, Runtime 5.019683, Loss 0.153540, forward nfe 5700, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 021, Runtime 4.922013, Loss 0.196286, forward nfe 5996, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 022, Runtime 4.925867, Loss 0.206403, forward nfe 6292, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 023, Runtime 4.768101, Loss 0.152495, forward nfe 6588, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 024, Runtime 4.804541, Loss 0.174022, forward nfe 6884, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 025, Runtime 4.679698, Loss 0.139596, forward nfe 7180, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 026, Runtime 4.690018, Loss 0.187975, forward nfe 7476, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 027, Runtime 4.807946, Loss 0.175477, forward nfe 7772, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 028, Runtime 4.905798, Loss 0.155973, forward nfe 8068, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 029, Runtime 4.834716, Loss 0.152911, forward nfe 8364, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 030, Runtime 4.858817, Loss 0.121554, forward nfe 8660, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 031, Runtime 5.003607, Loss 0.138839, forward nfe 8956, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 032, Runtime 4.980880, Loss 0.138085, forward nfe 9252, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 033, Runtime 4.903026, Loss 0.136333, forward nfe 9548, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 034, Runtime 4.951260, Loss 0.127770, forward nfe 9844, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 035, Runtime 4.765418, Loss 0.124324, forward nfe 10140, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 036, Runtime 4.676046, Loss 0.110710, forward nfe 10436, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 037, Runtime 4.707646, Loss 0.120409, forward nfe 10732, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 038, Runtime 4.733146, Loss 0.124336, forward nfe 11028, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 039, Runtime 4.732834, Loss 0.139054, forward nfe 11324, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 040, Runtime 4.764947, Loss 0.117016, forward nfe 11620, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 041, Runtime 4.858083, Loss 0.126355, forward nfe 11916, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 042, Runtime 4.807503, Loss 0.133421, forward nfe 12212, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 043, Runtime 4.860480, Loss 0.114397, forward nfe 12508, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 044, Runtime 4.884243, Loss 0.102460, forward nfe 12804, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 045, Runtime 4.959478, Loss 0.132046, forward nfe 13100, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 046, Runtime 4.918775, Loss 0.124256, forward nfe 13396, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 047, Runtime 4.729361, Loss 0.121608, forward nfe 13692, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 048, Runtime 4.705766, Loss 0.118648, forward nfe 13988, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 049, Runtime 4.712232, Loss 0.126069, forward nfe 14284, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 050, Runtime 4.775289, Loss 0.115931, forward nfe 14580, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 051, Runtime 4.750516, Loss 0.154685, forward nfe 14876, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 052, Runtime 4.708023, Loss 0.120641, forward nfe 15172, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 053, Runtime 4.845333, Loss 0.121832, forward nfe 15468, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 054, Runtime 4.864339, Loss 0.100784, forward nfe 15764, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 055, Runtime 4.820884, Loss 0.201656, forward nfe 16060, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 056, Runtime 4.865102, Loss 0.109112, forward nfe 16356, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 057, Runtime 4.920832, Loss 0.097924, forward nfe 16652, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 058, Runtime 4.846670, Loss 0.114660, forward nfe 16948, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 059, Runtime 4.689403, Loss 0.085708, forward nfe 17244, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 060, Runtime 4.700161, Loss 0.102313, forward nfe 17540, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 061, Runtime 4.694453, Loss 0.140739, forward nfe 17836, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 062, Runtime 4.699706, Loss 0.094631, forward nfe 18132, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 063, Runtime 4.744408, Loss 0.106559, forward nfe 18428, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 064, Runtime 4.813918, Loss 0.130483, forward nfe 18724, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 065, Runtime 4.804147, Loss 0.136952, forward nfe 19020, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 066, Runtime 4.802208, Loss 0.112562, forward nfe 19316, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 067, Runtime 4.800029, Loss 0.077827, forward nfe 19612, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 068, Runtime 4.805995, Loss 0.114577, forward nfe 19908, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 069, Runtime 4.873952, Loss 0.102948, forward nfe 20204, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 070, Runtime 4.890170, Loss 0.109991, forward nfe 20500, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 071, Runtime 4.714864, Loss 0.097700, forward nfe 20796, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 072, Runtime 4.642434, Loss 0.130189, forward nfe 21092, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 073, Runtime 4.664714, Loss 0.099511, forward nfe 21388, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 074, Runtime 4.702614, Loss 0.091163, forward nfe 21684, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 075, Runtime 4.753721, Loss 0.083010, forward nfe 21980, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 076, Runtime 4.805659, Loss 0.108969, forward nfe 22276, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 077, Runtime 4.750852, Loss 0.106911, forward nfe 22572, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 078, Runtime 4.763786, Loss 0.103956, forward nfe 22868, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 079, Runtime 4.818432, Loss 0.069726, forward nfe 23164, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 080, Runtime 4.845464, Loss 0.082703, forward nfe 23460, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 081, Runtime 4.882438, Loss 0.086842, forward nfe 23756, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 082, Runtime 4.744162, Loss 0.089246, forward nfe 24052, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 083, Runtime 4.645430, Loss 0.096443, forward nfe 24348, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 084, Runtime 4.681123, Loss 0.065394, forward nfe 24644, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 085, Runtime 4.731530, Loss 0.105391, forward nfe 24940, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 086, Runtime 4.714337, Loss 0.066579, forward nfe 25236, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 087, Runtime 4.655376, Loss 0.094857, forward nfe 25532, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 088, Runtime 4.674420, Loss 0.068716, forward nfe 25828, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 089, Runtime 4.794141, Loss 0.080941, forward nfe 26124, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 090, Runtime 4.770758, Loss 0.081469, forward nfe 26420, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 091, Runtime 4.732162, Loss 0.081731, forward nfe 26716, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 092, Runtime 4.694860, Loss 0.107259, forward nfe 27012, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 093, Runtime 4.769563, Loss 0.126096, forward nfe 27308, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 094, Runtime 4.890669, Loss 0.086807, forward nfe 27604, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 095, Runtime 4.768662, Loss 0.095440, forward nfe 27900, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 096, Runtime 4.613304, Loss 0.119716, forward nfe 28196, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 097, Runtime 4.630862, Loss 0.130925, forward nfe 28492, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 098, Runtime 4.624659, Loss 0.078515, forward nfe 28788, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
Epoch: 099, Runtime 4.717078, Loss 0.133465, forward nfe 29084, backward nfe 0, Train: 0.9857, Val: 0.8507, Test: 0.8426, Best time: 18.2948
best val accuracy 0.850735 with test accuracy 0.842640 at epoch 12 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8324873096446701
Entropy Threshold: 2 Test accuracy: 0.8314720812182741
Entropy Threshold: 1.6 Test accuracy: 0.8324873096446701
Entropy Threshold: 1.5 Test accuracy: 0.8324873096446701
Entropy Threshold: 1.4 Test accuracy: 0.8313008130081301
Entropy Threshold: 1.3 Test accuracy: 0.8340122199592668
Entropy Threshold: 1.2 Test accuracy: 0.8346938775510204
Entropy Threshold: 1.1 Test accuracy: 0.8395061728395061
Entropy Threshold: 0.9 Test accuracy: 0.8481012658227848
Entropy Threshold: 0.8 Test accuracy: 0.8680479825517994
Entropy Threshold: 0.7 Test accuracy: 0.8808172531214529
Entropy Threshold: 0.6 Test accuracy: 0.8923076923076924
Entropy Threshold: 0.5 Test accuracy: 0.9016990291262136
Entropy Threshold: 0.4 Test accuracy: 0.9081761006289308
Entropy Threshold: 0.3 Test accuracy: 0.9187418086500655
Entropy Threshold: 0.2 Test accuracy: 0.9311797752808989
Entropy Threshold: 0.1 Test accuracy: 0.9422492401215805
