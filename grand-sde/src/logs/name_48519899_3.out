[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.1
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.596163, Loss 1.964359, forward nfe 76, backward nfe 0, Train: 0.4429, Val: 0.3147, Test: 0.3046, Best time: 3.0000
Epoch: 002, Runtime 14.378878, Loss 1.925226, forward nfe 372, backward nfe 0, Train: 0.6214, Val: 0.4588, Test: 0.5025, Best time: 4.0000
Epoch: 003, Runtime 14.083806, Loss 1.765282, forward nfe 668, backward nfe 0, Train: 0.8000, Val: 0.5794, Test: 0.6010, Best time: 2.0000
Epoch: 004, Runtime 14.116686, Loss 1.579095, forward nfe 964, backward nfe 0, Train: 0.8643, Val: 0.6324, Test: 0.6579, Best time: 5.0000
Epoch: 005, Runtime 14.378519, Loss 1.364225, forward nfe 1260, backward nfe 0, Train: 0.8929, Val: 0.7132, Test: 0.7188, Best time: 8.0000
Epoch: 006, Runtime 14.375315, Loss 1.078985, forward nfe 1556, backward nfe 0, Train: 0.9143, Val: 0.7588, Test: 0.7614, Best time: 7.0000
Epoch: 007, Runtime 14.119501, Loss 0.835961, forward nfe 1852, backward nfe 0, Train: 0.9071, Val: 0.7794, Test: 0.7706, Best time: 18.2948
Epoch: 008, Runtime 14.398135, Loss 0.606138, forward nfe 2148, backward nfe 0, Train: 0.9500, Val: 0.8029, Test: 0.8081, Best time: 10.0000
Epoch: 009, Runtime 14.441828, Loss 0.421390, forward nfe 2444, backward nfe 0, Train: 0.9643, Val: 0.8287, Test: 0.8234, Best time: 7.0000
Epoch: 010, Runtime 14.183098, Loss 0.341934, forward nfe 2740, backward nfe 0, Train: 0.9286, Val: 0.8346, Test: 0.8345, Best time: 54.0000
Epoch: 011, Runtime 14.236576, Loss 0.272522, forward nfe 3036, backward nfe 0, Train: 0.9714, Val: 0.8368, Test: 0.8416, Best time: 18.0000
Epoch: 012, Runtime 14.123716, Loss 0.226943, forward nfe 3332, backward nfe 0, Train: 0.9714, Val: 0.8390, Test: 0.8386, Best time: 14.0000
Epoch: 013, Runtime 14.253337, Loss 0.227741, forward nfe 3628, backward nfe 0, Train: 0.9714, Val: 0.8434, Test: 0.8457, Best time: 21.0000
Epoch: 014, Runtime 14.034226, Loss 0.191800, forward nfe 3924, backward nfe 0, Train: 0.9786, Val: 0.8471, Test: 0.8497, Best time: 16.0000
Epoch: 015, Runtime 14.031782, Loss 0.180349, forward nfe 4220, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 30.0000
Epoch: 016, Runtime 13.795819, Loss 0.192999, forward nfe 4516, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 18.2948
Epoch: 017, Runtime 14.108559, Loss 0.168864, forward nfe 4812, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 18.2948
Epoch: 018, Runtime 14.639872, Loss 0.164245, forward nfe 5108, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 18.2948
Epoch: 019, Runtime 14.303643, Loss 0.192165, forward nfe 5404, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 18.2948
Epoch: 020, Runtime 14.332785, Loss 0.156679, forward nfe 5700, backward nfe 0, Train: 0.9643, Val: 0.8493, Test: 0.8487, Best time: 18.2948
Epoch: 021, Runtime 14.959950, Loss 0.205610, forward nfe 5996, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 38.0000
Epoch: 022, Runtime 13.679895, Loss 0.195346, forward nfe 6292, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 023, Runtime 14.054501, Loss 0.208810, forward nfe 6588, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 024, Runtime 14.557934, Loss 0.202946, forward nfe 6884, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 025, Runtime 14.118701, Loss 0.199891, forward nfe 7180, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 026, Runtime 14.138785, Loss 0.233497, forward nfe 7476, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 027, Runtime 14.574153, Loss 0.197214, forward nfe 7772, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 028, Runtime 14.868268, Loss 0.202695, forward nfe 8068, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 029, Runtime 14.480134, Loss 0.166520, forward nfe 8364, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 030, Runtime 14.548356, Loss 0.179456, forward nfe 8660, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 031, Runtime 14.962538, Loss 0.181764, forward nfe 8956, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 032, Runtime 15.186218, Loss 0.173588, forward nfe 9252, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 033, Runtime 14.871712, Loss 0.182977, forward nfe 9548, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 034, Runtime 14.660057, Loss 0.142832, forward nfe 9844, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 035, Runtime 15.097666, Loss 0.139253, forward nfe 10140, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 036, Runtime 15.287056, Loss 0.122503, forward nfe 10436, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 037, Runtime 15.215247, Loss 0.143336, forward nfe 10732, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 038, Runtime 15.001652, Loss 0.130946, forward nfe 11028, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 039, Runtime 15.211530, Loss 0.176015, forward nfe 11324, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 040, Runtime 15.531874, Loss 0.133107, forward nfe 11620, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 041, Runtime 15.366148, Loss 0.135938, forward nfe 11916, backward nfe 0, Train: 0.9786, Val: 0.8529, Test: 0.8619, Best time: 18.2948
Epoch: 042, Runtime 15.776119, Loss 0.149168, forward nfe 12212, backward nfe 0, Train: 0.9857, Val: 0.8588, Test: 0.8497, Best time: 28.0000
Epoch: 043, Runtime 13.565245, Loss 0.106566, forward nfe 12508, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 38.0000
Epoch: 044, Runtime 13.427466, Loss 0.144821, forward nfe 12804, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 045, Runtime 13.782648, Loss 0.110015, forward nfe 13100, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 046, Runtime 14.203780, Loss 0.126121, forward nfe 13396, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 047, Runtime 13.863503, Loss 0.172051, forward nfe 13692, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 048, Runtime 13.798014, Loss 0.164461, forward nfe 13988, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 049, Runtime 14.133335, Loss 0.109393, forward nfe 14284, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 050, Runtime 14.576373, Loss 0.128669, forward nfe 14580, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 051, Runtime 14.185990, Loss 0.151360, forward nfe 14876, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 052, Runtime 14.283541, Loss 0.126709, forward nfe 15172, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 053, Runtime 14.865227, Loss 0.109875, forward nfe 15468, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 054, Runtime 15.093951, Loss 0.182444, forward nfe 15764, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 055, Runtime 14.821809, Loss 0.195441, forward nfe 16060, backward nfe 0, Train: 0.9857, Val: 0.8610, Test: 0.8548, Best time: 18.2948
Epoch: 056, Runtime 15.224806, Loss 0.149394, forward nfe 16356, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 26.0000
Epoch: 057, Runtime 13.509144, Loss 0.129592, forward nfe 16652, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 058, Runtime 13.894247, Loss 0.109533, forward nfe 16948, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 059, Runtime 14.269382, Loss 0.117545, forward nfe 17244, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 060, Runtime 13.731905, Loss 0.113827, forward nfe 17540, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 061, Runtime 13.798242, Loss 0.110491, forward nfe 17836, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 062, Runtime 14.149025, Loss 0.129550, forward nfe 18132, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 063, Runtime 14.394717, Loss 0.104197, forward nfe 18428, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 064, Runtime 14.289694, Loss 0.131145, forward nfe 18724, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 065, Runtime 14.411074, Loss 0.139929, forward nfe 19020, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 066, Runtime 14.556944, Loss 0.110932, forward nfe 19316, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 067, Runtime 14.842704, Loss 0.128680, forward nfe 19612, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 068, Runtime 14.704060, Loss 0.136015, forward nfe 19908, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 069, Runtime 14.573499, Loss 0.112618, forward nfe 20204, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 070, Runtime 14.917611, Loss 0.101673, forward nfe 20500, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 071, Runtime 15.255245, Loss 0.107412, forward nfe 20796, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 072, Runtime 14.870894, Loss 0.121121, forward nfe 21092, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 073, Runtime 14.694580, Loss 0.136181, forward nfe 21388, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 074, Runtime 14.974387, Loss 0.098482, forward nfe 21684, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 075, Runtime 15.271773, Loss 0.133479, forward nfe 21980, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 076, Runtime 15.104625, Loss 0.125942, forward nfe 22276, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 077, Runtime 15.185232, Loss 0.095801, forward nfe 22572, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 078, Runtime 15.257843, Loss 0.179534, forward nfe 22868, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 079, Runtime 15.470872, Loss 0.111407, forward nfe 23164, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 080, Runtime 15.406815, Loss 0.125270, forward nfe 23460, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 081, Runtime 15.423680, Loss 0.126008, forward nfe 23756, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 082, Runtime 15.635467, Loss 0.085688, forward nfe 24052, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 083, Runtime 15.786501, Loss 0.084627, forward nfe 24348, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 084, Runtime 15.739007, Loss 0.115838, forward nfe 24644, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 085, Runtime 15.506632, Loss 0.119665, forward nfe 24940, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 086, Runtime 15.690565, Loss 0.081563, forward nfe 25236, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 087, Runtime 15.804122, Loss 0.122436, forward nfe 25532, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 088, Runtime 15.046527, Loss 0.102496, forward nfe 25828, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 089, Runtime 14.528315, Loss 0.121141, forward nfe 26124, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 090, Runtime 11.502204, Loss 0.118094, forward nfe 26420, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 091, Runtime 11.459544, Loss 0.086455, forward nfe 26716, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 092, Runtime 11.437508, Loss 0.116617, forward nfe 27012, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 093, Runtime 11.388060, Loss 0.111436, forward nfe 27308, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 094, Runtime 11.348710, Loss 0.085927, forward nfe 27604, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 095, Runtime 11.406840, Loss 0.100582, forward nfe 27900, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 096, Runtime 11.498087, Loss 0.149219, forward nfe 28196, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 097, Runtime 11.357449, Loss 0.093604, forward nfe 28492, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 098, Runtime 11.434662, Loss 0.103832, forward nfe 28788, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
Epoch: 099, Runtime 11.570847, Loss 0.089515, forward nfe 29084, backward nfe 0, Train: 0.9857, Val: 0.8632, Test: 0.8538, Best time: 18.2948
best val accuracy 0.863235 with test accuracy 0.853807 at epoch 56 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8416243654822335
Entropy Threshold: 2 Test accuracy: 0.8467005076142132
Entropy Threshold: 1.6 Test accuracy: 0.8472505091649695
Entropy Threshold: 1.5 Test accuracy: 0.8467824310520939
Entropy Threshold: 1.4 Test accuracy: 0.8445807770961146
Entropy Threshold: 1.3 Test accuracy: 0.8488253319713994
Entropy Threshold: 1.2 Test accuracy: 0.849329205366357
Entropy Threshold: 1.1 Test accuracy: 0.8519290928050052
Entropy Threshold: 0.9 Test accuracy: 0.8566844919786096
Entropy Threshold: 0.8 Test accuracy: 0.8754098360655738
Entropy Threshold: 0.7 Test accuracy: 0.8868778280542986
Entropy Threshold: 0.6 Test accuracy: 0.9062870699881376
Entropy Threshold: 0.5 Test accuracy: 0.9098660170523751
Entropy Threshold: 0.4 Test accuracy: 0.920099875156055
Entropy Threshold: 0.3 Test accuracy: 0.9333333333333333
Entropy Threshold: 0.2 Test accuracy: 0.9427792915531336
Entropy Threshold: 0.1 Test accuracy: 0.9576023391812866
