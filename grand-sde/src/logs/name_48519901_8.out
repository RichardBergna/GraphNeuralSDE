[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 19.326152, Loss 2.168410, forward nfe 76, backward nfe 0, Train: 0.5143, Val: 0.5265, Test: 0.5157, Best time: 3.0000
Epoch: 002, Runtime 21.148494, Loss 2.386638, forward nfe 372, backward nfe 0, Train: 0.5143, Val: 0.5265, Test: 0.5157, Best time: 18.2948
Epoch: 003, Runtime 14.311589, Loss 2.069773, forward nfe 668, backward nfe 0, Train: 0.7286, Val: 0.6735, Test: 0.6538, Best time: 2.0000
Epoch: 004, Runtime 12.488762, Loss 1.993823, forward nfe 964, backward nfe 0, Train: 0.7500, Val: 0.7632, Test: 0.7624, Best time: 7.0000
Epoch: 005, Runtime 15.148268, Loss 1.883116, forward nfe 1260, backward nfe 0, Train: 0.7643, Val: 0.7743, Test: 0.7675, Best time: 9.0000
Epoch: 006, Runtime 19.115445, Loss 1.859709, forward nfe 1556, backward nfe 0, Train: 0.7643, Val: 0.7743, Test: 0.7675, Best time: 18.2948
Epoch: 007, Runtime 19.284192, Loss 1.572410, forward nfe 1852, backward nfe 0, Train: 0.7643, Val: 0.7743, Test: 0.7675, Best time: 18.2948
Epoch: 008, Runtime 18.834155, Loss 1.490176, forward nfe 2148, backward nfe 0, Train: 0.7643, Val: 0.7743, Test: 0.7675, Best time: 18.2948
Epoch: 009, Runtime 19.079891, Loss 1.472483, forward nfe 2444, backward nfe 0, Train: 0.7643, Val: 0.7743, Test: 0.7675, Best time: 18.2948
Epoch: 010, Runtime 19.709302, Loss 1.172092, forward nfe 2740, backward nfe 0, Train: 0.8714, Val: 0.7831, Test: 0.7858, Best time: 15.0000
Epoch: 011, Runtime 18.343251, Loss 1.120615, forward nfe 3036, backward nfe 0, Train: 0.9000, Val: 0.8228, Test: 0.8122, Best time: 38.0000
Epoch: 012, Runtime 18.833164, Loss 1.057925, forward nfe 3332, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 37.0000
Epoch: 013, Runtime 18.700941, Loss 0.898177, forward nfe 3628, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 014, Runtime 19.495990, Loss 0.839041, forward nfe 3924, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 015, Runtime 19.491684, Loss 0.736997, forward nfe 4220, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 016, Runtime 19.519014, Loss 0.747146, forward nfe 4516, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 017, Runtime 19.289987, Loss 0.694013, forward nfe 4812, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 018, Runtime 19.530791, Loss 0.677911, forward nfe 5108, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 019, Runtime 20.671214, Loss 0.634375, forward nfe 5404, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 020, Runtime 20.413199, Loss 0.583580, forward nfe 5700, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 021, Runtime 19.685730, Loss 0.540704, forward nfe 5996, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 022, Runtime 19.286240, Loss 0.623530, forward nfe 6292, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 023, Runtime 20.137421, Loss 0.502497, forward nfe 6588, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 024, Runtime 19.796621, Loss 0.541078, forward nfe 6884, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 025, Runtime 19.083152, Loss 0.549345, forward nfe 7180, backward nfe 0, Train: 0.8929, Val: 0.8309, Test: 0.8234, Best time: 18.2948
Epoch: 026, Runtime 19.725383, Loss 0.516319, forward nfe 7476, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 47.0000
Epoch: 027, Runtime 17.801345, Loss 0.520591, forward nfe 7772, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 028, Runtime 18.345258, Loss 0.456396, forward nfe 8068, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 029, Runtime 18.050327, Loss 0.533093, forward nfe 8364, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 030, Runtime 18.047820, Loss 0.498449, forward nfe 8660, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 031, Runtime 18.278156, Loss 0.472699, forward nfe 8956, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 032, Runtime 16.681794, Loss 0.465147, forward nfe 9252, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 033, Runtime 16.824065, Loss 0.392493, forward nfe 9548, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 034, Runtime 16.972905, Loss 0.435219, forward nfe 9844, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 035, Runtime 16.895714, Loss 0.411097, forward nfe 10140, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 036, Runtime 17.209873, Loss 0.358574, forward nfe 10436, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 037, Runtime 17.249445, Loss 0.429588, forward nfe 10732, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 038, Runtime 17.252770, Loss 0.438080, forward nfe 11028, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 039, Runtime 17.417655, Loss 0.351950, forward nfe 11324, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 040, Runtime 17.493345, Loss 0.428870, forward nfe 11620, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 041, Runtime 16.991044, Loss 0.380546, forward nfe 11916, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 042, Runtime 16.468547, Loss 0.364797, forward nfe 12212, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 043, Runtime 16.749857, Loss 0.265012, forward nfe 12508, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 044, Runtime 16.326245, Loss 0.386190, forward nfe 12804, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 045, Runtime 16.465657, Loss 0.330276, forward nfe 13100, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 046, Runtime 16.803385, Loss 0.297140, forward nfe 13396, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 047, Runtime 16.472762, Loss 0.375875, forward nfe 13692, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 048, Runtime 16.428049, Loss 0.403063, forward nfe 13988, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 049, Runtime 16.322627, Loss 0.379893, forward nfe 14284, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 050, Runtime 16.481908, Loss 0.295905, forward nfe 14580, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 051, Runtime 16.721282, Loss 0.349259, forward nfe 14876, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 052, Runtime 16.690071, Loss 0.327580, forward nfe 15172, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 053, Runtime 16.756062, Loss 0.334715, forward nfe 15468, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 054, Runtime 16.779451, Loss 0.338950, forward nfe 15764, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 055, Runtime 16.737419, Loss 0.304342, forward nfe 16060, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 056, Runtime 17.010140, Loss 0.331949, forward nfe 16356, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 057, Runtime 16.938396, Loss 0.280870, forward nfe 16652, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 058, Runtime 16.973247, Loss 0.302240, forward nfe 16948, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 059, Runtime 16.945342, Loss 0.296164, forward nfe 17244, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 060, Runtime 16.871552, Loss 0.332128, forward nfe 17540, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 061, Runtime 16.387654, Loss 0.236235, forward nfe 17836, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 062, Runtime 17.281892, Loss 0.299775, forward nfe 18132, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 063, Runtime 17.960092, Loss 0.301992, forward nfe 18428, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 064, Runtime 18.042800, Loss 0.209430, forward nfe 18724, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 065, Runtime 18.043504, Loss 0.332411, forward nfe 19020, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 066, Runtime 17.745690, Loss 0.296957, forward nfe 19316, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 067, Runtime 15.860160, Loss 0.304760, forward nfe 19612, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 068, Runtime 15.391137, Loss 0.283533, forward nfe 19908, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 069, Runtime 15.740270, Loss 0.267884, forward nfe 20204, backward nfe 0, Train: 0.9286, Val: 0.8316, Test: 0.8213, Best time: 18.2948
Epoch: 070, Runtime 15.751851, Loss 0.328733, forward nfe 20500, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 54.8843
Epoch: 071, Runtime 11.782226, Loss 0.279520, forward nfe 20796, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 072, Runtime 12.101107, Loss 0.329909, forward nfe 21092, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 073, Runtime 11.856878, Loss 0.312018, forward nfe 21388, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 074, Runtime 12.008097, Loss 0.259386, forward nfe 21684, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 075, Runtime 12.483178, Loss 0.341366, forward nfe 21980, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 076, Runtime 12.442278, Loss 0.327401, forward nfe 22276, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 077, Runtime 12.786281, Loss 0.264074, forward nfe 22572, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 078, Runtime 13.727189, Loss 0.291600, forward nfe 22868, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 079, Runtime 14.762114, Loss 0.350297, forward nfe 23164, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 080, Runtime 14.848994, Loss 0.248669, forward nfe 23460, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 081, Runtime 15.235157, Loss 0.290388, forward nfe 23756, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 082, Runtime 15.193156, Loss 0.207260, forward nfe 24052, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 083, Runtime 15.615829, Loss 0.254578, forward nfe 24348, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 084, Runtime 16.144964, Loss 0.220905, forward nfe 24644, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 085, Runtime 16.163204, Loss 0.196558, forward nfe 24940, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 086, Runtime 16.339953, Loss 0.150396, forward nfe 25236, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 087, Runtime 16.423136, Loss 0.280443, forward nfe 25532, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 088, Runtime 16.339800, Loss 0.240083, forward nfe 25828, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 089, Runtime 16.522105, Loss 0.224826, forward nfe 26124, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 090, Runtime 16.792905, Loss 0.251452, forward nfe 26420, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 091, Runtime 16.746798, Loss 0.331573, forward nfe 26716, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 092, Runtime 17.099286, Loss 0.289505, forward nfe 27012, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 093, Runtime 17.241055, Loss 0.197060, forward nfe 27308, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 094, Runtime 17.388898, Loss 0.248882, forward nfe 27604, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 095, Runtime 17.671645, Loss 0.318470, forward nfe 27900, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 096, Runtime 17.941899, Loss 0.218973, forward nfe 28196, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 097, Runtime 17.959413, Loss 0.276251, forward nfe 28492, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 098, Runtime 18.160856, Loss 0.183863, forward nfe 28788, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
Epoch: 099, Runtime 18.431999, Loss 0.256143, forward nfe 29084, backward nfe 0, Train: 0.9571, Val: 0.8338, Test: 0.8294, Best time: 18.2948
best val accuracy 0.833824 with test accuracy 0.829442 at epoch 70 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8284263959390863
Entropy Threshold: 2 Test accuracy: 0.8284263959390863
Entropy Threshold: 1.6 Test accuracy: 0.8336734693877551
Entropy Threshold: 1.5 Test accuracy: 0.8285420944558521
Entropy Threshold: 1.4 Test accuracy: 0.842159916926272
Entropy Threshold: 1.3 Test accuracy: 0.8428270042194093
Entropy Threshold: 1.2 Test accuracy: 0.8444206008583691
Entropy Threshold: 1.1 Test accuracy: 0.8460698689956332
Entropy Threshold: 0.9 Test accuracy: 0.8599088838268792
Entropy Threshold: 0.8 Test accuracy: 0.866822429906542
Entropy Threshold: 0.7 Test accuracy: 0.8817073170731707
Entropy Threshold: 0.6 Test accuracy: 0.8908857509627728
Entropy Threshold: 0.5 Test accuracy: 0.9010695187165776
Entropy Threshold: 0.4 Test accuracy: 0.9206798866855525
Entropy Threshold: 0.3 Test accuracy: 0.9335347432024169
Entropy Threshold: 0.2 Test accuracy: 0.9393442622950819
Entropy Threshold: 0.1 Test accuracy: 0.955637707948244
