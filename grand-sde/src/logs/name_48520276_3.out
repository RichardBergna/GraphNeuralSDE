[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 7.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 30.396713, Loss 5.075902, forward nfe 76, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 002, Runtime 56.824189, Loss 28.582106, forward nfe 372, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 003, Runtime 23.186830, Loss 4.847376, forward nfe 668, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 004, Runtime 24.051475, Loss 5.083334, forward nfe 964, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 005, Runtime 24.530175, Loss 4.557414, forward nfe 1260, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 006, Runtime 25.511051, Loss 4.445890, forward nfe 1556, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 007, Runtime 24.032647, Loss 4.157726, forward nfe 1852, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 008, Runtime 23.331123, Loss 4.139266, forward nfe 2148, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 009, Runtime 24.122868, Loss 4.097741, forward nfe 2444, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 010, Runtime 24.386124, Loss 4.204141, forward nfe 2740, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 011, Runtime 25.155136, Loss 4.118525, forward nfe 3036, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 012, Runtime 25.895778, Loss 3.566388, forward nfe 3332, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 013, Runtime 25.053602, Loss 3.477799, forward nfe 3628, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 014, Runtime 25.623456, Loss 3.468957, forward nfe 3924, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 015, Runtime 26.003753, Loss 3.279976, forward nfe 4220, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 016, Runtime 26.621917, Loss 3.307454, forward nfe 4516, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 017, Runtime 26.519363, Loss 3.377333, forward nfe 4812, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 018, Runtime 27.656765, Loss 2.991055, forward nfe 5108, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 019, Runtime 27.815883, Loss 3.056868, forward nfe 5404, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 020, Runtime 27.325794, Loss 3.294282, forward nfe 5700, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 021, Runtime 28.565624, Loss 3.316474, forward nfe 5996, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 022, Runtime 29.056569, Loss 3.079956, forward nfe 6292, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 023, Runtime 28.974922, Loss 2.949538, forward nfe 6588, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 024, Runtime 28.471011, Loss 3.023842, forward nfe 6884, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 025, Runtime 29.043293, Loss 3.048219, forward nfe 7180, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 026, Runtime 29.247785, Loss 2.955451, forward nfe 7476, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 027, Runtime 29.255079, Loss 2.956209, forward nfe 7772, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 028, Runtime 28.829350, Loss 2.847474, forward nfe 8068, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 029, Runtime 29.333755, Loss 2.985687, forward nfe 8364, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 030, Runtime 19.540627, Loss 2.950556, forward nfe 8660, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 031, Runtime 18.368211, Loss 2.751282, forward nfe 8956, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 032, Runtime 18.550472, Loss 3.084040, forward nfe 9252, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 033, Runtime 19.309435, Loss 3.061416, forward nfe 9548, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 034, Runtime 19.547857, Loss 2.917320, forward nfe 9844, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 035, Runtime 19.856168, Loss 2.843083, forward nfe 10140, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 036, Runtime 20.602397, Loss 2.796056, forward nfe 10436, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 037, Runtime 21.516883, Loss 2.967464, forward nfe 10732, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 038, Runtime 21.334941, Loss 2.956245, forward nfe 11028, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 039, Runtime 21.494743, Loss 2.820629, forward nfe 11324, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 040, Runtime 21.730829, Loss 2.802437, forward nfe 11620, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 041, Runtime 21.987220, Loss 2.604366, forward nfe 11916, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 042, Runtime 22.245368, Loss 3.049386, forward nfe 12212, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 043, Runtime 22.550022, Loss 2.900283, forward nfe 12508, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 044, Runtime 22.693792, Loss 3.157139, forward nfe 12804, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 045, Runtime 22.987862, Loss 2.885902, forward nfe 13100, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 046, Runtime 23.519448, Loss 2.799441, forward nfe 13396, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 047, Runtime 23.355338, Loss 2.708310, forward nfe 13692, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 048, Runtime 23.622765, Loss 2.670668, forward nfe 13988, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 049, Runtime 23.672323, Loss 2.891012, forward nfe 14284, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 050, Runtime 23.799560, Loss 2.785950, forward nfe 14580, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 051, Runtime 24.511540, Loss 2.684257, forward nfe 14876, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 052, Runtime 24.219509, Loss 2.938607, forward nfe 15172, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 053, Runtime 24.143392, Loss 2.809933, forward nfe 15468, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 054, Runtime 24.538310, Loss 2.832520, forward nfe 15764, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 055, Runtime 24.833402, Loss 2.859297, forward nfe 16060, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 056, Runtime 25.018090, Loss 3.003683, forward nfe 16356, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 057, Runtime 25.354354, Loss 2.765976, forward nfe 16652, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 058, Runtime 25.242664, Loss 2.572005, forward nfe 16948, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 059, Runtime 25.084238, Loss 2.564557, forward nfe 17244, backward nfe 0, Train: 0.1714, Val: 0.1824, Test: 0.2122, Best time: 18.2948
Epoch: 060, Runtime 25.869329, Loss 2.748354, forward nfe 17540, backward nfe 0, Train: 0.1786, Val: 0.1882, Test: 0.1726, Best time: 11.0000
Epoch: 061, Runtime 17.713809, Loss 2.747423, forward nfe 17836, backward nfe 0, Train: 0.1571, Val: 0.2110, Test: 0.1929, Best time: 6.0000
Epoch: 062, Runtime 17.613956, Loss 2.597968, forward nfe 18132, backward nfe 0, Train: 0.1571, Val: 0.2162, Test: 0.2051, Best time: 5.0000
Epoch: 063, Runtime 17.561814, Loss 2.627577, forward nfe 18428, backward nfe 0, Train: 0.1500, Val: 0.2287, Test: 0.2112, Best time: 6.0000
Epoch: 064, Runtime 17.542769, Loss 2.540781, forward nfe 18724, backward nfe 0, Train: 0.1571, Val: 0.2449, Test: 0.2294, Best time: 6.0000
Epoch: 065, Runtime 17.531399, Loss 2.662504, forward nfe 19020, backward nfe 0, Train: 0.1500, Val: 0.2500, Test: 0.2335, Best time: 5.0000
Epoch: 066, Runtime 17.355660, Loss 2.702204, forward nfe 19316, backward nfe 0, Train: 0.1643, Val: 0.2596, Test: 0.2416, Best time: 5.0000
Epoch: 067, Runtime 17.502496, Loss 2.694677, forward nfe 19612, backward nfe 0, Train: 0.1571, Val: 0.2610, Test: 0.2477, Best time: 5.0000
Epoch: 068, Runtime 17.543320, Loss 2.510940, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.2713, Test: 0.2548, Best time: 7.0000
Epoch: 069, Runtime 17.689278, Loss 2.641507, forward nfe 20204, backward nfe 0, Train: 0.1500, Val: 0.2765, Test: 0.2599, Best time: 7.0000
Epoch: 070, Runtime 17.593729, Loss 2.434081, forward nfe 20500, backward nfe 0, Train: 0.1500, Val: 0.2801, Test: 0.2629, Best time: 6.0000
Epoch: 071, Runtime 17.834681, Loss 2.816308, forward nfe 20796, backward nfe 0, Train: 0.1500, Val: 0.2853, Test: 0.2650, Best time: 6.0000
Epoch: 072, Runtime 17.527715, Loss 2.675805, forward nfe 21092, backward nfe 0, Train: 0.1500, Val: 0.2853, Test: 0.2650, Best time: 18.2948
Epoch: 073, Runtime 17.675405, Loss 2.473685, forward nfe 21388, backward nfe 0, Train: 0.1286, Val: 0.2875, Test: 0.2751, Best time: 8.0000
Epoch: 074, Runtime 17.654386, Loss 2.639733, forward nfe 21684, backward nfe 0, Train: 0.1357, Val: 0.2890, Test: 0.2751, Best time: 7.0000
Epoch: 075, Runtime 17.805730, Loss 2.655063, forward nfe 21980, backward nfe 0, Train: 0.1286, Val: 0.2934, Test: 0.2772, Best time: 8.0000
Epoch: 076, Runtime 17.556936, Loss 2.694854, forward nfe 22276, backward nfe 0, Train: 0.1357, Val: 0.2985, Test: 0.2812, Best time: 9.0000
Epoch: 077, Runtime 17.569228, Loss 2.600020, forward nfe 22572, backward nfe 0, Train: 0.1357, Val: 0.3000, Test: 0.2822, Best time: 8.0000
Epoch: 078, Runtime 17.412968, Loss 2.752918, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3029, Test: 0.2822, Best time: 6.0000
Epoch: 079, Runtime 17.307638, Loss 2.579493, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3044, Test: 0.2812, Best time: 7.0000
Epoch: 080, Runtime 17.289733, Loss 2.579324, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3051, Test: 0.2853, Best time: 11.0000
Epoch: 081, Runtime 17.334981, Loss 2.485317, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3059, Test: 0.2863, Best time: 7.0000
Epoch: 082, Runtime 17.296116, Loss 2.735016, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2863, Best time: 9.0000
Epoch: 083, Runtime 17.086191, Loss 2.581295, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2863, Best time: 18.2948
Epoch: 084, Runtime 17.390590, Loss 2.683802, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2863, Best time: 18.2948
Epoch: 085, Runtime 17.935751, Loss 2.520544, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2812, Best time: 3.0000
Epoch: 086, Runtime 17.092674, Loss 2.637605, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2812, Best time: 18.2948
Epoch: 087, Runtime 17.476823, Loss 2.510692, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2812, Best time: 18.2948
Epoch: 088, Runtime 18.021574, Loss 2.706774, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2812, Best time: 18.2948
Epoch: 089, Runtime 18.444170, Loss 2.641705, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 4.0000
Epoch: 090, Runtime 17.216789, Loss 2.601217, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 091, Runtime 17.127047, Loss 2.677457, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 092, Runtime 17.995392, Loss 2.635771, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 093, Runtime 18.344053, Loss 2.675773, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 094, Runtime 18.718782, Loss 2.606175, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 095, Runtime 19.302417, Loss 2.557513, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 096, Runtime 20.005276, Loss 2.627089, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 097, Runtime 20.464249, Loss 2.444896, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 098, Runtime 20.760843, Loss 2.601169, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
Epoch: 099, Runtime 21.656583, Loss 2.659817, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2853, Best time: 18.2948
best val accuracy 0.308088 with test accuracy 0.285279 at epoch 89 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1431472081218274
Entropy Threshold: 2 Test accuracy: 0.14517766497461929
Entropy Threshold: 1.6 Test accuracy: None
Entropy Threshold: 1.5 Test accuracy: None
Entropy Threshold: 1.4 Test accuracy: None
Entropy Threshold: 1.3 Test accuracy: None
Entropy Threshold: 1.2 Test accuracy: None
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
