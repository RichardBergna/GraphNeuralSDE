[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 4.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 19.945229, Loss 2.689228, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.3176, Test: 0.2893, Best time: 1.0000
Epoch: 002, Runtime 31.532256, Loss 16.769720, forward nfe 372, backward nfe 0, Train: 0.1500, Val: 0.3176, Test: 0.2893, Best time: 18.2948
Epoch: 003, Runtime 16.689765, Loss 2.940497, forward nfe 668, backward nfe 0, Train: 0.1500, Val: 0.3176, Test: 0.2893, Best time: 18.2948
Epoch: 004, Runtime 17.217954, Loss 3.052654, forward nfe 964, backward nfe 0, Train: 0.1500, Val: 0.3176, Test: 0.2893, Best time: 18.2948
Epoch: 005, Runtime 18.655626, Loss 3.060491, forward nfe 1260, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 3.0000
Epoch: 006, Runtime 17.029805, Loss 3.141253, forward nfe 1556, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 007, Runtime 17.998875, Loss 2.998436, forward nfe 1852, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 008, Runtime 19.237737, Loss 2.796907, forward nfe 2148, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 009, Runtime 20.393522, Loss 2.827007, forward nfe 2444, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 010, Runtime 21.593275, Loss 2.716736, forward nfe 2740, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 011, Runtime 21.967526, Loss 2.728597, forward nfe 3036, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 012, Runtime 21.860361, Loss 2.835463, forward nfe 3332, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 013, Runtime 22.445272, Loss 2.721993, forward nfe 3628, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 014, Runtime 22.838376, Loss 2.536730, forward nfe 3924, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 015, Runtime 23.402213, Loss 2.511310, forward nfe 4220, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 016, Runtime 24.089679, Loss 2.691380, forward nfe 4516, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 017, Runtime 24.288945, Loss 2.756351, forward nfe 4812, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 018, Runtime 24.399193, Loss 2.602930, forward nfe 5108, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 019, Runtime 24.359503, Loss 2.599948, forward nfe 5404, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 020, Runtime 24.258512, Loss 2.468380, forward nfe 5700, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 021, Runtime 24.618083, Loss 2.451789, forward nfe 5996, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 022, Runtime 24.661964, Loss 2.476316, forward nfe 6292, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 023, Runtime 25.099093, Loss 2.445212, forward nfe 6588, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 024, Runtime 25.348300, Loss 2.393953, forward nfe 6884, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 025, Runtime 24.781077, Loss 2.509363, forward nfe 7180, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 026, Runtime 24.909171, Loss 2.466095, forward nfe 7476, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 027, Runtime 24.971565, Loss 2.415045, forward nfe 7772, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 028, Runtime 24.777802, Loss 2.509376, forward nfe 8068, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 029, Runtime 25.263098, Loss 2.395202, forward nfe 8364, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 030, Runtime 24.374287, Loss 2.445988, forward nfe 8660, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 031, Runtime 24.469280, Loss 2.532251, forward nfe 8956, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 032, Runtime 24.493670, Loss 2.422116, forward nfe 9252, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 033, Runtime 24.672843, Loss 2.367431, forward nfe 9548, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 034, Runtime 24.678577, Loss 2.480492, forward nfe 9844, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 035, Runtime 24.697128, Loss 2.421445, forward nfe 10140, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 036, Runtime 24.543619, Loss 2.576771, forward nfe 10436, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 037, Runtime 24.509055, Loss 2.327727, forward nfe 10732, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 038, Runtime 24.513208, Loss 2.342071, forward nfe 11028, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 039, Runtime 24.608923, Loss 2.441319, forward nfe 11324, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 040, Runtime 24.775161, Loss 2.372713, forward nfe 11620, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 041, Runtime 24.909182, Loss 2.337615, forward nfe 11916, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 042, Runtime 22.007809, Loss 2.219196, forward nfe 12212, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 043, Runtime 16.711109, Loss 2.387597, forward nfe 12508, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 044, Runtime 16.972934, Loss 2.390692, forward nfe 12804, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 045, Runtime 17.473407, Loss 2.249560, forward nfe 13100, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 046, Runtime 18.385067, Loss 2.314633, forward nfe 13396, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 047, Runtime 18.454726, Loss 2.209783, forward nfe 13692, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 048, Runtime 19.245284, Loss 2.282161, forward nfe 13988, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 049, Runtime 19.880917, Loss 2.208625, forward nfe 14284, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 050, Runtime 20.112661, Loss 2.331495, forward nfe 14580, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 051, Runtime 20.494870, Loss 2.399925, forward nfe 14876, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 052, Runtime 21.112922, Loss 2.326824, forward nfe 15172, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 053, Runtime 21.379572, Loss 2.305465, forward nfe 15468, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 054, Runtime 21.586770, Loss 2.188077, forward nfe 15764, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 055, Runtime 22.392106, Loss 2.181456, forward nfe 16060, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 056, Runtime 22.485616, Loss 2.326049, forward nfe 16356, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 057, Runtime 22.726862, Loss 2.127915, forward nfe 16652, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 058, Runtime 23.194043, Loss 2.275095, forward nfe 16948, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 059, Runtime 23.376482, Loss 2.410138, forward nfe 17244, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 060, Runtime 23.529137, Loss 2.267063, forward nfe 17540, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 061, Runtime 23.823056, Loss 2.429928, forward nfe 17836, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 062, Runtime 23.981972, Loss 2.372935, forward nfe 18132, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 063, Runtime 24.035717, Loss 2.223552, forward nfe 18428, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 064, Runtime 24.331224, Loss 2.237242, forward nfe 18724, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 065, Runtime 24.658404, Loss 2.295329, forward nfe 19020, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 066, Runtime 25.030905, Loss 2.232064, forward nfe 19316, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 067, Runtime 25.339151, Loss 2.119311, forward nfe 19612, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 068, Runtime 25.565271, Loss 2.150350, forward nfe 19908, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 069, Runtime 26.115588, Loss 2.165664, forward nfe 20204, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 070, Runtime 26.327882, Loss 2.346294, forward nfe 20500, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 071, Runtime 26.456831, Loss 2.240594, forward nfe 20796, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 072, Runtime 26.496197, Loss 2.334424, forward nfe 21092, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 073, Runtime 26.715989, Loss 2.226087, forward nfe 21388, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 074, Runtime 27.080500, Loss 2.243176, forward nfe 21684, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 075, Runtime 27.481051, Loss 2.202392, forward nfe 21980, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 076, Runtime 27.478542, Loss 2.170891, forward nfe 22276, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 077, Runtime 27.763047, Loss 2.315835, forward nfe 22572, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 078, Runtime 27.575123, Loss 2.153233, forward nfe 22868, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 079, Runtime 27.584704, Loss 2.131743, forward nfe 23164, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 080, Runtime 27.950351, Loss 2.186221, forward nfe 23460, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 081, Runtime 24.752547, Loss 2.152070, forward nfe 23756, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 082, Runtime 17.591244, Loss 2.185926, forward nfe 24052, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 083, Runtime 17.942436, Loss 2.119185, forward nfe 24348, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 084, Runtime 18.673656, Loss 2.306006, forward nfe 24644, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 085, Runtime 19.456327, Loss 2.163779, forward nfe 24940, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 086, Runtime 19.817080, Loss 2.112832, forward nfe 25236, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 087, Runtime 20.260844, Loss 2.244786, forward nfe 25532, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 088, Runtime 21.102158, Loss 2.132925, forward nfe 25828, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 089, Runtime 21.363671, Loss 2.186488, forward nfe 26124, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 090, Runtime 21.811342, Loss 2.293399, forward nfe 26420, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 091, Runtime 22.368731, Loss 2.163562, forward nfe 26716, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 092, Runtime 23.050395, Loss 2.128099, forward nfe 27012, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 093, Runtime 23.168542, Loss 2.214573, forward nfe 27308, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 094, Runtime 23.935055, Loss 2.130385, forward nfe 27604, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 095, Runtime 24.478112, Loss 2.200985, forward nfe 27900, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 096, Runtime 24.853994, Loss 2.197333, forward nfe 28196, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 097, Runtime 25.002031, Loss 2.171939, forward nfe 28492, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 098, Runtime 25.612765, Loss 2.120199, forward nfe 28788, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
Epoch: 099, Runtime 26.261070, Loss 2.183816, forward nfe 29084, backward nfe 0, Train: 0.2643, Val: 0.4199, Test: 0.3868, Best time: 18.2948
best val accuracy 0.419853 with test accuracy 0.386802 at epoch 5 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.10964467005076142
Entropy Threshold: 2 Test accuracy: 0.08426395939086294
Entropy Threshold: 1.6 Test accuracy: 0.09872611464968153
Entropy Threshold: 1.5 Test accuracy: 0.10032894736842106
Entropy Threshold: 1.4 Test accuracy: 0.08737864077669903
Entropy Threshold: 1.3 Test accuracy: 0.11594202898550725
Entropy Threshold: 1.2 Test accuracy: 0.038461538461538464
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
