[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 19.013318, Loss 2.074732, forward nfe 76, backward nfe 0, Train: 0.2714, Val: 0.3684, Test: 0.3746, Best time: 1.0000
Epoch: 002, Runtime 20.703106, Loss 2.415757, forward nfe 372, backward nfe 0, Train: 0.4000, Val: 0.4721, Test: 0.4893, Best time: 5.0000
Epoch: 003, Runtime 13.669955, Loss 2.104427, forward nfe 668, backward nfe 0, Train: 0.4000, Val: 0.4721, Test: 0.4893, Best time: 18.2948
Epoch: 004, Runtime 12.439147, Loss 1.965009, forward nfe 964, backward nfe 0, Train: 0.4000, Val: 0.4721, Test: 0.4893, Best time: 18.2948
Epoch: 005, Runtime 16.039433, Loss 1.933440, forward nfe 1260, backward nfe 0, Train: 0.4000, Val: 0.4721, Test: 0.4893, Best time: 18.2948
Epoch: 006, Runtime 20.784824, Loss 1.818233, forward nfe 1556, backward nfe 0, Train: 0.5929, Val: 0.5721, Test: 0.5726, Best time: 5.0000
Epoch: 007, Runtime 19.513723, Loss 1.675393, forward nfe 1852, backward nfe 0, Train: 0.6929, Val: 0.6382, Test: 0.6315, Best time: 4.0000
Epoch: 008, Runtime 19.146060, Loss 1.656836, forward nfe 2148, backward nfe 0, Train: 0.7429, Val: 0.6765, Test: 0.6650, Best time: 7.0000
Epoch: 009, Runtime 19.083076, Loss 1.400356, forward nfe 2444, backward nfe 0, Train: 0.7857, Val: 0.7125, Test: 0.6893, Best time: 11.0000
Epoch: 010, Runtime 18.969285, Loss 1.442363, forward nfe 2740, backward nfe 0, Train: 0.8286, Val: 0.7537, Test: 0.7431, Best time: 15.0000
Epoch: 011, Runtime 19.082222, Loss 1.261790, forward nfe 3036, backward nfe 0, Train: 0.8571, Val: 0.7853, Test: 0.7645, Best time: 26.0000
Epoch: 012, Runtime 19.142697, Loss 1.116316, forward nfe 3332, backward nfe 0, Train: 0.8643, Val: 0.7926, Test: 0.7635, Best time: 9.0000
Epoch: 013, Runtime 18.943619, Loss 0.992780, forward nfe 3628, backward nfe 0, Train: 0.8643, Val: 0.7926, Test: 0.7635, Best time: 18.2948
Epoch: 014, Runtime 19.533130, Loss 0.914254, forward nfe 3924, backward nfe 0, Train: 0.8643, Val: 0.7926, Test: 0.7635, Best time: 18.2948
Epoch: 015, Runtime 19.874811, Loss 0.869440, forward nfe 4220, backward nfe 0, Train: 0.8857, Val: 0.7971, Test: 0.7746, Best time: 12.0000
Epoch: 016, Runtime 19.122080, Loss 0.829673, forward nfe 4516, backward nfe 0, Train: 0.8929, Val: 0.8088, Test: 0.7777, Best time: 10.0000
Epoch: 017, Runtime 18.261796, Loss 0.709666, forward nfe 4812, backward nfe 0, Train: 0.9000, Val: 0.8140, Test: 0.7858, Best time: 11.0000
Epoch: 018, Runtime 18.658902, Loss 0.668588, forward nfe 5108, backward nfe 0, Train: 0.9071, Val: 0.8154, Test: 0.7909, Best time: 13.0000
Epoch: 019, Runtime 19.894855, Loss 0.685967, forward nfe 5404, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 21.0000
Epoch: 020, Runtime 18.889667, Loss 0.633763, forward nfe 5700, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 021, Runtime 18.840748, Loss 0.552703, forward nfe 5996, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 022, Runtime 18.306826, Loss 0.523774, forward nfe 6292, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 023, Runtime 18.550697, Loss 0.551203, forward nfe 6588, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 024, Runtime 19.118344, Loss 0.601037, forward nfe 6884, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 025, Runtime 18.399444, Loss 0.531416, forward nfe 7180, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8000, Best time: 18.2948
Epoch: 026, Runtime 18.807890, Loss 0.606835, forward nfe 7476, backward nfe 0, Train: 0.9357, Val: 0.8176, Test: 0.8203, Best time: 43.0000
Epoch: 027, Runtime 18.900046, Loss 0.592184, forward nfe 7772, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 45.0000
Epoch: 028, Runtime 18.403677, Loss 0.372335, forward nfe 8068, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 029, Runtime 18.507529, Loss 0.521436, forward nfe 8364, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 030, Runtime 18.731726, Loss 0.467084, forward nfe 8660, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 031, Runtime 18.631010, Loss 0.489640, forward nfe 8956, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 032, Runtime 17.429207, Loss 0.474124, forward nfe 9252, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 033, Runtime 17.272385, Loss 0.460144, forward nfe 9548, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 034, Runtime 17.126462, Loss 0.367409, forward nfe 9844, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 035, Runtime 17.440956, Loss 0.414646, forward nfe 10140, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 036, Runtime 17.732224, Loss 0.385400, forward nfe 10436, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 037, Runtime 17.482328, Loss 0.390383, forward nfe 10732, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 038, Runtime 17.929651, Loss 0.378860, forward nfe 11028, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 039, Runtime 17.889343, Loss 0.447538, forward nfe 11324, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 040, Runtime 17.810012, Loss 0.339888, forward nfe 11620, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 041, Runtime 17.541380, Loss 0.467046, forward nfe 11916, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 042, Runtime 16.822142, Loss 0.378372, forward nfe 12212, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 043, Runtime 16.830404, Loss 0.408341, forward nfe 12508, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 044, Runtime 17.099279, Loss 0.413423, forward nfe 12804, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 045, Runtime 16.730402, Loss 0.358675, forward nfe 13100, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 046, Runtime 16.526232, Loss 0.330034, forward nfe 13396, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 047, Runtime 17.086584, Loss 0.275194, forward nfe 13692, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 048, Runtime 16.838553, Loss 0.316563, forward nfe 13988, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 049, Runtime 16.515411, Loss 0.419576, forward nfe 14284, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 050, Runtime 16.916365, Loss 0.289404, forward nfe 14580, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 051, Runtime 16.675836, Loss 0.343642, forward nfe 14876, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 052, Runtime 16.815060, Loss 0.355978, forward nfe 15172, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 053, Runtime 17.277339, Loss 0.220498, forward nfe 15468, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 054, Runtime 17.290605, Loss 0.327608, forward nfe 15764, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 055, Runtime 17.449601, Loss 0.295776, forward nfe 16060, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 056, Runtime 17.661649, Loss 0.356812, forward nfe 16356, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 057, Runtime 17.290153, Loss 0.343658, forward nfe 16652, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 058, Runtime 17.086274, Loss 0.210806, forward nfe 16948, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 059, Runtime 17.098015, Loss 0.398584, forward nfe 17244, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 060, Runtime 17.545142, Loss 0.304707, forward nfe 17540, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 061, Runtime 16.691063, Loss 0.258465, forward nfe 17836, backward nfe 0, Train: 0.9214, Val: 0.8287, Test: 0.8244, Best time: 18.2948
Epoch: 062, Runtime 17.771228, Loss 0.289370, forward nfe 18132, backward nfe 0, Train: 0.9786, Val: 0.8360, Test: 0.8335, Best time: 50.0000
Epoch: 063, Runtime 13.219657, Loss 0.306654, forward nfe 18428, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 42.0000
Epoch: 064, Runtime 13.021354, Loss 0.243458, forward nfe 18724, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 065, Runtime 13.566632, Loss 0.234443, forward nfe 19020, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 066, Runtime 13.376126, Loss 0.345727, forward nfe 19316, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 067, Runtime 13.459590, Loss 0.269604, forward nfe 19612, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 068, Runtime 12.526623, Loss 0.234783, forward nfe 19908, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 069, Runtime 12.133194, Loss 0.280218, forward nfe 20204, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 070, Runtime 12.410521, Loss 0.324442, forward nfe 20500, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 071, Runtime 12.623487, Loss 0.298682, forward nfe 20796, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 072, Runtime 12.490734, Loss 0.232892, forward nfe 21092, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 073, Runtime 12.653499, Loss 0.246458, forward nfe 21388, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 074, Runtime 13.204827, Loss 0.240041, forward nfe 21684, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 075, Runtime 12.972214, Loss 0.277723, forward nfe 21980, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 076, Runtime 13.045207, Loss 0.290290, forward nfe 22276, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 077, Runtime 13.335657, Loss 0.237330, forward nfe 22572, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 078, Runtime 13.497121, Loss 0.281308, forward nfe 22868, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 079, Runtime 14.316603, Loss 0.267217, forward nfe 23164, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 080, Runtime 15.775954, Loss 0.270733, forward nfe 23460, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 081, Runtime 15.989002, Loss 0.247913, forward nfe 23756, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 082, Runtime 15.954591, Loss 0.179678, forward nfe 24052, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 083, Runtime 16.325658, Loss 0.215646, forward nfe 24348, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 084, Runtime 16.541660, Loss 0.261320, forward nfe 24644, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 085, Runtime 16.697212, Loss 0.253003, forward nfe 24940, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 086, Runtime 17.136750, Loss 0.261021, forward nfe 25236, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 087, Runtime 17.106957, Loss 0.198840, forward nfe 25532, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 088, Runtime 16.307488, Loss 0.291800, forward nfe 25828, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 089, Runtime 16.618270, Loss 0.325467, forward nfe 26124, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 090, Runtime 16.566319, Loss 0.324873, forward nfe 26420, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 091, Runtime 16.515256, Loss 0.215477, forward nfe 26716, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 092, Runtime 17.157233, Loss 0.178386, forward nfe 27012, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 093, Runtime 17.304276, Loss 0.250243, forward nfe 27308, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 094, Runtime 16.724262, Loss 0.224998, forward nfe 27604, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 095, Runtime 16.999334, Loss 0.177460, forward nfe 27900, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 096, Runtime 16.974217, Loss 0.205948, forward nfe 28196, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 097, Runtime 17.019266, Loss 0.264839, forward nfe 28492, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 098, Runtime 17.486686, Loss 0.259544, forward nfe 28788, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
Epoch: 099, Runtime 17.319105, Loss 0.296692, forward nfe 29084, backward nfe 0, Train: 0.9786, Val: 0.8368, Test: 0.8294, Best time: 18.2948
best val accuracy 0.836765 with test accuracy 0.829442 at epoch 63 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8436548223350254
Entropy Threshold: 2 Test accuracy: 0.8467005076142132
Entropy Threshold: 1.6 Test accuracy: 0.8474059003051883
Entropy Threshold: 1.5 Test accuracy: 0.8530318602261048
Entropy Threshold: 1.4 Test accuracy: 0.85625
Entropy Threshold: 1.3 Test accuracy: 0.8593913955928646
Entropy Threshold: 1.2 Test accuracy: 0.8636847710330139
Entropy Threshold: 1.1 Test accuracy: 0.8657205240174672
Entropy Threshold: 0.9 Test accuracy: 0.8860465116279069
Entropy Threshold: 0.8 Test accuracy: 0.8990267639902676
Entropy Threshold: 0.7 Test accuracy: 0.9162371134020618
Entropy Threshold: 0.6 Test accuracy: 0.9181446111869032
Entropy Threshold: 0.5 Test accuracy: 0.9232954545454546
Entropy Threshold: 0.4 Test accuracy: 0.9304084720121029
Entropy Threshold: 0.3 Test accuracy: 0.9425287356321839
Entropy Threshold: 0.2 Test accuracy: 0.9492119089316988
Entropy Threshold: 0.1 Test accuracy: 0.9490835030549898
