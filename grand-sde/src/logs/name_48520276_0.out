[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 7.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 32.457658, Loss 6.205157, forward nfe 76, backward nfe 0, Train: 0.1643, Val: 0.1493, Test: 0.1614, Best time: 2.0000
Epoch: 002, Runtime 49.846143, Loss 44.467018, forward nfe 372, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2670, Best time: 2.0000
Epoch: 003, Runtime 21.575493, Loss 5.599942, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 5.0000
Epoch: 004, Runtime 20.801540, Loss 5.673533, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 005, Runtime 21.216064, Loss 5.024595, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 006, Runtime 21.575655, Loss 4.555717, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 007, Runtime 22.864168, Loss 4.630423, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 008, Runtime 24.149150, Loss 4.473802, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 009, Runtime 25.264265, Loss 4.830194, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 010, Runtime 25.808071, Loss 4.689008, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 011, Runtime 27.809879, Loss 4.556754, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 012, Runtime 28.742991, Loss 4.079606, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 013, Runtime 30.250479, Loss 3.778904, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 014, Runtime 31.180974, Loss 3.623677, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 015, Runtime 32.267219, Loss 3.683736, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 016, Runtime 31.231643, Loss 3.539664, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 017, Runtime 31.696760, Loss 3.599792, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 018, Runtime 30.729396, Loss 3.565882, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 019, Runtime 31.437913, Loss 3.553897, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 020, Runtime 31.100182, Loss 3.480998, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 021, Runtime 32.058959, Loss 3.582429, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 022, Runtime 31.706127, Loss 3.417383, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 023, Runtime 31.699166, Loss 3.145293, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 024, Runtime 31.985292, Loss 3.157163, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 025, Runtime 27.868311, Loss 3.042175, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 026, Runtime 21.058944, Loss 3.060454, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 027, Runtime 21.711094, Loss 2.900740, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 028, Runtime 22.195153, Loss 2.945491, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 029, Runtime 23.058381, Loss 2.977160, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 030, Runtime 22.715505, Loss 2.955268, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 031, Runtime 23.823226, Loss 2.947625, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 032, Runtime 24.868534, Loss 2.939898, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 033, Runtime 24.297854, Loss 2.909647, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 034, Runtime 25.073147, Loss 2.624728, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 035, Runtime 25.266031, Loss 3.221228, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 036, Runtime 26.081855, Loss 2.748418, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 037, Runtime 26.288026, Loss 2.825610, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 038, Runtime 26.363093, Loss 2.786869, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 039, Runtime 26.637778, Loss 2.929098, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 040, Runtime 26.888642, Loss 2.929904, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 041, Runtime 27.387633, Loss 2.649929, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 042, Runtime 27.779885, Loss 2.656444, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 043, Runtime 27.913234, Loss 2.769747, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 044, Runtime 27.673928, Loss 2.873450, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 045, Runtime 27.971391, Loss 2.870256, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 046, Runtime 27.936581, Loss 2.708075, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 047, Runtime 28.621549, Loss 2.915841, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 048, Runtime 28.714108, Loss 2.876691, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2873, Best time: 18.2948
Epoch: 049, Runtime 29.024812, Loss 2.863557, forward nfe 14284, backward nfe 0, Train: 0.1571, Val: 0.3022, Test: 0.2883, Best time: 4.0000
Epoch: 050, Runtime 18.125342, Loss 2.679907, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3029, Test: 0.2883, Best time: 3.0000
Epoch: 051, Runtime 18.154199, Loss 2.662217, forward nfe 14876, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 5.0000
Epoch: 052, Runtime 17.697015, Loss 2.617564, forward nfe 15172, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 053, Runtime 17.917085, Loss 2.728413, forward nfe 15468, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 054, Runtime 18.538586, Loss 2.746157, forward nfe 15764, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 055, Runtime 19.463436, Loss 2.825008, forward nfe 16060, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 056, Runtime 19.802902, Loss 2.917103, forward nfe 16356, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 057, Runtime 20.169980, Loss 2.622589, forward nfe 16652, backward nfe 0, Train: 0.1571, Val: 0.3037, Test: 0.2893, Best time: 18.2948
Epoch: 058, Runtime 21.531321, Loss 2.800376, forward nfe 16948, backward nfe 0, Train: 0.1571, Val: 0.3051, Test: 0.2914, Best time: 5.0000
Epoch: 059, Runtime 18.219060, Loss 2.626662, forward nfe 17244, backward nfe 0, Train: 0.1571, Val: 0.3059, Test: 0.2914, Best time: 5.0000
Epoch: 060, Runtime 18.158435, Loss 2.582639, forward nfe 17540, backward nfe 0, Train: 0.1571, Val: 0.3059, Test: 0.2914, Best time: 18.2948
Epoch: 061, Runtime 18.222003, Loss 2.685468, forward nfe 17836, backward nfe 0, Train: 0.1571, Val: 0.3059, Test: 0.2914, Best time: 18.2948
Epoch: 062, Runtime 19.194997, Loss 2.594572, forward nfe 18132, backward nfe 0, Train: 0.1571, Val: 0.3081, Test: 0.2904, Best time: 4.0000
Epoch: 063, Runtime 17.841741, Loss 2.508924, forward nfe 18428, backward nfe 0, Train: 0.1571, Val: 0.3081, Test: 0.2904, Best time: 18.2948
Epoch: 064, Runtime 18.229123, Loss 2.652242, forward nfe 18724, backward nfe 0, Train: 0.1643, Val: 0.3103, Test: 0.2954, Best time: 5.0000
Epoch: 065, Runtime 17.926163, Loss 2.561559, forward nfe 19020, backward nfe 0, Train: 0.1643, Val: 0.3110, Test: 0.2975, Best time: 4.0000
Epoch: 066, Runtime 17.741485, Loss 2.690728, forward nfe 19316, backward nfe 0, Train: 0.1643, Val: 0.3110, Test: 0.2975, Best time: 18.2948
Epoch: 067, Runtime 18.015401, Loss 2.750539, forward nfe 19612, backward nfe 0, Train: 0.1643, Val: 0.3110, Test: 0.2975, Best time: 18.2948
Epoch: 068, Runtime 18.381125, Loss 2.872163, forward nfe 19908, backward nfe 0, Train: 0.1643, Val: 0.3125, Test: 0.2964, Best time: 5.0000
Epoch: 069, Runtime 17.506948, Loss 2.822759, forward nfe 20204, backward nfe 0, Train: 0.1643, Val: 0.3125, Test: 0.2964, Best time: 18.2948
Epoch: 070, Runtime 17.800524, Loss 2.621487, forward nfe 20500, backward nfe 0, Train: 0.1643, Val: 0.3125, Test: 0.2964, Best time: 18.2948
Epoch: 071, Runtime 18.338150, Loss 2.793486, forward nfe 20796, backward nfe 0, Train: 0.1857, Val: 0.3132, Test: 0.3005, Best time: 4.0000
Epoch: 072, Runtime 17.714286, Loss 2.849307, forward nfe 21092, backward nfe 0, Train: 0.1857, Val: 0.3169, Test: 0.3015, Best time: 4.0000
Epoch: 073, Runtime 17.536906, Loss 2.605050, forward nfe 21388, backward nfe 0, Train: 0.1857, Val: 0.3176, Test: 0.3015, Best time: 4.0000
Epoch: 074, Runtime 17.477853, Loss 2.561297, forward nfe 21684, backward nfe 0, Train: 0.1857, Val: 0.3176, Test: 0.3015, Best time: 18.2948
Epoch: 075, Runtime 17.789499, Loss 2.577846, forward nfe 21980, backward nfe 0, Train: 0.1857, Val: 0.3176, Test: 0.3015, Best time: 18.2948
Epoch: 076, Runtime 18.197239, Loss 2.647305, forward nfe 22276, backward nfe 0, Train: 0.1857, Val: 0.3176, Test: 0.3015, Best time: 18.2948
Epoch: 077, Runtime 18.883669, Loss 2.563760, forward nfe 22572, backward nfe 0, Train: 0.1857, Val: 0.3176, Test: 0.3015, Best time: 18.2948
Epoch: 078, Runtime 19.391686, Loss 2.275417, forward nfe 22868, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 5.0000
Epoch: 079, Runtime 17.529935, Loss 2.644602, forward nfe 23164, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 080, Runtime 17.847705, Loss 2.698238, forward nfe 23460, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 081, Runtime 18.305946, Loss 2.484066, forward nfe 23756, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 082, Runtime 19.062615, Loss 2.537032, forward nfe 24052, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 083, Runtime 19.471394, Loss 2.672983, forward nfe 24348, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 084, Runtime 19.706339, Loss 2.543956, forward nfe 24644, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 085, Runtime 20.921044, Loss 2.786636, forward nfe 24940, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 086, Runtime 21.147026, Loss 2.564897, forward nfe 25236, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 087, Runtime 21.830329, Loss 2.371658, forward nfe 25532, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 088, Runtime 22.688367, Loss 2.637578, forward nfe 25828, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 089, Runtime 23.060522, Loss 2.496603, forward nfe 26124, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 090, Runtime 23.598858, Loss 2.454454, forward nfe 26420, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 091, Runtime 24.136918, Loss 2.570362, forward nfe 26716, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 092, Runtime 24.635457, Loss 2.426678, forward nfe 27012, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 093, Runtime 24.917946, Loss 2.500496, forward nfe 27308, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 094, Runtime 24.640683, Loss 2.591761, forward nfe 27604, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 095, Runtime 24.723373, Loss 2.564578, forward nfe 27900, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 096, Runtime 25.248191, Loss 2.685612, forward nfe 28196, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 097, Runtime 26.013343, Loss 2.568191, forward nfe 28492, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 098, Runtime 25.506571, Loss 2.601844, forward nfe 28788, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
Epoch: 099, Runtime 25.920210, Loss 2.806394, forward nfe 29084, backward nfe 0, Train: 0.1857, Val: 0.3191, Test: 0.3076, Best time: 18.2948
best val accuracy 0.319118 with test accuracy 0.307614 at epoch 78 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.150253807106599
Entropy Threshold: 2 Test accuracy: 0.15228426395939088
Entropy Threshold: 1.6 Test accuracy: 0.14035087719298245
Entropy Threshold: 1.5 Test accuracy: 0.26666666666666666
Entropy Threshold: 1.4 Test accuracy: 0.15789473684210525
Entropy Threshold: 1.3 Test accuracy: 0.2
Entropy Threshold: 1.2 Test accuracy: 0.1
Entropy Threshold: 1.1 Test accuracy: 0.16666666666666666
Entropy Threshold: 0.9 Test accuracy: 0.25
Entropy Threshold: 0.8 Test accuracy: 0.5
Entropy Threshold: 0.7 Test accuracy: 1.0
Entropy Threshold: 0.6 Test accuracy: 1.0
Entropy Threshold: 0.5 Test accuracy: 1.0
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
