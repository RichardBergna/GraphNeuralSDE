[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 2.5
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.635828, Loss 2.696265, forward nfe 76, backward nfe 0, Train: 0.3071, Val: 0.2456, Test: 0.2487, Best time: 6.0000
Epoch: 002, Runtime 14.823662, Loss 3.533170, forward nfe 372, backward nfe 0, Train: 0.4929, Val: 0.3419, Test: 0.3807, Best time: 1.0000
Epoch: 003, Runtime 14.091810, Loss 2.814851, forward nfe 668, backward nfe 0, Train: 0.5000, Val: 0.4235, Test: 0.4487, Best time: 3.0000
Epoch: 004, Runtime 13.593599, Loss 2.453915, forward nfe 964, backward nfe 0, Train: 0.4786, Val: 0.4397, Test: 0.4609, Best time: 13.0000
Epoch: 005, Runtime 13.657427, Loss 2.510324, forward nfe 1260, backward nfe 0, Train: 0.4786, Val: 0.4397, Test: 0.4609, Best time: 18.2948
Epoch: 006, Runtime 14.028297, Loss 2.373434, forward nfe 1556, backward nfe 0, Train: 0.4786, Val: 0.4397, Test: 0.4609, Best time: 18.2948
Epoch: 007, Runtime 13.793404, Loss 2.285618, forward nfe 1852, backward nfe 0, Train: 0.4786, Val: 0.4397, Test: 0.4609, Best time: 18.2948
Epoch: 008, Runtime 14.354016, Loss 2.252184, forward nfe 2148, backward nfe 0, Train: 0.4786, Val: 0.4397, Test: 0.4609, Best time: 18.2948
Epoch: 009, Runtime 13.860073, Loss 2.001912, forward nfe 2444, backward nfe 0, Train: 0.7071, Val: 0.5154, Test: 0.5381, Best time: 1.0000
Epoch: 010, Runtime 13.004752, Loss 1.854499, forward nfe 2740, backward nfe 0, Train: 0.7786, Val: 0.6412, Test: 0.6558, Best time: 9.0000
Epoch: 011, Runtime 12.888297, Loss 1.825094, forward nfe 3036, backward nfe 0, Train: 0.8143, Val: 0.6875, Test: 0.7005, Best time: 9.0000
Epoch: 012, Runtime 12.778413, Loss 1.707514, forward nfe 3332, backward nfe 0, Train: 0.8286, Val: 0.7000, Test: 0.6924, Best time: 11.0000
Epoch: 013, Runtime 12.668518, Loss 1.473755, forward nfe 3628, backward nfe 0, Train: 0.8429, Val: 0.7096, Test: 0.7036, Best time: 6.0000
Epoch: 014, Runtime 12.780068, Loss 1.316550, forward nfe 3924, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 12.0000
Epoch: 015, Runtime 12.526872, Loss 1.293088, forward nfe 4220, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 016, Runtime 13.018964, Loss 1.237341, forward nfe 4516, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 017, Runtime 12.720486, Loss 1.186950, forward nfe 4812, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 018, Runtime 13.191478, Loss 1.209149, forward nfe 5108, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 019, Runtime 13.598760, Loss 1.047397, forward nfe 5404, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 020, Runtime 13.728892, Loss 1.014134, forward nfe 5700, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 021, Runtime 13.977165, Loss 0.983365, forward nfe 5996, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 022, Runtime 14.772924, Loss 0.847771, forward nfe 6292, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 023, Runtime 14.454507, Loss 0.910583, forward nfe 6588, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 024, Runtime 14.945465, Loss 0.776943, forward nfe 6884, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 025, Runtime 15.433800, Loss 0.848451, forward nfe 7180, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 026, Runtime 14.853598, Loss 0.828487, forward nfe 7476, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 027, Runtime 15.409023, Loss 0.737704, forward nfe 7772, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 028, Runtime 15.318897, Loss 0.793104, forward nfe 8068, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 029, Runtime 15.704875, Loss 0.796502, forward nfe 8364, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 030, Runtime 16.039044, Loss 0.672984, forward nfe 8660, backward nfe 0, Train: 0.8714, Val: 0.7184, Test: 0.7096, Best time: 18.2948
Epoch: 031, Runtime 16.400126, Loss 0.569264, forward nfe 8956, backward nfe 0, Train: 0.8786, Val: 0.7199, Test: 0.7310, Best time: 18.2948
Epoch: 032, Runtime 13.724015, Loss 0.712740, forward nfe 9252, backward nfe 0, Train: 0.8786, Val: 0.7316, Test: 0.7452, Best time: 18.2948
Epoch: 033, Runtime 13.713282, Loss 0.573195, forward nfe 9548, backward nfe 0, Train: 0.8786, Val: 0.7316, Test: 0.7452, Best time: 18.2948
Epoch: 034, Runtime 14.430168, Loss 0.504577, forward nfe 9844, backward nfe 0, Train: 0.8786, Val: 0.7316, Test: 0.7452, Best time: 18.2948
Epoch: 035, Runtime 14.552290, Loss 0.710330, forward nfe 10140, backward nfe 0, Train: 0.8786, Val: 0.7316, Test: 0.7452, Best time: 18.2948
Epoch: 036, Runtime 14.333876, Loss 0.612099, forward nfe 10436, backward nfe 0, Train: 0.8786, Val: 0.7316, Test: 0.7452, Best time: 18.2948
Epoch: 037, Runtime 14.997477, Loss 0.536790, forward nfe 10732, backward nfe 0, Train: 0.9071, Val: 0.7493, Test: 0.7563, Best time: 18.2948
Epoch: 038, Runtime 14.418693, Loss 0.534783, forward nfe 11028, backward nfe 0, Train: 0.8571, Val: 0.7507, Test: 0.7411, Best time: 18.2948
Epoch: 039, Runtime 14.504663, Loss 0.572530, forward nfe 11324, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 040, Runtime 14.507922, Loss 0.575066, forward nfe 11620, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 041, Runtime 14.344950, Loss 0.480123, forward nfe 11916, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 042, Runtime 14.201618, Loss 0.599402, forward nfe 12212, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 043, Runtime 14.409267, Loss 0.512475, forward nfe 12508, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 044, Runtime 14.359094, Loss 0.492979, forward nfe 12804, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 045, Runtime 14.104072, Loss 0.539216, forward nfe 13100, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 046, Runtime 14.284573, Loss 0.534701, forward nfe 13396, backward nfe 0, Train: 0.8786, Val: 0.7625, Test: 0.7604, Best time: 18.2948
Epoch: 047, Runtime 14.648517, Loss 0.440399, forward nfe 13692, backward nfe 0, Train: 0.9500, Val: 0.7816, Test: 0.7665, Best time: 18.2948
Epoch: 048, Runtime 13.940329, Loss 0.435730, forward nfe 13988, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 049, Runtime 14.077376, Loss 0.400292, forward nfe 14284, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 050, Runtime 14.341723, Loss 0.432563, forward nfe 14580, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 051, Runtime 13.836569, Loss 0.468964, forward nfe 14876, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 052, Runtime 13.897552, Loss 0.524061, forward nfe 15172, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 053, Runtime 13.802073, Loss 0.577131, forward nfe 15468, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 054, Runtime 13.734341, Loss 0.494508, forward nfe 15764, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 055, Runtime 14.240493, Loss 0.518138, forward nfe 16060, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 056, Runtime 14.711537, Loss 0.596573, forward nfe 16356, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 057, Runtime 15.047121, Loss 0.527498, forward nfe 16652, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 058, Runtime 15.085726, Loss 0.477789, forward nfe 16948, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 059, Runtime 15.132223, Loss 0.535766, forward nfe 17244, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 060, Runtime 15.160182, Loss 0.436312, forward nfe 17540, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 061, Runtime 15.558170, Loss 0.523463, forward nfe 17836, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 062, Runtime 15.781485, Loss 0.387729, forward nfe 18132, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 063, Runtime 15.680093, Loss 0.422376, forward nfe 18428, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 064, Runtime 16.095734, Loss 0.393174, forward nfe 18724, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 065, Runtime 15.748976, Loss 0.542706, forward nfe 19020, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 066, Runtime 16.124614, Loss 0.453660, forward nfe 19316, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 067, Runtime 16.194898, Loss 0.418963, forward nfe 19612, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 068, Runtime 16.249553, Loss 0.320005, forward nfe 19908, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 069, Runtime 16.921772, Loss 0.436545, forward nfe 20204, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 070, Runtime 16.714696, Loss 0.403878, forward nfe 20500, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 071, Runtime 16.728238, Loss 0.382838, forward nfe 20796, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 072, Runtime 17.226573, Loss 0.399668, forward nfe 21092, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 073, Runtime 17.142521, Loss 0.382407, forward nfe 21388, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 074, Runtime 17.362672, Loss 0.453794, forward nfe 21684, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 075, Runtime 17.456043, Loss 0.436633, forward nfe 21980, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 076, Runtime 17.485516, Loss 0.419429, forward nfe 22276, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 077, Runtime 17.194185, Loss 0.492570, forward nfe 22572, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 078, Runtime 17.406448, Loss 0.407617, forward nfe 22868, backward nfe 0, Train: 0.9286, Val: 0.7912, Test: 0.7675, Best time: 18.2948
Epoch: 079, Runtime 17.443615, Loss 0.361699, forward nfe 23164, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 080, Runtime 13.345151, Loss 0.370717, forward nfe 23460, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 081, Runtime 14.162731, Loss 0.451971, forward nfe 23756, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 082, Runtime 13.610493, Loss 0.392092, forward nfe 24052, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 083, Runtime 13.865633, Loss 0.374917, forward nfe 24348, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 084, Runtime 13.866814, Loss 0.430407, forward nfe 24644, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 085, Runtime 14.231518, Loss 0.452504, forward nfe 24940, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 086, Runtime 14.730354, Loss 0.296995, forward nfe 25236, backward nfe 0, Train: 0.9571, Val: 0.8022, Test: 0.7878, Best time: 18.2948
Epoch: 087, Runtime 14.820838, Loss 0.324545, forward nfe 25532, backward nfe 0, Train: 0.9571, Val: 0.8118, Test: 0.8041, Best time: 18.2948
Epoch: 088, Runtime 13.706784, Loss 0.458750, forward nfe 25828, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 089, Runtime 13.386992, Loss 0.342723, forward nfe 26124, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 090, Runtime 13.956378, Loss 0.414702, forward nfe 26420, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 091, Runtime 13.630185, Loss 0.456599, forward nfe 26716, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 092, Runtime 13.806183, Loss 0.354329, forward nfe 27012, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 093, Runtime 14.028859, Loss 0.355869, forward nfe 27308, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 094, Runtime 14.329266, Loss 0.481373, forward nfe 27604, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 095, Runtime 15.063743, Loss 0.397988, forward nfe 27900, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 096, Runtime 14.162794, Loss 0.288730, forward nfe 28196, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 097, Runtime 14.944379, Loss 0.280582, forward nfe 28492, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 098, Runtime 14.477791, Loss 0.282522, forward nfe 28788, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
Epoch: 099, Runtime 14.532276, Loss 0.365559, forward nfe 29084, backward nfe 0, Train: 0.9643, Val: 0.8147, Test: 0.7959, Best time: 18.2948
best val accuracy 0.814706 with test accuracy 0.795939 at epoch 88 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.817258883248731
Entropy Threshold: 2 Test accuracy: 0.8111675126903554
Entropy Threshold: 1.6 Test accuracy: 0.8243654822335026
Entropy Threshold: 1.5 Test accuracy: 0.8105906313645621
Entropy Threshold: 1.4 Test accuracy: 0.8237704918032787
Entropy Threshold: 1.3 Test accuracy: 0.8171487603305785
Entropy Threshold: 1.2 Test accuracy: 0.8272251308900523
Entropy Threshold: 1.1 Test accuracy: 0.8387096774193549
Entropy Threshold: 0.9 Test accuracy: 0.8529411764705882
Entropy Threshold: 0.8 Test accuracy: 0.859338061465721
Entropy Threshold: 0.7 Test accuracy: 0.8678304239401496
Entropy Threshold: 0.6 Test accuracy: 0.8888888888888888
Entropy Threshold: 0.5 Test accuracy: 0.8940027894002789
Entropy Threshold: 0.4 Test accuracy: 0.9178082191780822
Entropy Threshold: 0.3 Test accuracy: 0.9320388349514563
Entropy Threshold: 0.2 Test accuracy: 0.9449378330373002
Entropy Threshold: 0.1 Test accuracy: 0.9537223340040242
