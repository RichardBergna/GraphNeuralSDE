[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 5.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 27.309551, Loss 2.957826, forward nfe 76, backward nfe 0, Train: 0.2643, Val: 0.2044, Test: 0.2457, Best time: 7.0000
Epoch: 002, Runtime 44.427725, Loss 31.039164, forward nfe 372, backward nfe 0, Train: 0.2643, Val: 0.2044, Test: 0.2457, Best time: 18.2948
Epoch: 003, Runtime 20.301427, Loss 3.374090, forward nfe 668, backward nfe 0, Train: 0.2643, Val: 0.2044, Test: 0.2457, Best time: 18.2948
Epoch: 004, Runtime 20.601325, Loss 4.181036, forward nfe 964, backward nfe 0, Train: 0.2643, Val: 0.2044, Test: 0.2457, Best time: 18.2948
Epoch: 005, Runtime 23.426112, Loss 4.375075, forward nfe 1260, backward nfe 0, Train: 0.2643, Val: 0.2044, Test: 0.2457, Best time: 18.2948
Epoch: 006, Runtime 26.216755, Loss 4.809402, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.2279, Test: 0.2091, Best time: 16.0000
Epoch: 007, Runtime 23.235406, Loss 3.742621, forward nfe 1852, backward nfe 0, Train: 0.1286, Val: 0.2485, Test: 0.2294, Best time: 15.0000
Epoch: 008, Runtime 24.006660, Loss 3.235387, forward nfe 2148, backward nfe 0, Train: 0.1214, Val: 0.2706, Test: 0.2487, Best time: 15.0000
Epoch: 009, Runtime 24.475944, Loss 3.091470, forward nfe 2444, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 13.0000
Epoch: 010, Runtime 23.933085, Loss 3.081701, forward nfe 2740, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 011, Runtime 25.047270, Loss 3.412955, forward nfe 3036, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 012, Runtime 25.163789, Loss 3.342540, forward nfe 3332, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 013, Runtime 24.946291, Loss 3.258001, forward nfe 3628, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 014, Runtime 24.978173, Loss 3.040545, forward nfe 3924, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 015, Runtime 26.444569, Loss 2.979149, forward nfe 4220, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 016, Runtime 26.976605, Loss 2.913200, forward nfe 4516, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 017, Runtime 27.919615, Loss 2.523690, forward nfe 4812, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 018, Runtime 29.047504, Loss 2.522458, forward nfe 5108, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 019, Runtime 29.506980, Loss 2.625442, forward nfe 5404, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 020, Runtime 30.883717, Loss 2.507926, forward nfe 5700, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 021, Runtime 30.464135, Loss 2.634977, forward nfe 5996, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 022, Runtime 30.289176, Loss 2.583617, forward nfe 6292, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 023, Runtime 31.581254, Loss 2.450377, forward nfe 6588, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 024, Runtime 29.661501, Loss 2.645990, forward nfe 6884, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 025, Runtime 30.413897, Loss 2.823139, forward nfe 7180, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 026, Runtime 30.405570, Loss 2.498354, forward nfe 7476, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 027, Runtime 29.693247, Loss 2.857108, forward nfe 7772, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 028, Runtime 30.801384, Loss 2.725360, forward nfe 8068, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 029, Runtime 31.499808, Loss 2.688831, forward nfe 8364, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 030, Runtime 30.419423, Loss 2.473590, forward nfe 8660, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 031, Runtime 30.880643, Loss 2.642640, forward nfe 8956, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 032, Runtime 20.757780, Loss 2.842567, forward nfe 9252, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 033, Runtime 19.822692, Loss 2.723655, forward nfe 9548, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 034, Runtime 20.205778, Loss 2.627390, forward nfe 9844, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 035, Runtime 20.858869, Loss 2.648898, forward nfe 10140, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 036, Runtime 21.864680, Loss 2.608355, forward nfe 10436, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 037, Runtime 22.496439, Loss 2.814536, forward nfe 10732, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 038, Runtime 22.143513, Loss 2.756930, forward nfe 11028, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 039, Runtime 23.327539, Loss 2.549556, forward nfe 11324, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 040, Runtime 24.442988, Loss 2.757900, forward nfe 11620, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 041, Runtime 24.651270, Loss 2.500129, forward nfe 11916, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 042, Runtime 24.726074, Loss 2.676214, forward nfe 12212, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 043, Runtime 25.480704, Loss 2.362124, forward nfe 12508, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 044, Runtime 25.315555, Loss 2.643510, forward nfe 12804, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 045, Runtime 25.476471, Loss 2.496112, forward nfe 13100, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 046, Runtime 26.124318, Loss 2.516975, forward nfe 13396, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 047, Runtime 26.920413, Loss 2.564977, forward nfe 13692, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 048, Runtime 27.500626, Loss 2.626443, forward nfe 13988, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 049, Runtime 26.970784, Loss 2.525321, forward nfe 14284, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 050, Runtime 27.369023, Loss 2.146016, forward nfe 14580, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 051, Runtime 27.625065, Loss 2.631929, forward nfe 14876, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 052, Runtime 27.671381, Loss 2.604448, forward nfe 15172, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 053, Runtime 27.625402, Loss 2.712493, forward nfe 15468, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 054, Runtime 28.234450, Loss 2.559209, forward nfe 15764, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 055, Runtime 28.421033, Loss 2.480739, forward nfe 16060, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 056, Runtime 19.211140, Loss 2.504406, forward nfe 16356, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 057, Runtime 18.361574, Loss 2.381555, forward nfe 16652, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 058, Runtime 18.789076, Loss 2.421421, forward nfe 16948, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 059, Runtime 19.757427, Loss 2.331295, forward nfe 17244, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 060, Runtime 19.684460, Loss 2.441472, forward nfe 17540, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 061, Runtime 20.157375, Loss 2.467396, forward nfe 17836, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 062, Runtime 20.408234, Loss 2.398973, forward nfe 18132, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 063, Runtime 21.351675, Loss 2.517575, forward nfe 18428, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 064, Runtime 21.557355, Loss 2.263719, forward nfe 18724, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 065, Runtime 21.704207, Loss 2.425012, forward nfe 19020, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 066, Runtime 22.134155, Loss 2.506726, forward nfe 19316, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 067, Runtime 22.999006, Loss 2.654258, forward nfe 19612, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 068, Runtime 23.028785, Loss 2.367156, forward nfe 19908, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 069, Runtime 23.280401, Loss 2.496854, forward nfe 20204, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 070, Runtime 23.656886, Loss 2.486504, forward nfe 20500, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 071, Runtime 24.588159, Loss 2.585569, forward nfe 20796, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 072, Runtime 24.741441, Loss 2.557497, forward nfe 21092, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 073, Runtime 23.948590, Loss 2.541576, forward nfe 21388, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 074, Runtime 24.268229, Loss 2.412896, forward nfe 21684, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 075, Runtime 24.809000, Loss 2.410510, forward nfe 21980, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 076, Runtime 24.796801, Loss 2.472302, forward nfe 22276, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 077, Runtime 24.955805, Loss 2.658328, forward nfe 22572, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 078, Runtime 25.394221, Loss 2.409443, forward nfe 22868, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 079, Runtime 25.584368, Loss 2.547742, forward nfe 23164, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 080, Runtime 25.692871, Loss 2.399929, forward nfe 23460, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 081, Runtime 25.901184, Loss 2.484776, forward nfe 23756, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 082, Runtime 26.227298, Loss 2.350805, forward nfe 24052, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 083, Runtime 26.745488, Loss 2.430415, forward nfe 24348, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 084, Runtime 26.647062, Loss 2.247298, forward nfe 24644, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 085, Runtime 26.764056, Loss 2.638069, forward nfe 24940, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 086, Runtime 26.910548, Loss 2.381149, forward nfe 25236, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 087, Runtime 27.363760, Loss 2.502073, forward nfe 25532, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 088, Runtime 27.367342, Loss 2.438135, forward nfe 25828, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 089, Runtime 27.576010, Loss 2.397331, forward nfe 26124, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 090, Runtime 23.866867, Loss 2.293189, forward nfe 26420, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 091, Runtime 17.901605, Loss 2.431693, forward nfe 26716, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 092, Runtime 18.182311, Loss 2.446188, forward nfe 27012, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 093, Runtime 18.717229, Loss 2.351991, forward nfe 27308, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 094, Runtime 19.609469, Loss 2.190883, forward nfe 27604, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 095, Runtime 20.407002, Loss 2.429310, forward nfe 27900, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 096, Runtime 20.742534, Loss 2.328740, forward nfe 28196, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 097, Runtime 20.936466, Loss 2.352655, forward nfe 28492, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 098, Runtime 21.809981, Loss 2.309294, forward nfe 28788, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
Epoch: 099, Runtime 22.726313, Loss 2.445065, forward nfe 29084, backward nfe 0, Train: 0.1143, Val: 0.2735, Test: 0.2487, Best time: 18.2948
best val accuracy 0.273529 with test accuracy 0.248731 at epoch 9 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1401015228426396
Entropy Threshold: 2 Test accuracy: 0.15634517766497463
Entropy Threshold: 1.6 Test accuracy: 0.16411824668705402
Entropy Threshold: 1.5 Test accuracy: 0.16213389121338911
Entropy Threshold: 1.4 Test accuracy: 0.16493656286043828
Entropy Threshold: 1.3 Test accuracy: 0.16148148148148148
Entropy Threshold: 1.2 Test accuracy: 0.13274336283185842
Entropy Threshold: 1.1 Test accuracy: 0.12222222222222222
Entropy Threshold: 0.9 Test accuracy: 0.18333333333333332
Entropy Threshold: 0.8 Test accuracy: 0.1388888888888889
Entropy Threshold: 0.7 Test accuracy: 0.17647058823529413
Entropy Threshold: 0.6 Test accuracy: 0.3
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.5
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: 0.0
