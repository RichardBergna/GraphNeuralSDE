[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 15.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 75.918552, Loss 25.691116, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.0772, Test: 0.0944, Best time: 15.0000
Epoch: 002, Runtime 124.570725, Loss 4374.747070, forward nfe 372, backward nfe 0, Train: 0.1357, Val: 0.1559, Test: 0.1401, Best time: 18.2948
Epoch: 003, Runtime 49.486627, Loss 18.039383, forward nfe 668, backward nfe 0, Train: 0.1357, Val: 0.1559, Test: 0.1401, Best time: 18.2948
Epoch: 004, Runtime 46.087427, Loss 21.070551, forward nfe 964, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 005, Runtime 46.817326, Loss 23.870018, forward nfe 1260, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 006, Runtime 54.081139, Loss 25.579079, forward nfe 1556, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 007, Runtime 60.151130, Loss 25.719582, forward nfe 1852, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 008, Runtime 61.700279, Loss 27.066355, forward nfe 2148, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 009, Runtime 61.904340, Loss 26.365322, forward nfe 2444, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 010, Runtime 59.012462, Loss 23.678143, forward nfe 2740, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 011, Runtime 54.703977, Loss 22.847706, forward nfe 3036, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 012, Runtime 58.769819, Loss 22.225704, forward nfe 3332, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 013, Runtime 62.308541, Loss 22.108192, forward nfe 3628, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 014, Runtime 57.750690, Loss 21.742546, forward nfe 3924, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 015, Runtime 60.926822, Loss 19.465105, forward nfe 4220, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 016, Runtime 57.014832, Loss 16.412666, forward nfe 4516, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 017, Runtime 50.269393, Loss 13.336875, forward nfe 4812, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 018, Runtime 53.342497, Loss 12.695260, forward nfe 5108, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 019, Runtime 53.664411, Loss 12.069443, forward nfe 5404, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 020, Runtime 49.683491, Loss 10.556718, forward nfe 5700, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 021, Runtime 51.881769, Loss 9.271599, forward nfe 5996, backward nfe 0, Train: 0.1286, Val: 0.1632, Test: 0.1401, Best time: 18.2948
Epoch: 022, Runtime 49.523718, Loss 8.741385, forward nfe 6292, backward nfe 0, Train: 0.1071, Val: 0.1654, Test: 0.1533, Best time: 18.2948
Epoch: 023, Runtime 40.960302, Loss 7.273649, forward nfe 6588, backward nfe 0, Train: 0.1071, Val: 0.1654, Test: 0.1533, Best time: 18.2948
Epoch: 024, Runtime 41.778255, Loss 7.867726, forward nfe 6884, backward nfe 0, Train: 0.1071, Val: 0.1654, Test: 0.1533, Best time: 18.2948
Epoch: 025, Runtime 44.349116, Loss 7.502438, forward nfe 7180, backward nfe 0, Train: 0.1071, Val: 0.1654, Test: 0.1533, Best time: 18.2948
Epoch: 026, Runtime 45.187060, Loss 7.617028, forward nfe 7476, backward nfe 0, Train: 0.1143, Val: 0.1699, Test: 0.1888, Best time: 18.2948
Epoch: 027, Runtime 39.602872, Loss 7.728636, forward nfe 7772, backward nfe 0, Train: 0.1714, Val: 0.1831, Test: 0.1939, Best time: 18.2948
Epoch: 028, Runtime 40.444939, Loss 8.500434, forward nfe 8068, backward nfe 0, Train: 0.1143, Val: 0.1875, Test: 0.1959, Best time: 18.2948
Epoch: 029, Runtime 39.595414, Loss 8.642088, forward nfe 8364, backward nfe 0, Train: 0.1571, Val: 0.2059, Test: 0.2030, Best time: 18.2948
Epoch: 030, Runtime 39.121351, Loss 8.205921, forward nfe 8660, backward nfe 0, Train: 0.1286, Val: 0.2081, Test: 0.2071, Best time: 18.2948
Epoch: 031, Runtime 38.530710, Loss 7.568871, forward nfe 8956, backward nfe 0, Train: 0.1286, Val: 0.2081, Test: 0.2071, Best time: 18.2948
Epoch: 032, Runtime 42.243238, Loss 7.285847, forward nfe 9252, backward nfe 0, Train: 0.1214, Val: 0.2125, Test: 0.2183, Best time: 18.2948
Epoch: 033, Runtime 37.830891, Loss 7.454616, forward nfe 9548, backward nfe 0, Train: 0.1214, Val: 0.2125, Test: 0.2183, Best time: 18.2948
Epoch: 034, Runtime 41.370312, Loss 7.777005, forward nfe 9844, backward nfe 0, Train: 0.1214, Val: 0.2125, Test: 0.2183, Best time: 18.2948
Epoch: 035, Runtime 43.799741, Loss 6.927879, forward nfe 10140, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 036, Runtime 39.192315, Loss 6.008238, forward nfe 10436, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 037, Runtime 40.035331, Loss 6.428060, forward nfe 10732, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 038, Runtime 40.445630, Loss 6.194290, forward nfe 11028, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 039, Runtime 41.540423, Loss 5.737691, forward nfe 11324, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 040, Runtime 44.705031, Loss 6.203840, forward nfe 11620, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 041, Runtime 45.105706, Loss 5.556047, forward nfe 11916, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 042, Runtime 47.438365, Loss 5.481798, forward nfe 12212, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 043, Runtime 49.920624, Loss 5.639507, forward nfe 12508, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 044, Runtime 46.633964, Loss 5.585579, forward nfe 12804, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 045, Runtime 37.532111, Loss 5.440260, forward nfe 13100, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 046, Runtime 39.588819, Loss 5.826606, forward nfe 13396, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 047, Runtime 40.927710, Loss 5.556109, forward nfe 13692, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 048, Runtime 42.004562, Loss 5.991573, forward nfe 13988, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 049, Runtime 44.106651, Loss 5.552231, forward nfe 14284, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 050, Runtime 46.646093, Loss 6.055985, forward nfe 14580, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 051, Runtime 48.426085, Loss 5.291057, forward nfe 14876, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 052, Runtime 48.321372, Loss 5.399160, forward nfe 15172, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 053, Runtime 45.315839, Loss 5.421598, forward nfe 15468, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 054, Runtime 36.876278, Loss 5.393916, forward nfe 15764, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 055, Runtime 38.465074, Loss 5.319442, forward nfe 16060, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 056, Runtime 43.204101, Loss 5.165599, forward nfe 16356, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 057, Runtime 44.205323, Loss 5.219878, forward nfe 16652, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 058, Runtime 45.399568, Loss 5.250602, forward nfe 16948, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 059, Runtime 47.765165, Loss 5.216973, forward nfe 17244, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 060, Runtime 49.062037, Loss 4.955465, forward nfe 17540, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 061, Runtime 47.413278, Loss 5.367955, forward nfe 17836, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 062, Runtime 39.533121, Loss 5.162125, forward nfe 18132, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 063, Runtime 39.162961, Loss 5.138395, forward nfe 18428, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 064, Runtime 42.095232, Loss 5.109272, forward nfe 18724, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 065, Runtime 43.565163, Loss 5.094354, forward nfe 19020, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 066, Runtime 45.847318, Loss 5.273850, forward nfe 19316, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 067, Runtime 46.354265, Loss 4.939249, forward nfe 19612, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 068, Runtime 48.126543, Loss 4.887484, forward nfe 19908, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 069, Runtime 48.962159, Loss 5.212891, forward nfe 20204, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 070, Runtime 42.835418, Loss 4.920461, forward nfe 20500, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 071, Runtime 37.591233, Loss 5.041765, forward nfe 20796, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 072, Runtime 38.841501, Loss 4.858764, forward nfe 21092, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 073, Runtime 41.189825, Loss 5.104593, forward nfe 21388, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 074, Runtime 42.429975, Loss 4.871605, forward nfe 21684, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 075, Runtime 44.713310, Loss 5.110985, forward nfe 21980, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 076, Runtime 46.633818, Loss 5.122510, forward nfe 22276, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 077, Runtime 48.151052, Loss 4.869609, forward nfe 22572, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 078, Runtime 49.528744, Loss 4.928749, forward nfe 22868, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 079, Runtime 49.275377, Loss 4.885347, forward nfe 23164, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 080, Runtime 39.540693, Loss 5.147126, forward nfe 23460, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 081, Runtime 40.986503, Loss 4.771667, forward nfe 23756, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 082, Runtime 42.711992, Loss 5.380425, forward nfe 24052, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 083, Runtime 42.858617, Loss 4.844864, forward nfe 24348, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 084, Runtime 45.812845, Loss 4.549851, forward nfe 24644, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 085, Runtime 46.672979, Loss 4.451427, forward nfe 24940, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 086, Runtime 48.503256, Loss 4.870283, forward nfe 25236, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 087, Runtime 49.610739, Loss 4.538178, forward nfe 25532, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 088, Runtime 51.628289, Loss 4.494857, forward nfe 25828, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 089, Runtime 53.009572, Loss 4.711566, forward nfe 26124, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 090, Runtime 49.687894, Loss 4.386070, forward nfe 26420, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 091, Runtime 38.899205, Loss 4.834328, forward nfe 26716, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 092, Runtime 40.628061, Loss 4.849456, forward nfe 27012, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 093, Runtime 42.327472, Loss 4.530576, forward nfe 27308, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 094, Runtime 44.047351, Loss 4.919415, forward nfe 27604, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 095, Runtime 46.302353, Loss 4.938899, forward nfe 27900, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 096, Runtime 46.209002, Loss 4.300163, forward nfe 28196, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 097, Runtime 47.639588, Loss 4.824827, forward nfe 28492, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 098, Runtime 51.279802, Loss 4.647317, forward nfe 28788, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
Epoch: 099, Runtime 52.578717, Loss 4.866580, forward nfe 29084, backward nfe 0, Train: 0.0929, Val: 0.2162, Test: 0.2071, Best time: 18.2948
best val accuracy 0.216176 with test accuracy 0.207107 at epoch 35 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.25279187817258886
Entropy Threshold: 2 Test accuracy: 0.25279187817258886
Entropy Threshold: 1.6 Test accuracy: 0.25573770491803277
Entropy Threshold: 1.5 Test accuracy: 0.27808988764044945
Entropy Threshold: 1.4 Test accuracy: 0.2629399585921325
Entropy Threshold: 1.3 Test accuracy: 0.3
Entropy Threshold: 1.2 Test accuracy: 0.3163265306122449
Entropy Threshold: 1.1 Test accuracy: 0.3283582089552239
Entropy Threshold: 0.9 Test accuracy: 0.5
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
