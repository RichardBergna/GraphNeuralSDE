[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 12.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 61.832684, Loss 19.569340, forward nfe 76, backward nfe 0, Train: 0.1286, Val: 0.3015, Test: 0.2569, Best time: 54.0000
Epoch: 002, Runtime 101.788718, Loss 460.912933, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2812, Best time: 36.0000
Epoch: 003, Runtime 31.789874, Loss 6.291438, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2812, Best time: 18.2948
Epoch: 004, Runtime 33.966974, Loss 6.841634, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.3140, Test: 0.2812, Best time: 18.2948
Epoch: 005, Runtime 36.124113, Loss 7.482644, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.3147, Test: 0.2832, Best time: 2.0000
Epoch: 006, Runtime 35.175169, Loss 7.844721, forward nfe 1556, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 26.0000
Epoch: 007, Runtime 35.195931, Loss 7.801177, forward nfe 1852, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 008, Runtime 38.808098, Loss 7.595203, forward nfe 2148, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 009, Runtime 39.719090, Loss 6.996211, forward nfe 2444, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 010, Runtime 40.970620, Loss 6.372812, forward nfe 2740, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 011, Runtime 43.536826, Loss 5.586668, forward nfe 3036, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 012, Runtime 44.341703, Loss 4.791267, forward nfe 3332, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 013, Runtime 45.633753, Loss 4.385501, forward nfe 3628, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 014, Runtime 45.893378, Loss 4.626480, forward nfe 3924, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 015, Runtime 43.329774, Loss 3.998361, forward nfe 4220, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 016, Runtime 33.864171, Loss 4.367067, forward nfe 4516, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 017, Runtime 34.354287, Loss 4.434133, forward nfe 4812, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 018, Runtime 35.927937, Loss 4.460803, forward nfe 5108, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 019, Runtime 37.473525, Loss 4.688183, forward nfe 5404, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 020, Runtime 38.522457, Loss 4.519552, forward nfe 5700, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 021, Runtime 39.922941, Loss 4.081910, forward nfe 5996, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 022, Runtime 40.911477, Loss 4.212502, forward nfe 6292, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 023, Runtime 40.216636, Loss 4.261770, forward nfe 6588, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 024, Runtime 40.800985, Loss 4.142534, forward nfe 6884, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 025, Runtime 41.310121, Loss 3.838098, forward nfe 7180, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 026, Runtime 42.623756, Loss 4.153506, forward nfe 7476, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 027, Runtime 38.509898, Loss 3.921033, forward nfe 7772, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 028, Runtime 29.227292, Loss 3.869352, forward nfe 8068, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 029, Runtime 30.752850, Loss 3.698610, forward nfe 8364, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 030, Runtime 32.088597, Loss 3.913031, forward nfe 8660, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 031, Runtime 33.591064, Loss 3.589289, forward nfe 8956, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 032, Runtime 35.550292, Loss 3.581735, forward nfe 9252, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 033, Runtime 36.533870, Loss 3.304099, forward nfe 9548, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 034, Runtime 37.464669, Loss 3.833868, forward nfe 9844, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 035, Runtime 37.147650, Loss 3.672145, forward nfe 10140, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 036, Runtime 39.928889, Loss 3.580358, forward nfe 10436, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 037, Runtime 41.008464, Loss 3.523172, forward nfe 10732, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 038, Runtime 41.693300, Loss 3.480165, forward nfe 11028, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 039, Runtime 42.571273, Loss 3.526518, forward nfe 11324, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 040, Runtime 43.201051, Loss 3.421759, forward nfe 11620, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 041, Runtime 37.256550, Loss 3.336787, forward nfe 11916, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 042, Runtime 27.768824, Loss 3.721422, forward nfe 12212, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 043, Runtime 29.415751, Loss 3.532847, forward nfe 12508, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 044, Runtime 30.649060, Loss 3.683785, forward nfe 12804, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 045, Runtime 32.119376, Loss 3.582931, forward nfe 13100, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 046, Runtime 33.034125, Loss 3.688758, forward nfe 13396, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 047, Runtime 34.755668, Loss 3.511915, forward nfe 13692, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 048, Runtime 35.081908, Loss 3.547804, forward nfe 13988, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 049, Runtime 35.864308, Loss 3.769556, forward nfe 14284, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 050, Runtime 36.996354, Loss 3.730049, forward nfe 14580, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 051, Runtime 38.487397, Loss 3.454479, forward nfe 14876, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 052, Runtime 38.687343, Loss 3.359903, forward nfe 15172, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 053, Runtime 39.928962, Loss 3.455005, forward nfe 15468, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 054, Runtime 36.128268, Loss 3.758149, forward nfe 15764, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 055, Runtime 27.669910, Loss 3.521567, forward nfe 16060, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 056, Runtime 28.813587, Loss 3.592207, forward nfe 16356, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 057, Runtime 29.691650, Loss 3.525940, forward nfe 16652, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 058, Runtime 30.583029, Loss 3.789155, forward nfe 16948, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 059, Runtime 32.233160, Loss 3.043070, forward nfe 17244, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 060, Runtime 32.694449, Loss 3.340734, forward nfe 17540, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 061, Runtime 33.355414, Loss 3.056486, forward nfe 17836, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 062, Runtime 35.636025, Loss 3.604677, forward nfe 18132, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 063, Runtime 36.698884, Loss 3.373846, forward nfe 18428, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 064, Runtime 37.562306, Loss 3.319653, forward nfe 18724, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 065, Runtime 38.414345, Loss 3.001009, forward nfe 19020, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 066, Runtime 40.043073, Loss 3.383727, forward nfe 19316, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 067, Runtime 40.330305, Loss 3.296921, forward nfe 19612, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 068, Runtime 36.443208, Loss 3.413489, forward nfe 19908, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 069, Runtime 27.476624, Loss 3.294500, forward nfe 20204, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 070, Runtime 29.087572, Loss 3.401090, forward nfe 20500, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 071, Runtime 29.911372, Loss 2.998726, forward nfe 20796, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 072, Runtime 30.988093, Loss 3.415144, forward nfe 21092, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 073, Runtime 32.208824, Loss 3.286173, forward nfe 21388, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 074, Runtime 33.063436, Loss 3.402493, forward nfe 21684, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 075, Runtime 34.273695, Loss 3.433056, forward nfe 21980, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 076, Runtime 35.597733, Loss 3.061037, forward nfe 22276, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 077, Runtime 36.228659, Loss 3.315522, forward nfe 22572, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 078, Runtime 37.516441, Loss 3.467005, forward nfe 22868, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 079, Runtime 37.453527, Loss 3.496985, forward nfe 23164, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 080, Runtime 39.101484, Loss 3.470536, forward nfe 23460, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 081, Runtime 39.482028, Loss 3.151759, forward nfe 23756, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 082, Runtime 35.386436, Loss 3.231484, forward nfe 24052, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 083, Runtime 26.856656, Loss 3.192616, forward nfe 24348, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 084, Runtime 27.950611, Loss 3.433022, forward nfe 24644, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 085, Runtime 29.170457, Loss 3.404189, forward nfe 24940, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 086, Runtime 30.765720, Loss 3.450359, forward nfe 25236, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 087, Runtime 31.977438, Loss 3.416881, forward nfe 25532, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 088, Runtime 33.329442, Loss 3.422696, forward nfe 25828, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 089, Runtime 34.383514, Loss 3.325811, forward nfe 26124, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 090, Runtime 35.373957, Loss 3.452118, forward nfe 26420, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 091, Runtime 36.254374, Loss 3.112137, forward nfe 26716, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 092, Runtime 37.083282, Loss 3.386435, forward nfe 27012, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 093, Runtime 38.423918, Loss 3.236501, forward nfe 27308, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 094, Runtime 39.176743, Loss 3.676942, forward nfe 27604, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 095, Runtime 39.578582, Loss 3.166145, forward nfe 27900, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 096, Runtime 42.328385, Loss 3.231309, forward nfe 28196, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 097, Runtime 36.758283, Loss 3.318700, forward nfe 28492, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 098, Runtime 27.566479, Loss 3.128380, forward nfe 28788, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
Epoch: 099, Runtime 28.649864, Loss 3.578261, forward nfe 29084, backward nfe 0, Train: 0.1357, Val: 0.3213, Test: 0.2802, Best time: 18.2948
best val accuracy 0.321324 with test accuracy 0.280203 at epoch 6 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.18071065989847715
Entropy Threshold: 2 Test accuracy: 0.18274111675126903
Entropy Threshold: 1.6 Test accuracy: 0.18071065989847715
Entropy Threshold: 1.5 Test accuracy: 0.17515274949083504
Entropy Threshold: 1.4 Test accuracy: 0.17484008528784648
Entropy Threshold: 1.3 Test accuracy: 0.16955445544554457
Entropy Threshold: 1.2 Test accuracy: 0.16758747697974216
Entropy Threshold: 1.1 Test accuracy: 0.16971279373368145
Entropy Threshold: 0.9 Test accuracy: 0.13636363636363635
Entropy Threshold: 0.8 Test accuracy: 0.21428571428571427
Entropy Threshold: 0.7 Test accuracy: 0.07142857142857142
Entropy Threshold: 0.6 Test accuracy: 0.5
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
