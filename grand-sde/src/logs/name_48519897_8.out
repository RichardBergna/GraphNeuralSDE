[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.01
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 7.608495, Loss 1.953455, forward nfe 76, backward nfe 0, Train: 0.6857, Val: 0.5706, Test: 0.5340, Best time: 4.0000
Epoch: 002, Runtime 7.560936, Loss 1.909493, forward nfe 372, backward nfe 0, Train: 0.7500, Val: 0.6551, Test: 0.6274, Best time: 3.0000
Epoch: 003, Runtime 7.658633, Loss 1.793750, forward nfe 668, backward nfe 0, Train: 0.8571, Val: 0.7824, Test: 0.7614, Best time: 7.0000
Epoch: 004, Runtime 7.229559, Loss 1.601189, forward nfe 964, backward nfe 0, Train: 0.8571, Val: 0.7824, Test: 0.7614, Best time: 18.2948
Epoch: 005, Runtime 7.370141, Loss 1.383319, forward nfe 1260, backward nfe 0, Train: 0.8571, Val: 0.7824, Test: 0.7614, Best time: 18.2948
Epoch: 006, Runtime 7.907826, Loss 1.116341, forward nfe 1556, backward nfe 0, Train: 0.8929, Val: 0.7868, Test: 0.7939, Best time: 49.0000
Epoch: 007, Runtime 7.755553, Loss 0.874817, forward nfe 1852, backward nfe 0, Train: 0.9000, Val: 0.8125, Test: 0.8193, Best time: 53.0000
Epoch: 008, Runtime 7.745206, Loss 0.602258, forward nfe 2148, backward nfe 0, Train: 0.9357, Val: 0.8243, Test: 0.8325, Best time: 31.0000
Epoch: 009, Runtime 7.366934, Loss 0.466045, forward nfe 2444, backward nfe 0, Train: 0.9357, Val: 0.8243, Test: 0.8325, Best time: 18.2948
Epoch: 010, Runtime 7.273441, Loss 0.351925, forward nfe 2740, backward nfe 0, Train: 0.9357, Val: 0.8243, Test: 0.8325, Best time: 18.2948
Epoch: 011, Runtime 7.492321, Loss 0.271987, forward nfe 3036, backward nfe 0, Train: 0.9357, Val: 0.8243, Test: 0.8325, Best time: 18.2948
Epoch: 012, Runtime 7.580662, Loss 0.265555, forward nfe 3332, backward nfe 0, Train: 0.9357, Val: 0.8243, Test: 0.8325, Best time: 18.2948
Epoch: 013, Runtime 7.868748, Loss 0.193196, forward nfe 3628, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 54.8843
Epoch: 014, Runtime 7.386664, Loss 0.190733, forward nfe 3924, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 015, Runtime 7.349115, Loss 0.249335, forward nfe 4220, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 016, Runtime 7.499462, Loss 0.169476, forward nfe 4516, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 017, Runtime 7.585145, Loss 0.192624, forward nfe 4812, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 018, Runtime 7.509811, Loss 0.262038, forward nfe 5108, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 019, Runtime 7.502897, Loss 0.207354, forward nfe 5404, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 020, Runtime 7.685042, Loss 0.204210, forward nfe 5700, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 021, Runtime 7.646878, Loss 0.199274, forward nfe 5996, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 022, Runtime 7.862476, Loss 0.170345, forward nfe 6292, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 023, Runtime 7.713831, Loss 0.179922, forward nfe 6588, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 024, Runtime 7.431580, Loss 0.210269, forward nfe 6884, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 025, Runtime 7.268311, Loss 0.177428, forward nfe 7180, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 026, Runtime 7.344917, Loss 0.206565, forward nfe 7476, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 027, Runtime 7.504466, Loss 0.170520, forward nfe 7772, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 028, Runtime 7.527790, Loss 0.177978, forward nfe 8068, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 029, Runtime 7.508574, Loss 0.154225, forward nfe 8364, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 030, Runtime 7.543659, Loss 0.193101, forward nfe 8660, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 031, Runtime 7.506390, Loss 0.202435, forward nfe 8956, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 032, Runtime 7.618865, Loss 0.156321, forward nfe 9252, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 033, Runtime 7.736950, Loss 0.159626, forward nfe 9548, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 034, Runtime 7.579820, Loss 0.189895, forward nfe 9844, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 035, Runtime 7.805310, Loss 0.146033, forward nfe 10140, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 036, Runtime 7.283984, Loss 0.155654, forward nfe 10436, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 037, Runtime 7.362411, Loss 0.181139, forward nfe 10732, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 038, Runtime 7.366361, Loss 0.141465, forward nfe 11028, backward nfe 0, Train: 0.9286, Val: 0.8250, Test: 0.8193, Best time: 18.2948
Epoch: 039, Runtime 7.600969, Loss 0.146929, forward nfe 11324, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 040, Runtime 7.166706, Loss 0.139579, forward nfe 11620, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 041, Runtime 7.279369, Loss 0.169164, forward nfe 11916, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 042, Runtime 7.275584, Loss 0.148243, forward nfe 12212, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 043, Runtime 7.381947, Loss 0.149067, forward nfe 12508, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 044, Runtime 7.369311, Loss 0.135606, forward nfe 12804, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 045, Runtime 7.432021, Loss 0.112952, forward nfe 13100, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 046, Runtime 7.508408, Loss 0.106934, forward nfe 13396, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 047, Runtime 7.517307, Loss 0.164981, forward nfe 13692, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 048, Runtime 7.639789, Loss 0.142119, forward nfe 13988, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 049, Runtime 7.624096, Loss 0.110758, forward nfe 14284, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 050, Runtime 7.176287, Loss 0.147140, forward nfe 14580, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 051, Runtime 7.180075, Loss 0.111379, forward nfe 14876, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 052, Runtime 7.183779, Loss 0.155658, forward nfe 15172, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 053, Runtime 7.284306, Loss 0.101605, forward nfe 15468, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 054, Runtime 7.380860, Loss 0.109379, forward nfe 15764, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 055, Runtime 7.413951, Loss 0.118264, forward nfe 16060, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 056, Runtime 7.415651, Loss 0.155182, forward nfe 16356, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 057, Runtime 7.608163, Loss 0.080462, forward nfe 16652, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 058, Runtime 7.572416, Loss 0.102381, forward nfe 16948, backward nfe 0, Train: 0.9500, Val: 0.8279, Test: 0.8142, Best time: 18.2948
Epoch: 059, Runtime 7.833409, Loss 0.156833, forward nfe 17244, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 23.0000
Epoch: 060, Runtime 7.082024, Loss 0.109014, forward nfe 17540, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 061, Runtime 7.167630, Loss 0.162717, forward nfe 17836, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 062, Runtime 7.219813, Loss 0.130994, forward nfe 18132, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 063, Runtime 7.364974, Loss 0.141449, forward nfe 18428, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 064, Runtime 7.373177, Loss 0.101300, forward nfe 18724, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 065, Runtime 7.259357, Loss 0.228390, forward nfe 19020, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 066, Runtime 7.391051, Loss 0.145761, forward nfe 19316, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 067, Runtime 7.425592, Loss 0.179931, forward nfe 19612, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 068, Runtime 7.463986, Loss 0.152298, forward nfe 19908, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 069, Runtime 7.493797, Loss 0.139509, forward nfe 20204, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 070, Runtime 7.148328, Loss 0.150626, forward nfe 20500, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 071, Runtime 7.156450, Loss 0.105683, forward nfe 20796, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 072, Runtime 7.130708, Loss 0.133298, forward nfe 21092, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 073, Runtime 7.304663, Loss 0.191073, forward nfe 21388, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 074, Runtime 7.335639, Loss 0.120427, forward nfe 21684, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 075, Runtime 7.391901, Loss 0.130923, forward nfe 21980, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 076, Runtime 7.322383, Loss 0.148867, forward nfe 22276, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 077, Runtime 7.560731, Loss 0.109892, forward nfe 22572, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 078, Runtime 7.448033, Loss 0.115513, forward nfe 22868, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 079, Runtime 7.584755, Loss 0.085290, forward nfe 23164, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 080, Runtime 7.534273, Loss 0.107392, forward nfe 23460, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 081, Runtime 7.661483, Loss 0.136334, forward nfe 23756, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 082, Runtime 7.212903, Loss 0.126323, forward nfe 24052, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 083, Runtime 7.155530, Loss 0.117776, forward nfe 24348, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 084, Runtime 7.124918, Loss 0.095280, forward nfe 24644, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 085, Runtime 7.327003, Loss 0.117612, forward nfe 24940, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 086, Runtime 7.378118, Loss 0.123567, forward nfe 25236, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 087, Runtime 7.348063, Loss 0.154382, forward nfe 25532, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 088, Runtime 7.531406, Loss 0.101745, forward nfe 25828, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 089, Runtime 7.363676, Loss 0.104634, forward nfe 26124, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 090, Runtime 7.470638, Loss 0.087703, forward nfe 26420, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 091, Runtime 7.581710, Loss 0.088365, forward nfe 26716, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 092, Runtime 7.518193, Loss 0.077792, forward nfe 27012, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 093, Runtime 7.595357, Loss 0.098676, forward nfe 27308, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 094, Runtime 7.196801, Loss 0.067102, forward nfe 27604, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 095, Runtime 7.064509, Loss 0.069190, forward nfe 27900, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 096, Runtime 7.200723, Loss 0.073971, forward nfe 28196, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 097, Runtime 7.266292, Loss 0.079530, forward nfe 28492, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 098, Runtime 7.189131, Loss 0.066633, forward nfe 28788, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
Epoch: 099, Runtime 7.353664, Loss 0.091019, forward nfe 29084, backward nfe 0, Train: 0.9857, Val: 0.8294, Test: 0.8071, Best time: 18.2948
best val accuracy 0.829412 with test accuracy 0.807107 at epoch 59 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8131979695431472
Entropy Threshold: 2 Test accuracy: 0.8142131979695432
Entropy Threshold: 1.6 Test accuracy: 0.8121827411167513
Entropy Threshold: 1.5 Test accuracy: 0.8142131979695432
Entropy Threshold: 1.4 Test accuracy: 0.8168870803662258
Entropy Threshold: 1.3 Test accuracy: 0.817533129459735
Entropy Threshold: 1.2 Test accuracy: 0.819672131147541
Entropy Threshold: 1.1 Test accuracy: 0.8246887966804979
Entropy Threshold: 0.9 Test accuracy: 0.8478260869565217
Entropy Threshold: 0.8 Test accuracy: 0.8582589285714286
Entropy Threshold: 0.7 Test accuracy: 0.8735362997658079
Entropy Threshold: 0.6 Test accuracy: 0.8902439024390244
Entropy Threshold: 0.5 Test accuracy: 0.908150064683053
Entropy Threshold: 0.4 Test accuracy: 0.9144385026737968
Entropy Threshold: 0.3 Test accuracy: 0.9225449515905948
Entropy Threshold: 0.2 Test accuracy: 0.9315866084425036
Entropy Threshold: 0.1 Test accuracy: 0.9502407704654896
