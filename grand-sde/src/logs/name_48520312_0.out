[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 11.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 49.910719, Loss 11.438260, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 002, Runtime 138.941967, Loss 74.784843, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 003, Runtime 28.535826, Loss 5.200791, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 004, Runtime 28.002632, Loss 4.972829, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 005, Runtime 29.079742, Loss 5.215414, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 006, Runtime 30.396306, Loss 5.104164, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 007, Runtime 32.255894, Loss 4.743052, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 008, Runtime 35.584129, Loss 4.511766, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 009, Runtime 38.362233, Loss 4.339681, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 010, Runtime 40.606890, Loss 4.071297, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 011, Runtime 42.264723, Loss 4.205062, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 012, Runtime 45.001478, Loss 4.227931, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 013, Runtime 46.696142, Loss 4.340080, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 014, Runtime 46.357227, Loss 4.137033, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 015, Runtime 47.867899, Loss 4.280886, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 016, Runtime 41.841408, Loss 3.885311, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 017, Runtime 31.819731, Loss 4.403677, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 018, Runtime 32.928235, Loss 3.965468, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 019, Runtime 33.990653, Loss 3.691962, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 020, Runtime 35.191700, Loss 4.048990, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 021, Runtime 35.694896, Loss 3.878273, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 022, Runtime 37.457887, Loss 4.108863, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 023, Runtime 37.172055, Loss 3.958209, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 024, Runtime 39.137399, Loss 3.659724, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 025, Runtime 39.472811, Loss 3.685059, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 026, Runtime 41.664293, Loss 3.974895, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 027, Runtime 42.095680, Loss 3.920961, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 028, Runtime 42.476949, Loss 4.128370, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 029, Runtime 37.956624, Loss 3.857621, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 030, Runtime 29.465789, Loss 4.038065, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 031, Runtime 30.693668, Loss 3.837970, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 032, Runtime 31.695715, Loss 3.995313, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 033, Runtime 32.818736, Loss 3.820539, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 034, Runtime 33.717192, Loss 4.211459, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 035, Runtime 34.064250, Loss 4.078452, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 036, Runtime 36.079178, Loss 3.718169, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 037, Runtime 37.022756, Loss 3.829731, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 038, Runtime 37.465903, Loss 4.062885, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 039, Runtime 38.928277, Loss 3.813028, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 040, Runtime 36.333163, Loss 3.448065, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 041, Runtime 28.895950, Loss 3.411185, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 042, Runtime 30.135919, Loss 3.565131, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 043, Runtime 31.209414, Loss 3.813627, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 044, Runtime 32.224531, Loss 3.830012, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 045, Runtime 31.726157, Loss 3.505680, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 046, Runtime 32.314259, Loss 3.523849, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 047, Runtime 33.543026, Loss 3.376349, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 048, Runtime 35.915251, Loss 3.680007, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 049, Runtime 36.111169, Loss 3.563567, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 050, Runtime 37.529846, Loss 3.172076, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 051, Runtime 38.294357, Loss 3.900825, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 052, Runtime 39.632938, Loss 3.273178, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 053, Runtime 40.372447, Loss 3.420253, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 054, Runtime 41.105208, Loss 3.357622, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 055, Runtime 41.464222, Loss 3.455682, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 056, Runtime 42.233482, Loss 3.573198, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 057, Runtime 40.969059, Loss 3.621572, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 058, Runtime 42.292454, Loss 3.214882, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 059, Runtime 35.570966, Loss 3.360922, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 060, Runtime 28.952226, Loss 3.221867, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 061, Runtime 29.923549, Loss 3.523511, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 062, Runtime 31.074347, Loss 3.280559, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 063, Runtime 33.061963, Loss 3.714872, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 064, Runtime 33.849413, Loss 3.267958, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.2941, Test: 0.3025, Best time: 18.2948
Epoch: 065, Runtime 35.443975, Loss 3.537696, forward nfe 19020, backward nfe 0, Train: 0.1500, Val: 0.2949, Test: 0.2904, Best time: 28.0000
Epoch: 066, Runtime 27.371257, Loss 3.149920, forward nfe 19316, backward nfe 0, Train: 0.1500, Val: 0.2949, Test: 0.2904, Best time: 18.2948
Epoch: 067, Runtime 29.164116, Loss 3.508682, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.2963, Test: 0.2914, Best time: 29.0000
Epoch: 068, Runtime 27.530377, Loss 3.310036, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.2963, Test: 0.2914, Best time: 18.2948
Epoch: 069, Runtime 28.911384, Loss 3.399800, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.2971, Test: 0.2904, Best time: 29.0000
Epoch: 070, Runtime 26.388164, Loss 3.321586, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.2971, Test: 0.2904, Best time: 18.2948
Epoch: 071, Runtime 28.374250, Loss 3.430038, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.2978, Test: 0.2893, Best time: 28.0000
Epoch: 072, Runtime 25.369713, Loss 3.342603, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.2985, Test: 0.2914, Best time: 28.0000
Epoch: 073, Runtime 25.409323, Loss 3.417395, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.2993, Test: 0.2924, Best time: 28.0000
Epoch: 074, Runtime 25.245541, Loss 3.334594, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.2993, Test: 0.2924, Best time: 18.2948
Epoch: 075, Runtime 25.847986, Loss 2.917937, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.2993, Test: 0.2924, Best time: 18.2948
Epoch: 076, Runtime 27.045245, Loss 2.660039, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3000, Test: 0.2924, Best time: 28.0000
Epoch: 077, Runtime 27.329750, Loss 3.353602, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3000, Test: 0.2924, Best time: 18.2948
Epoch: 078, Runtime 28.421961, Loss 3.347202, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3000, Test: 0.2924, Best time: 18.2948
Epoch: 079, Runtime 29.206089, Loss 3.511269, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2924, Best time: 27.0000
Epoch: 080, Runtime 27.743353, Loss 3.329483, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2924, Best time: 18.2948
Epoch: 081, Runtime 28.512436, Loss 3.173583, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.2924, Best time: 18.2948
Epoch: 082, Runtime 29.069366, Loss 3.391303, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 28.0000
Epoch: 083, Runtime 27.491840, Loss 3.377225, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 084, Runtime 28.380354, Loss 3.327050, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 085, Runtime 28.509268, Loss 3.090263, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 086, Runtime 28.796376, Loss 3.390634, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 087, Runtime 29.854926, Loss 3.403545, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 088, Runtime 31.071491, Loss 3.124348, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 089, Runtime 31.773768, Loss 3.242835, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 090, Runtime 32.503268, Loss 3.339568, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 091, Runtime 33.848223, Loss 3.308346, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 092, Runtime 34.788964, Loss 3.705279, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 093, Runtime 35.344414, Loss 3.137991, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 094, Runtime 35.700076, Loss 3.291703, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 095, Runtime 36.174761, Loss 3.276599, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 096, Runtime 37.327102, Loss 3.373917, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 097, Runtime 38.030023, Loss 3.088304, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 098, Runtime 37.967551, Loss 3.239680, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
Epoch: 099, Runtime 38.168219, Loss 3.670387, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3015, Test: 0.2934, Best time: 18.2948
best val accuracy 0.301471 with test accuracy 0.293401 at epoch 82 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1299492385786802
Entropy Threshold: 2 Test accuracy: 0.1319796954314721
Entropy Threshold: 1.6 Test accuracy: 0.07692307692307693
Entropy Threshold: 1.5 Test accuracy: 0.3333333333333333
Entropy Threshold: 1.4 Test accuracy: 0.0
Entropy Threshold: 1.3 Test accuracy: 0.0
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
