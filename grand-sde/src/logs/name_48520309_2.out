[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 9.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 39.408869, Loss 13.271627, forward nfe 76, backward nfe 0, Train: 0.1571, Val: 0.1574, Test: 0.1574, Best time: 18.2948
Epoch: 002, Runtime 97.081223, Loss 83.413994, forward nfe 372, backward nfe 0, Train: 0.1571, Val: 0.1574, Test: 0.1574, Best time: 18.2948
Epoch: 003, Runtime 25.181752, Loss 5.396680, forward nfe 668, backward nfe 0, Train: 0.1571, Val: 0.1574, Test: 0.1574, Best time: 18.2948
Epoch: 004, Runtime 26.045193, Loss 5.785398, forward nfe 964, backward nfe 0, Train: 0.1571, Val: 0.1574, Test: 0.1574, Best time: 18.2948
Epoch: 005, Runtime 29.034058, Loss 5.927424, forward nfe 1260, backward nfe 0, Train: 0.1286, Val: 0.1588, Test: 0.1330, Best time: 23.0000
Epoch: 006, Runtime 27.525933, Loss 6.107424, forward nfe 1556, backward nfe 0, Train: 0.1357, Val: 0.1640, Test: 0.1371, Best time: 21.0000
Epoch: 007, Runtime 29.245243, Loss 6.278484, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.1824, Test: 0.1574, Best time: 1.0000
Epoch: 008, Runtime 29.942741, Loss 6.299930, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.1882, Test: 0.1777, Best time: 1.0000
Epoch: 009, Runtime 32.030327, Loss 6.627344, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.1882, Test: 0.1777, Best time: 18.2948
Epoch: 010, Runtime 33.663786, Loss 6.538398, forward nfe 2740, backward nfe 0, Train: 0.1357, Val: 0.1993, Test: 0.2041, Best time: 18.2948
Epoch: 011, Runtime 31.864103, Loss 6.111201, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.2324, Test: 0.2365, Best time: 18.2948
Epoch: 012, Runtime 31.977812, Loss 6.216897, forward nfe 3332, backward nfe 0, Train: 0.1357, Val: 0.2706, Test: 0.2660, Best time: 18.2948
Epoch: 013, Runtime 31.616603, Loss 6.395360, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.2772, Test: 0.2701, Best time: 18.2948
Epoch: 014, Runtime 31.165010, Loss 5.876255, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.2772, Test: 0.2701, Best time: 18.2948
Epoch: 015, Runtime 32.191617, Loss 5.333387, forward nfe 4220, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 016, Runtime 30.100626, Loss 5.251310, forward nfe 4516, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 017, Runtime 31.196205, Loss 4.845493, forward nfe 4812, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 018, Runtime 31.899292, Loss 4.959596, forward nfe 5108, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 019, Runtime 32.988596, Loss 4.675788, forward nfe 5404, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 020, Runtime 33.772794, Loss 4.391469, forward nfe 5700, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 021, Runtime 35.180384, Loss 4.587850, forward nfe 5996, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 022, Runtime 36.035799, Loss 4.631197, forward nfe 6292, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 023, Runtime 37.305038, Loss 4.569784, forward nfe 6588, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 024, Runtime 37.506183, Loss 4.189553, forward nfe 6884, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 025, Runtime 38.937605, Loss 4.059204, forward nfe 7180, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 026, Runtime 39.426073, Loss 4.031609, forward nfe 7476, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 027, Runtime 38.910985, Loss 3.987768, forward nfe 7772, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 028, Runtime 39.682644, Loss 4.112831, forward nfe 8068, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 029, Runtime 40.065924, Loss 4.241270, forward nfe 8364, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 030, Runtime 30.627893, Loss 3.982861, forward nfe 8660, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 031, Runtime 27.389798, Loss 3.918064, forward nfe 8956, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 032, Runtime 27.605632, Loss 3.592125, forward nfe 9252, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 033, Runtime 27.288128, Loss 3.754762, forward nfe 9548, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 034, Runtime 26.725922, Loss 3.464097, forward nfe 9844, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 035, Runtime 26.418236, Loss 3.822018, forward nfe 10140, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 036, Runtime 27.154192, Loss 3.484764, forward nfe 10436, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 037, Runtime 26.080837, Loss 3.530539, forward nfe 10732, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 038, Runtime 26.915825, Loss 3.344049, forward nfe 11028, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 039, Runtime 26.649198, Loss 3.658129, forward nfe 11324, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 040, Runtime 26.571061, Loss 3.401526, forward nfe 11620, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 041, Runtime 25.488248, Loss 3.581446, forward nfe 11916, backward nfe 0, Train: 0.1571, Val: 0.2860, Test: 0.2883, Best time: 18.2948
Epoch: 042, Runtime 26.530914, Loss 3.348756, forward nfe 12212, backward nfe 0, Train: 0.1286, Val: 0.2882, Test: 0.2893, Best time: 3.0000
Epoch: 043, Runtime 24.924950, Loss 3.558820, forward nfe 12508, backward nfe 0, Train: 0.1357, Val: 0.2949, Test: 0.2944, Best time: 5.0000
Epoch: 044, Runtime 25.342754, Loss 3.388490, forward nfe 12804, backward nfe 0, Train: 0.1357, Val: 0.2949, Test: 0.2944, Best time: 18.2948
Epoch: 045, Runtime 26.290320, Loss 3.461007, forward nfe 13100, backward nfe 0, Train: 0.1357, Val: 0.2956, Test: 0.3036, Best time: 3.0000
Epoch: 046, Runtime 24.360928, Loss 3.403592, forward nfe 13396, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 2.0000
Epoch: 047, Runtime 24.165104, Loss 3.463928, forward nfe 13692, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 048, Runtime 25.585659, Loss 3.343832, forward nfe 13988, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 049, Runtime 25.631236, Loss 3.216453, forward nfe 14284, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 050, Runtime 25.786781, Loss 3.319972, forward nfe 14580, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 051, Runtime 26.315121, Loss 3.297558, forward nfe 14876, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 052, Runtime 28.178292, Loss 3.128143, forward nfe 15172, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 053, Runtime 28.371256, Loss 3.405198, forward nfe 15468, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 054, Runtime 29.720081, Loss 3.288934, forward nfe 15764, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 055, Runtime 30.296607, Loss 2.888746, forward nfe 16060, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 056, Runtime 31.063400, Loss 3.241467, forward nfe 16356, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 057, Runtime 32.367543, Loss 3.263268, forward nfe 16652, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 058, Runtime 32.981438, Loss 3.340387, forward nfe 16948, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 059, Runtime 33.667060, Loss 3.445848, forward nfe 17244, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 060, Runtime 34.420304, Loss 3.120749, forward nfe 17540, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 061, Runtime 34.255473, Loss 3.240283, forward nfe 17836, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 062, Runtime 35.239608, Loss 3.205674, forward nfe 18132, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 063, Runtime 35.451079, Loss 3.179293, forward nfe 18428, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 064, Runtime 35.971356, Loss 3.043791, forward nfe 18724, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 065, Runtime 36.730324, Loss 2.860142, forward nfe 19020, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 066, Runtime 36.120032, Loss 3.164558, forward nfe 19316, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 067, Runtime 32.662303, Loss 3.267892, forward nfe 19612, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 068, Runtime 24.663837, Loss 3.203989, forward nfe 19908, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 069, Runtime 25.196385, Loss 3.411131, forward nfe 20204, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 070, Runtime 26.398372, Loss 3.090515, forward nfe 20500, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 071, Runtime 27.587255, Loss 3.185650, forward nfe 20796, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 072, Runtime 28.437658, Loss 3.178320, forward nfe 21092, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 073, Runtime 28.530280, Loss 3.244333, forward nfe 21388, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 074, Runtime 29.285819, Loss 2.787571, forward nfe 21684, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 075, Runtime 28.661687, Loss 2.732924, forward nfe 21980, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 076, Runtime 29.457675, Loss 3.178071, forward nfe 22276, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 077, Runtime 32.136179, Loss 2.948764, forward nfe 22572, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 078, Runtime 34.490733, Loss 3.324210, forward nfe 22868, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 079, Runtime 35.235308, Loss 3.049265, forward nfe 23164, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 080, Runtime 35.727074, Loss 3.387890, forward nfe 23460, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 081, Runtime 36.480266, Loss 3.130768, forward nfe 23756, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 082, Runtime 36.430052, Loss 3.059412, forward nfe 24052, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 083, Runtime 37.749877, Loss 3.163040, forward nfe 24348, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 084, Runtime 37.904298, Loss 3.055523, forward nfe 24644, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 085, Runtime 38.094426, Loss 2.869611, forward nfe 24940, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 086, Runtime 37.654776, Loss 3.105988, forward nfe 25236, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 087, Runtime 32.819569, Loss 2.963935, forward nfe 25532, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 088, Runtime 25.596581, Loss 3.055958, forward nfe 25828, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 089, Runtime 26.657114, Loss 2.893735, forward nfe 26124, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 090, Runtime 27.488400, Loss 3.061159, forward nfe 26420, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 091, Runtime 28.843468, Loss 2.951773, forward nfe 26716, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 092, Runtime 29.631715, Loss 2.919187, forward nfe 27012, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 093, Runtime 30.545710, Loss 2.887921, forward nfe 27308, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 094, Runtime 31.402308, Loss 2.949537, forward nfe 27604, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 095, Runtime 31.286920, Loss 3.022349, forward nfe 27900, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 096, Runtime 31.653065, Loss 3.047166, forward nfe 28196, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 097, Runtime 32.923045, Loss 3.100264, forward nfe 28492, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 098, Runtime 33.620210, Loss 3.116441, forward nfe 28788, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
Epoch: 099, Runtime 33.799990, Loss 2.964167, forward nfe 29084, backward nfe 0, Train: 0.1357, Val: 0.2963, Test: 0.2995, Best time: 18.2948
best val accuracy 0.296324 with test accuracy 0.299492 at epoch 46 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.07918781725888324
Entropy Threshold: 2 Test accuracy: 0.07715736040609138
Entropy Threshold: 1.6 Test accuracy: 0.07668711656441718
Entropy Threshold: 1.5 Test accuracy: 0.07377049180327869
Entropy Threshold: 1.4 Test accuracy: 0.06964656964656965
Entropy Threshold: 1.3 Test accuracy: 0.07659115426105717
Entropy Threshold: 1.2 Test accuracy: 0.059907834101382486
Entropy Threshold: 1.1 Test accuracy: 0.06926952141057935
Entropy Threshold: 0.9 Test accuracy: 0.07317073170731707
Entropy Threshold: 0.8 Test accuracy: 0.05924170616113744
Entropy Threshold: 0.7 Test accuracy: 0.06567164179104477
Entropy Threshold: 0.6 Test accuracy: 0.05128205128205128
Entropy Threshold: 0.5 Test accuracy: 0.04054054054054054
Entropy Threshold: 0.4 Test accuracy: 0.05660377358490566
Entropy Threshold: 0.3 Test accuracy: 0.045454545454545456
Entropy Threshold: 0.2 Test accuracy: 0.07317073170731707
Entropy Threshold: 0.1 Test accuracy: 0.10714285714285714
