[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.1
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.368793, Loss 1.960977, forward nfe 76, backward nfe 0, Train: 0.4714, Val: 0.3147, Test: 0.3310, Best time: 1.0000
Epoch: 002, Runtime 14.099232, Loss 1.912439, forward nfe 372, backward nfe 0, Train: 0.7071, Val: 0.4765, Test: 0.4792, Best time: 1.0000
Epoch: 003, Runtime 13.724171, Loss 1.765503, forward nfe 668, backward nfe 0, Train: 0.8714, Val: 0.6471, Test: 0.6315, Best time: 3.0000
Epoch: 004, Runtime 13.946031, Loss 1.592156, forward nfe 964, backward nfe 0, Train: 0.8786, Val: 0.7147, Test: 0.7107, Best time: 8.0000
Epoch: 005, Runtime 13.915879, Loss 1.347676, forward nfe 1260, backward nfe 0, Train: 0.9000, Val: 0.7426, Test: 0.7371, Best time: 11.0000
Epoch: 006, Runtime 13.981392, Loss 1.028988, forward nfe 1556, backward nfe 0, Train: 0.8857, Val: 0.7750, Test: 0.7787, Best time: 26.0000
Epoch: 007, Runtime 14.059112, Loss 0.776867, forward nfe 1852, backward nfe 0, Train: 0.9214, Val: 0.7993, Test: 0.7990, Best time: 6.0000
Epoch: 008, Runtime 14.183845, Loss 0.600392, forward nfe 2148, backward nfe 0, Train: 0.9357, Val: 0.8118, Test: 0.8071, Best time: 5.0000
Epoch: 009, Runtime 14.062441, Loss 0.419566, forward nfe 2444, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 010, Runtime 13.511944, Loss 0.355312, forward nfe 2740, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 011, Runtime 14.064196, Loss 0.296671, forward nfe 3036, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 012, Runtime 14.649861, Loss 0.265475, forward nfe 3332, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 013, Runtime 14.095328, Loss 0.218537, forward nfe 3628, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 014, Runtime 14.059793, Loss 0.216200, forward nfe 3924, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 015, Runtime 14.626329, Loss 0.203239, forward nfe 4220, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 016, Runtime 15.004183, Loss 0.179373, forward nfe 4516, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 017, Runtime 14.394942, Loss 0.187695, forward nfe 4812, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 018, Runtime 14.531646, Loss 0.180701, forward nfe 5108, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 019, Runtime 14.862339, Loss 0.185663, forward nfe 5404, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 020, Runtime 15.207978, Loss 0.179781, forward nfe 5700, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 021, Runtime 14.700317, Loss 0.189648, forward nfe 5996, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 022, Runtime 14.700068, Loss 0.211004, forward nfe 6292, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 023, Runtime 14.942426, Loss 0.220621, forward nfe 6588, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 024, Runtime 15.109338, Loss 0.184056, forward nfe 6884, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 025, Runtime 15.021477, Loss 0.216039, forward nfe 7180, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 026, Runtime 14.995766, Loss 0.248449, forward nfe 7476, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 027, Runtime 15.173025, Loss 0.195587, forward nfe 7772, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 028, Runtime 15.321081, Loss 0.180129, forward nfe 8068, backward nfe 0, Train: 0.8929, Val: 0.8250, Test: 0.8223, Best time: 18.2948
Epoch: 029, Runtime 15.382313, Loss 0.202070, forward nfe 8364, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 42.0000
Epoch: 030, Runtime 13.417838, Loss 0.172889, forward nfe 8660, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 031, Runtime 13.868865, Loss 0.142595, forward nfe 8956, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 032, Runtime 14.226078, Loss 0.197718, forward nfe 9252, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 033, Runtime 13.754583, Loss 0.167414, forward nfe 9548, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 034, Runtime 13.678291, Loss 0.157120, forward nfe 9844, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 035, Runtime 14.111473, Loss 0.194430, forward nfe 10140, backward nfe 0, Train: 0.9643, Val: 0.8324, Test: 0.8284, Best time: 18.2948
Epoch: 036, Runtime 14.617878, Loss 0.134614, forward nfe 10436, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 54.0000
Epoch: 037, Runtime 13.260540, Loss 0.135597, forward nfe 10732, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 038, Runtime 13.675722, Loss 0.138347, forward nfe 11028, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 039, Runtime 14.274185, Loss 0.174246, forward nfe 11324, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 040, Runtime 13.697675, Loss 0.159896, forward nfe 11620, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 041, Runtime 13.642541, Loss 0.145248, forward nfe 11916, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 042, Runtime 14.210102, Loss 0.115354, forward nfe 12212, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 043, Runtime 14.589202, Loss 0.165405, forward nfe 12508, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 044, Runtime 13.993055, Loss 0.193954, forward nfe 12804, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 045, Runtime 14.097910, Loss 0.157692, forward nfe 13100, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 046, Runtime 14.400954, Loss 0.131324, forward nfe 13396, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 047, Runtime 14.669210, Loss 0.230519, forward nfe 13692, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 048, Runtime 14.260012, Loss 0.135016, forward nfe 13988, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 049, Runtime 14.277317, Loss 0.194175, forward nfe 14284, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 050, Runtime 14.497645, Loss 0.120533, forward nfe 14580, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 051, Runtime 14.841177, Loss 0.124823, forward nfe 14876, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 052, Runtime 14.789444, Loss 0.164091, forward nfe 15172, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 053, Runtime 14.928455, Loss 0.148741, forward nfe 15468, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 054, Runtime 15.030018, Loss 0.098763, forward nfe 15764, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 055, Runtime 15.166333, Loss 0.117113, forward nfe 16060, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 056, Runtime 15.209013, Loss 0.117188, forward nfe 16356, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 057, Runtime 15.039755, Loss 0.135526, forward nfe 16652, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 058, Runtime 15.299315, Loss 0.129383, forward nfe 16948, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 059, Runtime 15.352509, Loss 0.148618, forward nfe 17244, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 060, Runtime 15.314806, Loss 0.168288, forward nfe 17540, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 061, Runtime 15.156224, Loss 0.141171, forward nfe 17836, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 062, Runtime 15.382220, Loss 0.106483, forward nfe 18132, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 063, Runtime 15.597982, Loss 0.170317, forward nfe 18428, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 064, Runtime 15.491587, Loss 0.108847, forward nfe 18724, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 065, Runtime 15.382028, Loss 0.134281, forward nfe 19020, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 066, Runtime 15.473274, Loss 0.144125, forward nfe 19316, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 067, Runtime 15.507977, Loss 0.095749, forward nfe 19612, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 068, Runtime 15.561779, Loss 0.132700, forward nfe 19908, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 069, Runtime 15.462684, Loss 0.090352, forward nfe 20204, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 070, Runtime 15.500366, Loss 0.104839, forward nfe 20500, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 071, Runtime 15.517303, Loss 0.087487, forward nfe 20796, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 072, Runtime 15.515423, Loss 0.122269, forward nfe 21092, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 073, Runtime 15.503991, Loss 0.127094, forward nfe 21388, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 074, Runtime 15.675239, Loss 0.124027, forward nfe 21684, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 075, Runtime 15.636571, Loss 0.105594, forward nfe 21980, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 076, Runtime 15.797531, Loss 0.092019, forward nfe 22276, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 077, Runtime 15.562304, Loss 0.145608, forward nfe 22572, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 078, Runtime 15.509187, Loss 0.097704, forward nfe 22868, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 079, Runtime 15.669611, Loss 0.104209, forward nfe 23164, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 080, Runtime 15.859642, Loss 0.161681, forward nfe 23460, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 081, Runtime 15.812405, Loss 0.100311, forward nfe 23756, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 082, Runtime 15.851735, Loss 0.105723, forward nfe 24052, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 083, Runtime 15.883556, Loss 0.168686, forward nfe 24348, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 084, Runtime 15.814124, Loss 0.100065, forward nfe 24644, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 085, Runtime 15.669186, Loss 0.177053, forward nfe 24940, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 086, Runtime 15.704844, Loss 0.125570, forward nfe 25236, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 087, Runtime 14.988589, Loss 0.148692, forward nfe 25532, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 088, Runtime 14.688849, Loss 0.103797, forward nfe 25828, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 089, Runtime 11.624591, Loss 0.082549, forward nfe 26124, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 090, Runtime 11.558944, Loss 0.101257, forward nfe 26420, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 091, Runtime 11.554901, Loss 0.105964, forward nfe 26716, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 092, Runtime 11.647679, Loss 0.089632, forward nfe 27012, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 093, Runtime 11.476287, Loss 0.074392, forward nfe 27308, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 094, Runtime 11.492030, Loss 0.094758, forward nfe 27604, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 095, Runtime 11.685812, Loss 0.114490, forward nfe 27900, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 096, Runtime 11.676863, Loss 0.149674, forward nfe 28196, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 097, Runtime 11.498647, Loss 0.134442, forward nfe 28492, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 098, Runtime 11.621695, Loss 0.085543, forward nfe 28788, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
Epoch: 099, Runtime 11.793016, Loss 0.100477, forward nfe 29084, backward nfe 0, Train: 0.9643, Val: 0.8346, Test: 0.8305, Best time: 18.2948
best val accuracy 0.834559 with test accuracy 0.830457 at epoch 36 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8324873096446701
Entropy Threshold: 2 Test accuracy: 0.833502538071066
Entropy Threshold: 1.6 Test accuracy: 0.8301119023397762
Entropy Threshold: 1.5 Test accuracy: 0.8326530612244898
Entropy Threshold: 1.4 Test accuracy: 0.8350409836065574
Entropy Threshold: 1.3 Test accuracy: 0.8362512873326468
Entropy Threshold: 1.2 Test accuracy: 0.8382045929018789
Entropy Threshold: 1.1 Test accuracy: 0.846723044397463
Entropy Threshold: 0.9 Test accuracy: 0.8668146503884573
Entropy Threshold: 0.8 Test accuracy: 0.8761467889908257
Entropy Threshold: 0.7 Test accuracy: 0.8871733966745843
Entropy Threshold: 0.6 Test accuracy: 0.9016189290161893
Entropy Threshold: 0.5 Test accuracy: 0.9081632653061225
Entropy Threshold: 0.4 Test accuracy: 0.917989417989418
Entropy Threshold: 0.3 Test accuracy: 0.9197786998616874
Entropy Threshold: 0.2 Test accuracy: 0.9270833333333334
Entropy Threshold: 0.1 Test accuracy: 0.9381107491856677
