[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 3.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 18.340293, Loss 2.583103, forward nfe 76, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 54.0000
Epoch: 002, Runtime 24.143360, Loss 7.875258, forward nfe 372, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 003, Runtime 15.728237, Loss 2.800348, forward nfe 668, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 004, Runtime 15.661178, Loss 2.836411, forward nfe 964, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 005, Runtime 16.627395, Loss 2.646774, forward nfe 1260, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 006, Runtime 17.135525, Loss 2.539043, forward nfe 1556, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 007, Runtime 17.852733, Loss 2.596253, forward nfe 1852, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 008, Runtime 17.955520, Loss 2.545241, forward nfe 2148, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 009, Runtime 18.259764, Loss 2.174649, forward nfe 2444, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 010, Runtime 18.335427, Loss 2.451396, forward nfe 2740, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 011, Runtime 18.577673, Loss 2.374487, forward nfe 3036, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 012, Runtime 18.675009, Loss 2.437509, forward nfe 3332, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 013, Runtime 18.856571, Loss 2.673860, forward nfe 3628, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 014, Runtime 18.856349, Loss 2.311639, forward nfe 3924, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 015, Runtime 19.404381, Loss 2.426381, forward nfe 4220, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 016, Runtime 19.697405, Loss 2.298987, forward nfe 4516, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 017, Runtime 19.856465, Loss 2.430012, forward nfe 4812, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 018, Runtime 20.521195, Loss 2.298996, forward nfe 5108, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 019, Runtime 20.835436, Loss 2.430945, forward nfe 5404, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 020, Runtime 20.941333, Loss 2.261675, forward nfe 5700, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 021, Runtime 21.023902, Loss 2.359847, forward nfe 5996, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 022, Runtime 21.111819, Loss 2.235211, forward nfe 6292, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 023, Runtime 21.279541, Loss 2.208719, forward nfe 6588, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 024, Runtime 21.650834, Loss 2.272178, forward nfe 6884, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 025, Runtime 21.882623, Loss 2.280381, forward nfe 7180, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 026, Runtime 22.242220, Loss 2.215743, forward nfe 7476, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 027, Runtime 22.296797, Loss 2.141602, forward nfe 7772, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 028, Runtime 22.733209, Loss 2.190165, forward nfe 8068, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 029, Runtime 22.905349, Loss 2.452420, forward nfe 8364, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 030, Runtime 22.994943, Loss 2.248221, forward nfe 8660, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 031, Runtime 23.351582, Loss 2.298250, forward nfe 8956, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 032, Runtime 21.575614, Loss 2.117675, forward nfe 9252, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 033, Runtime 21.532155, Loss 2.210400, forward nfe 9548, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 034, Runtime 21.859728, Loss 2.163522, forward nfe 9844, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 035, Runtime 22.247626, Loss 2.196992, forward nfe 10140, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 036, Runtime 22.108271, Loss 2.187688, forward nfe 10436, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 037, Runtime 22.305501, Loss 2.238847, forward nfe 10732, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 038, Runtime 23.317071, Loss 2.164609, forward nfe 11028, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 039, Runtime 24.190375, Loss 2.096653, forward nfe 11324, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 040, Runtime 23.696973, Loss 2.149451, forward nfe 11620, backward nfe 0, Train: 0.3571, Val: 0.2515, Test: 0.2660, Best time: 18.2948
Epoch: 041, Runtime 23.842785, Loss 2.124054, forward nfe 11916, backward nfe 0, Train: 0.3000, Val: 0.2691, Test: 0.2558, Best time: 1.0000
Epoch: 042, Runtime 15.261207, Loss 2.130097, forward nfe 12212, backward nfe 0, Train: 0.3214, Val: 0.2853, Test: 0.2690, Best time: 1.0000
Epoch: 043, Runtime 15.348783, Loss 2.142428, forward nfe 12508, backward nfe 0, Train: 0.3429, Val: 0.2949, Test: 0.2914, Best time: 1.0000
Epoch: 044, Runtime 15.422297, Loss 2.044387, forward nfe 12804, backward nfe 0, Train: 0.3571, Val: 0.3037, Test: 0.3036, Best time: 1.0000
Epoch: 045, Runtime 15.541548, Loss 2.111932, forward nfe 13100, backward nfe 0, Train: 0.3500, Val: 0.3074, Test: 0.3036, Best time: 2.0000
Epoch: 046, Runtime 15.567150, Loss 2.213097, forward nfe 13396, backward nfe 0, Train: 0.3786, Val: 0.3132, Test: 0.3076, Best time: 1.0000
Epoch: 047, Runtime 15.593732, Loss 2.129327, forward nfe 13692, backward nfe 0, Train: 0.3786, Val: 0.3132, Test: 0.3076, Best time: 18.2948
Epoch: 048, Runtime 15.894638, Loss 2.065771, forward nfe 13988, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 1.0000
Epoch: 049, Runtime 15.759245, Loss 1.974103, forward nfe 14284, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 050, Runtime 16.021230, Loss 2.075151, forward nfe 14580, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 051, Runtime 18.018024, Loss 2.012419, forward nfe 14876, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 052, Runtime 19.041564, Loss 2.083232, forward nfe 15172, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 053, Runtime 19.423814, Loss 1.960428, forward nfe 15468, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 054, Runtime 20.067237, Loss 2.035204, forward nfe 15764, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 055, Runtime 20.797760, Loss 2.089988, forward nfe 16060, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 056, Runtime 21.429047, Loss 2.165432, forward nfe 16356, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 057, Runtime 21.976213, Loss 2.038281, forward nfe 16652, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 058, Runtime 22.706419, Loss 1.966468, forward nfe 16948, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 059, Runtime 23.089349, Loss 1.990577, forward nfe 17244, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 060, Runtime 23.344469, Loss 2.101647, forward nfe 17540, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 061, Runtime 24.047198, Loss 2.144753, forward nfe 17836, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 062, Runtime 24.325895, Loss 2.054400, forward nfe 18132, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 063, Runtime 24.642256, Loss 2.033912, forward nfe 18428, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 064, Runtime 25.165135, Loss 1.954916, forward nfe 18724, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 065, Runtime 25.076344, Loss 2.004052, forward nfe 19020, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 066, Runtime 25.417758, Loss 1.905934, forward nfe 19316, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 067, Runtime 25.741452, Loss 2.173267, forward nfe 19612, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 068, Runtime 25.914380, Loss 1.994802, forward nfe 19908, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 069, Runtime 26.115863, Loss 1.920903, forward nfe 20204, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 070, Runtime 26.149725, Loss 1.952767, forward nfe 20500, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 071, Runtime 26.243369, Loss 2.027212, forward nfe 20796, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 072, Runtime 26.472320, Loss 1.994892, forward nfe 21092, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 073, Runtime 27.509531, Loss 2.015253, forward nfe 21388, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 074, Runtime 26.853163, Loss 2.014019, forward nfe 21684, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 075, Runtime 27.416334, Loss 2.032661, forward nfe 21980, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 076, Runtime 18.853659, Loss 1.896330, forward nfe 22276, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 077, Runtime 17.201344, Loss 1.963355, forward nfe 22572, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 078, Runtime 17.293067, Loss 2.018627, forward nfe 22868, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 079, Runtime 17.253812, Loss 1.944544, forward nfe 23164, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 080, Runtime 17.403250, Loss 2.004078, forward nfe 23460, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 081, Runtime 18.145143, Loss 1.957818, forward nfe 23756, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 082, Runtime 17.980950, Loss 1.994896, forward nfe 24052, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 083, Runtime 18.334975, Loss 2.007538, forward nfe 24348, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 084, Runtime 18.989074, Loss 1.976895, forward nfe 24644, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 085, Runtime 19.067182, Loss 1.981153, forward nfe 24940, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 086, Runtime 19.156785, Loss 1.932453, forward nfe 25236, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 087, Runtime 19.619058, Loss 1.873206, forward nfe 25532, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 088, Runtime 19.697624, Loss 1.998639, forward nfe 25828, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 089, Runtime 19.951302, Loss 1.911538, forward nfe 26124, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 090, Runtime 20.098825, Loss 1.988993, forward nfe 26420, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 091, Runtime 20.419823, Loss 1.923362, forward nfe 26716, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 092, Runtime 20.762452, Loss 1.859958, forward nfe 27012, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 093, Runtime 20.916820, Loss 1.905142, forward nfe 27308, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 094, Runtime 21.052741, Loss 1.995081, forward nfe 27604, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 095, Runtime 21.282917, Loss 1.970175, forward nfe 27900, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 096, Runtime 21.686400, Loss 1.891587, forward nfe 28196, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 097, Runtime 21.671921, Loss 1.984868, forward nfe 28492, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 098, Runtime 21.824081, Loss 1.909428, forward nfe 28788, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
Epoch: 099, Runtime 22.281559, Loss 1.896214, forward nfe 29084, backward nfe 0, Train: 0.3857, Val: 0.3176, Test: 0.3137, Best time: 18.2948
best val accuracy 0.317647 with test accuracy 0.313706 at epoch 48 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.10152284263959391
Entropy Threshold: 2 Test accuracy: 0.10456852791878173
Entropy Threshold: 1.6 Test accuracy: 0.0
Entropy Threshold: 1.5 Test accuracy: 0.0
Entropy Threshold: 1.4 Test accuracy: 0.0
Entropy Threshold: 1.3 Test accuracy: None
Entropy Threshold: 1.2 Test accuracy: None
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
