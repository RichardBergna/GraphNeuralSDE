[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 2.5
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 15.382011, Loss 2.741545, forward nfe 76, backward nfe 0, Train: 0.3714, Val: 0.1860, Test: 0.1817, Best time: 1.0000
Epoch: 002, Runtime 15.366348, Loss 3.429489, forward nfe 372, backward nfe 0, Train: 0.4214, Val: 0.3441, Test: 0.3320, Best time: 1.0000
Epoch: 003, Runtime 14.574948, Loss 2.346736, forward nfe 668, backward nfe 0, Train: 0.4500, Val: 0.3654, Test: 0.3756, Best time: 1.0000
Epoch: 004, Runtime 14.702606, Loss 2.530373, forward nfe 964, backward nfe 0, Train: 0.6000, Val: 0.4287, Test: 0.4315, Best time: 1.0000
Epoch: 005, Runtime 14.485629, Loss 2.342071, forward nfe 1260, backward nfe 0, Train: 0.6143, Val: 0.4426, Test: 0.4690, Best time: 1.0000
Epoch: 006, Runtime 14.232368, Loss 2.166939, forward nfe 1556, backward nfe 0, Train: 0.6143, Val: 0.4654, Test: 0.4558, Best time: 27.0000
Epoch: 007, Runtime 14.265405, Loss 1.997343, forward nfe 1852, backward nfe 0, Train: 0.5857, Val: 0.4985, Test: 0.5056, Best time: 31.0000
Epoch: 008, Runtime 13.666901, Loss 1.779761, forward nfe 2148, backward nfe 0, Train: 0.5857, Val: 0.5110, Test: 0.5178, Best time: 24.0000
Epoch: 009, Runtime 13.325028, Loss 1.794345, forward nfe 2444, backward nfe 0, Train: 0.6429, Val: 0.5632, Test: 0.5655, Best time: 23.0000
Epoch: 010, Runtime 13.259293, Loss 1.594481, forward nfe 2740, backward nfe 0, Train: 0.7357, Val: 0.6676, Test: 0.6822, Best time: 24.0000
Epoch: 011, Runtime 13.184508, Loss 1.516748, forward nfe 3036, backward nfe 0, Train: 0.8286, Val: 0.7463, Test: 0.7777, Best time: 21.0000
Epoch: 012, Runtime 13.277329, Loss 1.333735, forward nfe 3332, backward nfe 0, Train: 0.8714, Val: 0.7779, Test: 0.8193, Best time: 29.0000
Epoch: 013, Runtime 13.605069, Loss 1.228125, forward nfe 3628, backward nfe 0, Train: 0.8786, Val: 0.7860, Test: 0.8264, Best time: 27.0000
Epoch: 014, Runtime 13.403115, Loss 1.244917, forward nfe 3924, backward nfe 0, Train: 0.8786, Val: 0.7860, Test: 0.8264, Best time: 18.2948
Epoch: 015, Runtime 14.320761, Loss 1.084909, forward nfe 4220, backward nfe 0, Train: 0.8786, Val: 0.7860, Test: 0.8264, Best time: 18.2948
Epoch: 016, Runtime 14.095744, Loss 0.954255, forward nfe 4516, backward nfe 0, Train: 0.8786, Val: 0.7860, Test: 0.8264, Best time: 18.2948
Epoch: 017, Runtime 14.427576, Loss 0.933555, forward nfe 4812, backward nfe 0, Train: 0.8500, Val: 0.7875, Test: 0.8244, Best time: 43.0000
Epoch: 018, Runtime 14.052394, Loss 0.903050, forward nfe 5108, backward nfe 0, Train: 0.8571, Val: 0.7941, Test: 0.8335, Best time: 51.0000
Epoch: 019, Runtime 14.115972, Loss 0.865484, forward nfe 5404, backward nfe 0, Train: 0.8714, Val: 0.8044, Test: 0.8376, Best time: 47.0000
Epoch: 020, Runtime 14.450438, Loss 0.813230, forward nfe 5700, backward nfe 0, Train: 0.8643, Val: 0.8125, Test: 0.8386, Best time: 45.0000
Epoch: 021, Runtime 14.549800, Loss 0.724329, forward nfe 5996, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 50.0000
Epoch: 022, Runtime 14.591675, Loss 0.763488, forward nfe 6292, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 023, Runtime 14.742713, Loss 0.673494, forward nfe 6588, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 024, Runtime 14.245651, Loss 0.800947, forward nfe 6884, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 025, Runtime 14.798213, Loss 0.677245, forward nfe 7180, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 026, Runtime 14.707913, Loss 0.712597, forward nfe 7476, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 027, Runtime 15.150290, Loss 0.662914, forward nfe 7772, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 028, Runtime 15.503424, Loss 0.709024, forward nfe 8068, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 029, Runtime 15.624609, Loss 0.747174, forward nfe 8364, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 030, Runtime 16.089076, Loss 0.702410, forward nfe 8660, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 031, Runtime 15.866620, Loss 0.575514, forward nfe 8956, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 032, Runtime 16.217250, Loss 0.605807, forward nfe 9252, backward nfe 0, Train: 0.8643, Val: 0.8140, Test: 0.8325, Best time: 18.2948
Epoch: 033, Runtime 16.488760, Loss 0.550490, forward nfe 9548, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 25.0000
Epoch: 034, Runtime 14.615905, Loss 0.552539, forward nfe 9844, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 035, Runtime 14.953801, Loss 0.599816, forward nfe 10140, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 036, Runtime 14.201329, Loss 0.741677, forward nfe 10436, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 037, Runtime 14.637745, Loss 0.574916, forward nfe 10732, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 038, Runtime 14.608109, Loss 0.396445, forward nfe 11028, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 039, Runtime 14.692071, Loss 0.612100, forward nfe 11324, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 040, Runtime 14.761662, Loss 0.523404, forward nfe 11620, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 041, Runtime 15.139945, Loss 0.428849, forward nfe 11916, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 042, Runtime 15.707496, Loss 0.505955, forward nfe 12212, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 043, Runtime 15.561884, Loss 0.734813, forward nfe 12508, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 044, Runtime 15.717307, Loss 0.536972, forward nfe 12804, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 045, Runtime 15.858937, Loss 0.465342, forward nfe 13100, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 046, Runtime 16.140586, Loss 0.507094, forward nfe 13396, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 047, Runtime 16.585947, Loss 0.674245, forward nfe 13692, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 048, Runtime 16.060297, Loss 0.430258, forward nfe 13988, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 049, Runtime 16.492813, Loss 0.533292, forward nfe 14284, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 050, Runtime 15.955851, Loss 0.562389, forward nfe 14580, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 051, Runtime 15.985691, Loss 0.544860, forward nfe 14876, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 052, Runtime 16.216404, Loss 0.581609, forward nfe 15172, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 053, Runtime 16.762033, Loss 0.639344, forward nfe 15468, backward nfe 0, Train: 0.9071, Val: 0.8162, Test: 0.8315, Best time: 18.2948
Epoch: 054, Runtime 17.372376, Loss 0.479668, forward nfe 15764, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 29.0000
Epoch: 055, Runtime 14.169286, Loss 0.473262, forward nfe 16060, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 056, Runtime 14.619881, Loss 0.405504, forward nfe 16356, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 057, Runtime 14.056978, Loss 0.442901, forward nfe 16652, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 058, Runtime 14.069647, Loss 0.428384, forward nfe 16948, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 059, Runtime 13.946346, Loss 0.508394, forward nfe 17244, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 060, Runtime 14.404597, Loss 0.462185, forward nfe 17540, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 061, Runtime 14.644601, Loss 0.405180, forward nfe 17836, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 062, Runtime 14.705358, Loss 0.497742, forward nfe 18132, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 063, Runtime 15.086120, Loss 0.514560, forward nfe 18428, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 064, Runtime 14.867266, Loss 0.448156, forward nfe 18724, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 065, Runtime 14.996581, Loss 0.502758, forward nfe 19020, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 066, Runtime 15.160819, Loss 0.506752, forward nfe 19316, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 067, Runtime 15.454351, Loss 0.402202, forward nfe 19612, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 068, Runtime 15.929712, Loss 0.365787, forward nfe 19908, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 069, Runtime 15.447155, Loss 0.407495, forward nfe 20204, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 070, Runtime 15.824998, Loss 0.482380, forward nfe 20500, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 071, Runtime 15.717888, Loss 0.396437, forward nfe 20796, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 072, Runtime 15.800441, Loss 0.507529, forward nfe 21092, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 073, Runtime 15.955442, Loss 0.453382, forward nfe 21388, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 074, Runtime 16.044591, Loss 0.382596, forward nfe 21684, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 075, Runtime 16.459228, Loss 0.436073, forward nfe 21980, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 076, Runtime 16.323962, Loss 0.432050, forward nfe 22276, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 077, Runtime 16.295027, Loss 0.556079, forward nfe 22572, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 078, Runtime 16.555747, Loss 0.363442, forward nfe 22868, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 079, Runtime 16.852365, Loss 0.390413, forward nfe 23164, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 080, Runtime 17.114323, Loss 0.333179, forward nfe 23460, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 081, Runtime 16.714145, Loss 0.357728, forward nfe 23756, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 082, Runtime 16.962334, Loss 0.393463, forward nfe 24052, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 083, Runtime 16.869646, Loss 0.370791, forward nfe 24348, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 084, Runtime 16.865150, Loss 0.388043, forward nfe 24644, backward nfe 0, Train: 0.9357, Val: 0.8213, Test: 0.8345, Best time: 18.2948
Epoch: 085, Runtime 17.225692, Loss 0.440149, forward nfe 24940, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 42.0000
Epoch: 086, Runtime 13.234416, Loss 0.231297, forward nfe 25236, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 087, Runtime 13.813451, Loss 0.393408, forward nfe 25532, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 088, Runtime 13.299626, Loss 0.279599, forward nfe 25828, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 089, Runtime 13.575028, Loss 0.352338, forward nfe 26124, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 090, Runtime 14.027115, Loss 0.318709, forward nfe 26420, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 091, Runtime 14.368754, Loss 0.368260, forward nfe 26716, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 092, Runtime 14.883969, Loss 0.420607, forward nfe 27012, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 093, Runtime 13.959495, Loss 0.351936, forward nfe 27308, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 094, Runtime 14.360605, Loss 0.334087, forward nfe 27604, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 095, Runtime 14.225781, Loss 0.307053, forward nfe 27900, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 096, Runtime 14.402139, Loss 0.370453, forward nfe 28196, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 097, Runtime 14.759395, Loss 0.287006, forward nfe 28492, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 098, Runtime 15.293582, Loss 0.363931, forward nfe 28788, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
Epoch: 099, Runtime 15.751309, Loss 0.340144, forward nfe 29084, backward nfe 0, Train: 0.9714, Val: 0.8309, Test: 0.8437, Best time: 18.2948
best val accuracy 0.830882 with test accuracy 0.843655 at epoch 85 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8456852791878172
Entropy Threshold: 2 Test accuracy: 0.8406091370558376
Entropy Threshold: 1.6 Test accuracy: 0.8514750762970499
Entropy Threshold: 1.5 Test accuracy: 0.8486707566462167
Entropy Threshold: 1.4 Test accuracy: 0.8521199586349535
Entropy Threshold: 1.3 Test accuracy: 0.8598326359832636
Entropy Threshold: 1.2 Test accuracy: 0.8618490967056323
Entropy Threshold: 1.1 Test accuracy: 0.8704103671706264
Entropy Threshold: 0.9 Test accuracy: 0.8931475029036005
Entropy Threshold: 0.8 Test accuracy: 0.9063625450180072
Entropy Threshold: 0.7 Test accuracy: 0.9116161616161617
Entropy Threshold: 0.6 Test accuracy: 0.9289544235924933
Entropy Threshold: 0.5 Test accuracy: 0.9396914446002805
Entropy Threshold: 0.4 Test accuracy: 0.9469026548672567
Entropy Threshold: 0.3 Test accuracy: 0.9594155844155844
Entropy Threshold: 0.2 Test accuracy: 0.9616724738675958
Entropy Threshold: 0.1 Test accuracy: 0.967741935483871
