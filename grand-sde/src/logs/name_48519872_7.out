[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 15.442761, Loss 2.058654, forward nfe 76, backward nfe 0, Train: 0.3143, Val: 0.4235, Test: 0.3858, Best time: 1.0000
Epoch: 002, Runtime 16.726638, Loss 2.213164, forward nfe 372, backward nfe 0, Train: 0.5714, Val: 0.5419, Test: 0.5279, Best time: 4.0000
Epoch: 003, Runtime 14.195204, Loss 2.061042, forward nfe 668, backward nfe 0, Train: 0.5714, Val: 0.5419, Test: 0.5279, Best time: 18.2948
Epoch: 004, Runtime 13.963283, Loss 2.076424, forward nfe 964, backward nfe 0, Train: 0.5714, Val: 0.5419, Test: 0.5279, Best time: 18.2948
Epoch: 005, Runtime 14.589560, Loss 2.057103, forward nfe 1260, backward nfe 0, Train: 0.6429, Val: 0.5765, Test: 0.5706, Best time: 1.0000
Epoch: 006, Runtime 14.325731, Loss 1.958220, forward nfe 1556, backward nfe 0, Train: 0.8214, Val: 0.7368, Test: 0.7117, Best time: 4.0000
Epoch: 007, Runtime 14.373950, Loss 1.733357, forward nfe 1852, backward nfe 0, Train: 0.9214, Val: 0.7985, Test: 0.7838, Best time: 8.0000
Epoch: 008, Runtime 13.588531, Loss 1.667130, forward nfe 2148, backward nfe 0, Train: 0.9214, Val: 0.7985, Test: 0.7838, Best time: 18.2948
Epoch: 009, Runtime 13.699723, Loss 1.566776, forward nfe 2444, backward nfe 0, Train: 0.9214, Val: 0.7985, Test: 0.7838, Best time: 18.2948
Epoch: 010, Runtime 13.280453, Loss 1.317980, forward nfe 2740, backward nfe 0, Train: 0.9214, Val: 0.7985, Test: 0.7838, Best time: 18.2948
Epoch: 011, Runtime 13.405256, Loss 1.251453, forward nfe 3036, backward nfe 0, Train: 0.9143, Val: 0.8096, Test: 0.7980, Best time: 15.0000
Epoch: 012, Runtime 13.031002, Loss 1.087540, forward nfe 3332, backward nfe 0, Train: 0.9143, Val: 0.8213, Test: 0.8000, Best time: 21.0000
Epoch: 013, Runtime 13.256308, Loss 1.021675, forward nfe 3628, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 31.0000
Epoch: 014, Runtime 13.101163, Loss 0.752373, forward nfe 3924, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 015, Runtime 13.577084, Loss 0.710962, forward nfe 4220, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 016, Runtime 13.885399, Loss 0.650160, forward nfe 4516, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 017, Runtime 13.865929, Loss 0.687801, forward nfe 4812, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 018, Runtime 14.336842, Loss 0.561874, forward nfe 5108, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 019, Runtime 14.680943, Loss 0.548759, forward nfe 5404, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 020, Runtime 14.740286, Loss 0.497613, forward nfe 5700, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 021, Runtime 14.900520, Loss 0.508073, forward nfe 5996, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 022, Runtime 14.431343, Loss 0.508712, forward nfe 6292, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 023, Runtime 14.779104, Loss 0.506620, forward nfe 6588, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 024, Runtime 15.210127, Loss 0.465663, forward nfe 6884, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 025, Runtime 14.465299, Loss 0.441965, forward nfe 7180, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 026, Runtime 14.459118, Loss 0.376383, forward nfe 7476, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 027, Runtime 14.730114, Loss 0.368146, forward nfe 7772, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 028, Runtime 14.063430, Loss 0.421022, forward nfe 8068, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 029, Runtime 14.191626, Loss 0.413362, forward nfe 8364, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 030, Runtime 14.562644, Loss 0.440497, forward nfe 8660, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 031, Runtime 13.872540, Loss 0.366314, forward nfe 8956, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 032, Runtime 14.157690, Loss 0.394082, forward nfe 9252, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 033, Runtime 14.692284, Loss 0.367257, forward nfe 9548, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 034, Runtime 13.892083, Loss 0.326104, forward nfe 9844, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 035, Runtime 14.374914, Loss 0.330074, forward nfe 10140, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 036, Runtime 14.643023, Loss 0.344525, forward nfe 10436, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 037, Runtime 13.930782, Loss 0.294635, forward nfe 10732, backward nfe 0, Train: 0.9214, Val: 0.8228, Test: 0.8162, Best time: 18.2948
Epoch: 038, Runtime 14.354063, Loss 0.299189, forward nfe 11028, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 50.0000
Epoch: 039, Runtime 12.959357, Loss 0.308228, forward nfe 11324, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 040, Runtime 13.765972, Loss 0.326299, forward nfe 11620, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 041, Runtime 13.446370, Loss 0.252286, forward nfe 11916, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 042, Runtime 13.576456, Loss 0.260401, forward nfe 12212, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 043, Runtime 14.128299, Loss 0.281666, forward nfe 12508, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 044, Runtime 13.677402, Loss 0.237833, forward nfe 12804, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 045, Runtime 13.685890, Loss 0.382743, forward nfe 13100, backward nfe 0, Train: 0.9786, Val: 0.8287, Test: 0.8284, Best time: 18.2948
Epoch: 046, Runtime 14.317244, Loss 0.253257, forward nfe 13396, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 54.0000
Epoch: 047, Runtime 12.798919, Loss 0.249736, forward nfe 13692, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 048, Runtime 13.074469, Loss 0.347856, forward nfe 13988, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 049, Runtime 13.147074, Loss 0.300417, forward nfe 14284, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 050, Runtime 13.175798, Loss 0.273688, forward nfe 14580, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 051, Runtime 13.724642, Loss 0.354995, forward nfe 14876, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 052, Runtime 13.458977, Loss 0.278002, forward nfe 15172, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 053, Runtime 13.598958, Loss 0.301693, forward nfe 15468, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 054, Runtime 14.032158, Loss 0.269428, forward nfe 15764, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 055, Runtime 13.995528, Loss 0.285816, forward nfe 16060, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 056, Runtime 14.016636, Loss 0.197458, forward nfe 16356, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 057, Runtime 14.327969, Loss 0.250429, forward nfe 16652, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 058, Runtime 14.377655, Loss 0.230894, forward nfe 16948, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 059, Runtime 14.702764, Loss 0.246668, forward nfe 17244, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 060, Runtime 15.068990, Loss 0.238653, forward nfe 17540, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 061, Runtime 14.736695, Loss 0.219963, forward nfe 17836, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 062, Runtime 14.808582, Loss 0.233342, forward nfe 18132, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 063, Runtime 15.142345, Loss 0.218917, forward nfe 18428, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 064, Runtime 14.928508, Loss 0.293097, forward nfe 18724, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 065, Runtime 15.199681, Loss 0.260132, forward nfe 19020, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 066, Runtime 15.475242, Loss 0.240991, forward nfe 19316, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 067, Runtime 15.286629, Loss 0.341438, forward nfe 19612, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 068, Runtime 15.371755, Loss 0.277567, forward nfe 19908, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 069, Runtime 15.600342, Loss 0.328882, forward nfe 20204, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 070, Runtime 15.505696, Loss 0.256431, forward nfe 20500, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 071, Runtime 15.507940, Loss 0.190487, forward nfe 20796, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 072, Runtime 15.769372, Loss 0.233105, forward nfe 21092, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 073, Runtime 15.700115, Loss 0.282467, forward nfe 21388, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 074, Runtime 15.662131, Loss 0.270561, forward nfe 21684, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 075, Runtime 15.800297, Loss 0.244065, forward nfe 21980, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 076, Runtime 15.780747, Loss 0.281898, forward nfe 22276, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 077, Runtime 15.888557, Loss 0.346669, forward nfe 22572, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 078, Runtime 16.082682, Loss 0.207525, forward nfe 22868, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 079, Runtime 15.957953, Loss 0.275837, forward nfe 23164, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 080, Runtime 15.952213, Loss 0.282947, forward nfe 23460, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 081, Runtime 16.052022, Loss 0.267673, forward nfe 23756, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 082, Runtime 16.035468, Loss 0.267270, forward nfe 24052, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 083, Runtime 16.236928, Loss 0.350710, forward nfe 24348, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 084, Runtime 16.201314, Loss 0.342181, forward nfe 24644, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 085, Runtime 16.139954, Loss 0.282436, forward nfe 24940, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 086, Runtime 16.337459, Loss 0.235079, forward nfe 25236, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 087, Runtime 16.285107, Loss 0.228248, forward nfe 25532, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 088, Runtime 16.271563, Loss 0.270225, forward nfe 25828, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 089, Runtime 16.359897, Loss 0.274490, forward nfe 26124, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 090, Runtime 16.447028, Loss 0.174533, forward nfe 26420, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 091, Runtime 16.232149, Loss 0.248816, forward nfe 26716, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 092, Runtime 16.443816, Loss 0.178563, forward nfe 27012, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 093, Runtime 16.504415, Loss 0.261420, forward nfe 27308, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 094, Runtime 16.333608, Loss 0.154141, forward nfe 27604, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 095, Runtime 16.084164, Loss 0.260882, forward nfe 27900, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 096, Runtime 15.814829, Loss 0.262320, forward nfe 28196, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 097, Runtime 15.616577, Loss 0.179852, forward nfe 28492, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 098, Runtime 15.816397, Loss 0.153886, forward nfe 28788, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
Epoch: 099, Runtime 15.979644, Loss 0.320175, forward nfe 29084, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8376, Best time: 18.2948
best val accuracy 0.834559 with test accuracy 0.837563 at epoch 46 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8375634517766497
Entropy Threshold: 2 Test accuracy: 0.8375634517766497
Entropy Threshold: 1.6 Test accuracy: 0.8447395301327886
Entropy Threshold: 1.5 Test accuracy: 0.8497942386831275
Entropy Threshold: 1.4 Test accuracy: 0.8553590010405827
Entropy Threshold: 1.3 Test accuracy: 0.850104821802935
Entropy Threshold: 1.2 Test accuracy: 0.8568353067814855
Entropy Threshold: 1.1 Test accuracy: 0.867109634551495
Entropy Threshold: 0.9 Test accuracy: 0.8903301886792453
Entropy Threshold: 0.8 Test accuracy: 0.9057071960297767
Entropy Threshold: 0.7 Test accuracy: 0.9139240506329114
Entropy Threshold: 0.6 Test accuracy: 0.921727395411606
Entropy Threshold: 0.5 Test accuracy: 0.9350282485875706
Entropy Threshold: 0.4 Test accuracy: 0.943683409436834
Entropy Threshold: 0.3 Test accuracy: 0.9461663947797716
Entropy Threshold: 0.2 Test accuracy: 0.9512635379061372
Entropy Threshold: 0.1 Test accuracy: 0.9574468085106383
