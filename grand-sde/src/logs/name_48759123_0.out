[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.1
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 12.444521, Loss 2.136415, forward nfe 76, backward nfe 0, Train: 0.4500, Val: 0.3037, Test: 0.3005, Best time: 1.0000
Epoch: 002, Runtime 11.205007, Loss 2.454003, forward nfe 372, backward nfe 0, Train: 0.6000, Val: 0.4059, Test: 0.4284, Best time: 1.0000
Epoch: 003, Runtime 11.148526, Loss 2.226025, forward nfe 668, backward nfe 0, Train: 0.6143, Val: 0.4750, Test: 0.4629, Best time: 1.0000
Epoch: 004, Runtime 11.185061, Loss 2.037906, forward nfe 964, backward nfe 0, Train: 0.5643, Val: 0.4919, Test: 0.4548, Best time: 2.0000
Epoch: 005, Runtime 11.143493, Loss 2.017062, forward nfe 1260, backward nfe 0, Train: 0.6857, Val: 0.5882, Test: 0.5574, Best time: 4.0000
Epoch: 006, Runtime 11.166481, Loss 2.036829, forward nfe 1556, backward nfe 0, Train: 0.8571, Val: 0.7728, Test: 0.7675, Best time: 5.0000
Epoch: 007, Runtime 11.007967, Loss 1.843540, forward nfe 1852, backward nfe 0, Train: 0.8571, Val: 0.7728, Test: 0.7675, Best time: 18.2948
Epoch: 008, Runtime 11.453260, Loss 1.748273, forward nfe 2148, backward nfe 0, Train: 0.8571, Val: 0.7728, Test: 0.7675, Best time: 18.2948
Epoch: 009, Runtime 11.390063, Loss 1.626724, forward nfe 2444, backward nfe 0, Train: 0.8571, Val: 0.7728, Test: 0.7675, Best time: 18.2948
Epoch: 010, Runtime 11.434078, Loss 1.412105, forward nfe 2740, backward nfe 0, Train: 0.8571, Val: 0.7728, Test: 0.7675, Best time: 18.2948
Epoch: 011, Runtime 12.000313, Loss 1.253974, forward nfe 3036, backward nfe 0, Train: 0.8286, Val: 0.7735, Test: 0.7909, Best time: 43.0000
Epoch: 012, Runtime 11.211684, Loss 1.213978, forward nfe 3332, backward nfe 0, Train: 0.8500, Val: 0.7956, Test: 0.8284, Best time: 40.0000
Epoch: 013, Runtime 11.183659, Loss 1.075983, forward nfe 3628, backward nfe 0, Train: 0.9000, Val: 0.8103, Test: 0.8335, Best time: 14.0000
Epoch: 014, Runtime 11.173281, Loss 1.001793, forward nfe 3924, backward nfe 0, Train: 0.8857, Val: 0.8228, Test: 0.8396, Best time: 54.8843
Epoch: 015, Runtime 11.150997, Loss 0.870514, forward nfe 4220, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 19.0000
Epoch: 016, Runtime 11.018810, Loss 0.827731, forward nfe 4516, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 017, Runtime 11.415931, Loss 0.718878, forward nfe 4812, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 018, Runtime 11.328721, Loss 0.761335, forward nfe 5108, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 019, Runtime 11.400845, Loss 0.678140, forward nfe 5404, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 020, Runtime 11.789694, Loss 0.713593, forward nfe 5700, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 021, Runtime 11.614652, Loss 0.616259, forward nfe 5996, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 022, Runtime 11.713116, Loss 0.656400, forward nfe 6292, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 023, Runtime 12.135421, Loss 0.600396, forward nfe 6588, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 024, Runtime 12.079342, Loss 0.546273, forward nfe 6884, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 025, Runtime 11.942877, Loss 0.550945, forward nfe 7180, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 026, Runtime 12.393406, Loss 0.625698, forward nfe 7476, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 027, Runtime 12.346211, Loss 0.573997, forward nfe 7772, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 028, Runtime 12.393497, Loss 0.557907, forward nfe 8068, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 029, Runtime 12.677408, Loss 0.551036, forward nfe 8364, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 030, Runtime 12.610595, Loss 0.571213, forward nfe 8660, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 031, Runtime 12.568557, Loss 0.504920, forward nfe 8956, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 032, Runtime 12.906323, Loss 0.481341, forward nfe 9252, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 033, Runtime 12.758138, Loss 0.382957, forward nfe 9548, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 034, Runtime 12.669262, Loss 0.400767, forward nfe 9844, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 035, Runtime 12.868109, Loss 0.376303, forward nfe 10140, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 036, Runtime 12.917328, Loss 0.491903, forward nfe 10436, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 037, Runtime 12.711828, Loss 0.390748, forward nfe 10732, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 038, Runtime 13.000080, Loss 0.450482, forward nfe 11028, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 039, Runtime 12.993696, Loss 0.392976, forward nfe 11324, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 040, Runtime 13.017683, Loss 0.422420, forward nfe 11620, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 041, Runtime 13.042774, Loss 0.415747, forward nfe 11916, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 042, Runtime 13.171330, Loss 0.404737, forward nfe 12212, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 043, Runtime 13.112832, Loss 0.355261, forward nfe 12508, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 044, Runtime 13.250981, Loss 0.310810, forward nfe 12804, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 045, Runtime 13.298463, Loss 0.285254, forward nfe 13100, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 046, Runtime 13.193382, Loss 0.262302, forward nfe 13396, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 047, Runtime 13.394418, Loss 0.339366, forward nfe 13692, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 048, Runtime 13.251798, Loss 0.355491, forward nfe 13988, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 049, Runtime 13.183033, Loss 0.296065, forward nfe 14284, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 050, Runtime 13.270142, Loss 0.416265, forward nfe 14580, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 051, Runtime 13.358913, Loss 0.352610, forward nfe 14876, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 052, Runtime 13.287925, Loss 0.293040, forward nfe 15172, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 053, Runtime 13.359442, Loss 0.264690, forward nfe 15468, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 054, Runtime 13.436036, Loss 0.381994, forward nfe 15764, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 055, Runtime 13.520936, Loss 0.304038, forward nfe 16060, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 056, Runtime 13.548126, Loss 0.290142, forward nfe 16356, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 057, Runtime 13.470159, Loss 0.262983, forward nfe 16652, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 058, Runtime 13.404908, Loss 0.212835, forward nfe 16948, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 059, Runtime 13.557018, Loss 0.255598, forward nfe 17244, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 060, Runtime 13.574836, Loss 0.291715, forward nfe 17540, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 061, Runtime 13.287714, Loss 0.289557, forward nfe 17836, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 062, Runtime 13.093524, Loss 0.236223, forward nfe 18132, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 063, Runtime 12.401405, Loss 0.286877, forward nfe 18428, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 064, Runtime 11.861791, Loss 0.239898, forward nfe 18724, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 065, Runtime 11.797284, Loss 0.228700, forward nfe 19020, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 066, Runtime 11.897838, Loss 0.323454, forward nfe 19316, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 067, Runtime 11.876884, Loss 0.341368, forward nfe 19612, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 068, Runtime 11.876436, Loss 0.258542, forward nfe 19908, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 069, Runtime 12.882727, Loss 0.328552, forward nfe 20204, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 070, Runtime 13.724187, Loss 0.230169, forward nfe 20500, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 071, Runtime 13.722246, Loss 0.313588, forward nfe 20796, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 072, Runtime 13.812027, Loss 0.315577, forward nfe 21092, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 073, Runtime 13.801171, Loss 0.237033, forward nfe 21388, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 074, Runtime 13.918185, Loss 0.228111, forward nfe 21684, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 075, Runtime 13.758719, Loss 0.232287, forward nfe 21980, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 076, Runtime 13.730868, Loss 0.311643, forward nfe 22276, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 077, Runtime 13.912391, Loss 0.274001, forward nfe 22572, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 078, Runtime 13.856420, Loss 0.271562, forward nfe 22868, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 079, Runtime 13.836415, Loss 0.283382, forward nfe 23164, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 080, Runtime 13.946134, Loss 0.236538, forward nfe 23460, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 081, Runtime 13.894565, Loss 0.228539, forward nfe 23756, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 082, Runtime 13.854946, Loss 0.220348, forward nfe 24052, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 083, Runtime 13.953230, Loss 0.174856, forward nfe 24348, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 084, Runtime 13.940707, Loss 0.251755, forward nfe 24644, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 085, Runtime 13.921721, Loss 0.244991, forward nfe 24940, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 086, Runtime 14.021573, Loss 0.336853, forward nfe 25236, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 087, Runtime 13.936130, Loss 0.266334, forward nfe 25532, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 088, Runtime 13.974719, Loss 0.219752, forward nfe 25828, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 089, Runtime 14.072599, Loss 0.131169, forward nfe 26124, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 090, Runtime 14.118820, Loss 0.264783, forward nfe 26420, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 091, Runtime 13.979258, Loss 0.198239, forward nfe 26716, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 092, Runtime 14.178858, Loss 0.208137, forward nfe 27012, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 093, Runtime 14.040542, Loss 0.166894, forward nfe 27308, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 094, Runtime 13.938535, Loss 0.257400, forward nfe 27604, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 095, Runtime 13.955056, Loss 0.228468, forward nfe 27900, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 096, Runtime 14.159224, Loss 0.147591, forward nfe 28196, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 097, Runtime 13.972704, Loss 0.228082, forward nfe 28492, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 098, Runtime 14.097125, Loss 0.206088, forward nfe 28788, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
Epoch: 099, Runtime 14.107047, Loss 0.224428, forward nfe 29084, backward nfe 0, Train: 0.9214, Val: 0.8272, Test: 0.8426, Best time: 18.2948
best val accuracy 0.827206 with test accuracy 0.842640 at epoch 15 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8426395939086294
Entropy Threshold: 2 Test accuracy: 0.8416243654822335
Entropy Threshold: 1.6 Test accuracy: 0.8684516880093132
Entropy Threshold: 1.5 Test accuracy: 0.8793532338308457
Entropy Threshold: 1.4 Test accuracy: 0.8955223880597015
Entropy Threshold: 1.3 Test accuracy: 0.8932178932178932
Entropy Threshold: 1.2 Test accuracy: 0.9252782193958664
Entropy Threshold: 1.1 Test accuracy: 0.9316546762589928
Entropy Threshold: 0.9 Test accuracy: 0.953810623556582
Entropy Threshold: 0.8 Test accuracy: 0.9640102827763496
Entropy Threshold: 0.7 Test accuracy: 0.9789156626506024
Entropy Threshold: 0.6 Test accuracy: 0.9829931972789115
Entropy Threshold: 0.5 Test accuracy: 0.9844357976653697
Entropy Threshold: 0.4 Test accuracy: 0.9907834101382489
Entropy Threshold: 0.3 Test accuracy: 0.9883040935672515
Entropy Threshold: 0.2 Test accuracy: 0.9848484848484849
Entropy Threshold: 0.1 Test accuracy: 1.0
