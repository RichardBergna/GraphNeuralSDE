[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 7.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 32.196341, Loss 7.136050, forward nfe 76, backward nfe 0, Train: 0.1143, Val: 0.2699, Test: 0.2426, Best time: 18.2948
Epoch: 002, Runtime 50.226532, Loss 17.033672, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2863, Best time: 47.0000
Epoch: 003, Runtime 20.503026, Loss 4.152720, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2863, Best time: 18.2948
Epoch: 004, Runtime 20.261757, Loss 3.999550, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2863, Best time: 18.2948
Epoch: 005, Runtime 21.490998, Loss 3.637882, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2863, Best time: 18.2948
Epoch: 006, Runtime 22.933747, Loss 3.569743, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2863, Best time: 18.2948
Epoch: 007, Runtime 24.777827, Loss 3.347277, forward nfe 1852, backward nfe 0, Train: 0.1500, Val: 0.3140, Test: 0.2853, Best time: 2.0000
Epoch: 008, Runtime 22.540650, Loss 3.291891, forward nfe 2148, backward nfe 0, Train: 0.1714, Val: 0.3485, Test: 0.3208, Best time: 1.0000
Epoch: 009, Runtime 22.868570, Loss 3.207417, forward nfe 2444, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 3.0000
Epoch: 010, Runtime 22.619520, Loss 3.471667, forward nfe 2740, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 011, Runtime 23.802271, Loss 2.944988, forward nfe 3036, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 012, Runtime 24.273900, Loss 3.003033, forward nfe 3332, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 013, Runtime 24.735909, Loss 3.229266, forward nfe 3628, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 014, Runtime 25.162409, Loss 3.207749, forward nfe 3924, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 015, Runtime 26.235537, Loss 2.970211, forward nfe 4220, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 016, Runtime 27.126230, Loss 3.307264, forward nfe 4516, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 017, Runtime 27.949207, Loss 3.141573, forward nfe 4812, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 018, Runtime 28.328880, Loss 3.075808, forward nfe 5108, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 019, Runtime 28.629268, Loss 3.112177, forward nfe 5404, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 020, Runtime 29.121224, Loss 3.167285, forward nfe 5700, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 021, Runtime 29.220450, Loss 2.997414, forward nfe 5996, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 022, Runtime 29.342793, Loss 3.003870, forward nfe 6292, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 023, Runtime 29.589544, Loss 2.909744, forward nfe 6588, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 024, Runtime 30.223814, Loss 2.621770, forward nfe 6884, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 025, Runtime 30.812956, Loss 3.024032, forward nfe 7180, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 026, Runtime 30.676788, Loss 2.780053, forward nfe 7476, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 027, Runtime 30.208986, Loss 2.762047, forward nfe 7772, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 028, Runtime 29.923084, Loss 2.837806, forward nfe 8068, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 029, Runtime 29.818626, Loss 2.768795, forward nfe 8364, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 030, Runtime 29.514604, Loss 3.155875, forward nfe 8660, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 031, Runtime 27.563034, Loss 2.906309, forward nfe 8956, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 032, Runtime 19.796290, Loss 2.949569, forward nfe 9252, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 033, Runtime 20.105536, Loss 3.030907, forward nfe 9548, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 034, Runtime 20.125445, Loss 2.925721, forward nfe 9844, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 035, Runtime 20.408342, Loss 2.744565, forward nfe 10140, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 036, Runtime 21.405808, Loss 2.841411, forward nfe 10436, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 037, Runtime 22.375202, Loss 2.905804, forward nfe 10732, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 038, Runtime 21.732173, Loss 2.852623, forward nfe 11028, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 039, Runtime 22.659633, Loss 2.875194, forward nfe 11324, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 040, Runtime 23.710323, Loss 2.878647, forward nfe 11620, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 041, Runtime 24.338029, Loss 2.830378, forward nfe 11916, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 042, Runtime 25.421270, Loss 2.658532, forward nfe 12212, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 043, Runtime 25.857122, Loss 2.609015, forward nfe 12508, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 044, Runtime 26.070656, Loss 2.693114, forward nfe 12804, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 045, Runtime 26.077076, Loss 2.658870, forward nfe 13100, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 046, Runtime 26.741142, Loss 2.746859, forward nfe 13396, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 047, Runtime 25.569762, Loss 2.548848, forward nfe 13692, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 048, Runtime 26.345750, Loss 2.594982, forward nfe 13988, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 049, Runtime 26.323012, Loss 2.732330, forward nfe 14284, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 050, Runtime 26.825215, Loss 2.645639, forward nfe 14580, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 051, Runtime 27.236913, Loss 2.542954, forward nfe 14876, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 052, Runtime 26.794842, Loss 2.629388, forward nfe 15172, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 053, Runtime 27.449971, Loss 2.605735, forward nfe 15468, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 054, Runtime 27.441334, Loss 2.706501, forward nfe 15764, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 055, Runtime 28.382937, Loss 2.612945, forward nfe 16060, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 056, Runtime 28.741826, Loss 2.706507, forward nfe 16356, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 057, Runtime 29.928251, Loss 2.504795, forward nfe 16652, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 058, Runtime 28.874574, Loss 2.617733, forward nfe 16948, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 059, Runtime 29.105510, Loss 2.453881, forward nfe 17244, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 060, Runtime 25.860360, Loss 2.645075, forward nfe 17540, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 061, Runtime 19.352103, Loss 2.671323, forward nfe 17836, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 062, Runtime 20.133697, Loss 2.509032, forward nfe 18132, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 063, Runtime 20.115207, Loss 2.615437, forward nfe 18428, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 064, Runtime 21.539658, Loss 2.627710, forward nfe 18724, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 065, Runtime 22.235929, Loss 2.628438, forward nfe 19020, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 066, Runtime 22.976706, Loss 2.523306, forward nfe 19316, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 067, Runtime 23.367503, Loss 2.437359, forward nfe 19612, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 068, Runtime 23.376567, Loss 2.509484, forward nfe 19908, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 069, Runtime 24.705980, Loss 2.569503, forward nfe 20204, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 070, Runtime 24.569678, Loss 2.362156, forward nfe 20500, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 071, Runtime 24.916683, Loss 2.544442, forward nfe 20796, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 072, Runtime 25.076843, Loss 2.464027, forward nfe 21092, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 073, Runtime 26.059774, Loss 2.500204, forward nfe 21388, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 074, Runtime 26.127021, Loss 2.408715, forward nfe 21684, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 075, Runtime 26.624380, Loss 2.334760, forward nfe 21980, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 076, Runtime 27.039521, Loss 2.545300, forward nfe 22276, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 077, Runtime 27.227001, Loss 2.554542, forward nfe 22572, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 078, Runtime 27.531598, Loss 2.422823, forward nfe 22868, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 079, Runtime 27.374152, Loss 2.597593, forward nfe 23164, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 080, Runtime 27.242766, Loss 2.459075, forward nfe 23460, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 081, Runtime 27.503014, Loss 2.661475, forward nfe 23756, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 082, Runtime 28.307125, Loss 2.476700, forward nfe 24052, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 083, Runtime 28.315559, Loss 2.438106, forward nfe 24348, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 084, Runtime 29.076039, Loss 2.391237, forward nfe 24644, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 085, Runtime 19.878880, Loss 2.626874, forward nfe 24940, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 086, Runtime 19.057142, Loss 2.506232, forward nfe 25236, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 087, Runtime 19.516945, Loss 2.324869, forward nfe 25532, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 088, Runtime 20.172617, Loss 2.451838, forward nfe 25828, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 089, Runtime 20.038968, Loss 2.507953, forward nfe 26124, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 090, Runtime 20.785324, Loss 2.409438, forward nfe 26420, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 091, Runtime 21.255347, Loss 2.466553, forward nfe 26716, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 092, Runtime 22.124456, Loss 2.368346, forward nfe 27012, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 093, Runtime 21.825733, Loss 2.533174, forward nfe 27308, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 094, Runtime 22.139752, Loss 2.421863, forward nfe 27604, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 095, Runtime 22.753353, Loss 2.378816, forward nfe 27900, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 096, Runtime 23.609528, Loss 2.415263, forward nfe 28196, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 097, Runtime 23.419899, Loss 2.408880, forward nfe 28492, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 098, Runtime 24.209574, Loss 2.408513, forward nfe 28788, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
Epoch: 099, Runtime 24.350513, Loss 2.363709, forward nfe 29084, backward nfe 0, Train: 0.2143, Val: 0.3721, Test: 0.3279, Best time: 18.2948
best val accuracy 0.372059 with test accuracy 0.327919 at epoch 9 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.10253807106598985
Entropy Threshold: 2 Test accuracy: 0.09949238578680203
Entropy Threshold: 1.6 Test accuracy: 0.091324200913242
Entropy Threshold: 1.5 Test accuracy: 0.07692307692307693
Entropy Threshold: 1.4 Test accuracy: 0.13636363636363635
Entropy Threshold: 1.3 Test accuracy: 0.08823529411764706
Entropy Threshold: 1.2 Test accuracy: 0.10526315789473684
Entropy Threshold: 1.1 Test accuracy: 0.17647058823529413
Entropy Threshold: 0.9 Test accuracy: 0.08333333333333333
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: None
