[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 10.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 38.125111, Loss 4.590540, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.3022, Test: 0.2985, Best time: 47.0000
Epoch: 002, Runtime 47.730472, Loss 28.045218, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.3059, Test: 0.2995, Best time: 2.0000
Epoch: 003, Runtime 25.786086, Loss 6.578446, forward nfe 668, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 1.0000
Epoch: 004, Runtime 23.121577, Loss 5.890533, forward nfe 964, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 005, Runtime 23.750327, Loss 5.554108, forward nfe 1260, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 006, Runtime 24.475572, Loss 5.529107, forward nfe 1556, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 007, Runtime 24.050953, Loss 5.402847, forward nfe 1852, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 008, Runtime 24.458688, Loss 4.856452, forward nfe 2148, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 009, Runtime 24.937355, Loss 4.531237, forward nfe 2444, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 010, Runtime 26.147922, Loss 4.335197, forward nfe 2740, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 011, Runtime 26.852753, Loss 3.924981, forward nfe 3036, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 012, Runtime 28.335352, Loss 3.783786, forward nfe 3332, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 013, Runtime 29.593849, Loss 3.492271, forward nfe 3628, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 014, Runtime 30.326911, Loss 3.799159, forward nfe 3924, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 015, Runtime 31.724677, Loss 3.499822, forward nfe 4220, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 016, Runtime 31.793881, Loss 3.389696, forward nfe 4516, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 017, Runtime 33.332088, Loss 3.367027, forward nfe 4812, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 018, Runtime 33.463930, Loss 3.461156, forward nfe 5108, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 019, Runtime 34.077623, Loss 3.330750, forward nfe 5404, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 020, Runtime 33.596558, Loss 3.092793, forward nfe 5700, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 021, Runtime 33.634298, Loss 3.247206, forward nfe 5996, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 022, Runtime 28.957565, Loss 3.461485, forward nfe 6292, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 023, Runtime 22.274646, Loss 3.384972, forward nfe 6588, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 024, Runtime 22.213372, Loss 3.607326, forward nfe 6884, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 025, Runtime 22.672948, Loss 3.592714, forward nfe 7180, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 026, Runtime 22.308163, Loss 3.223026, forward nfe 7476, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 027, Runtime 23.731406, Loss 3.394271, forward nfe 7772, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 028, Runtime 24.071201, Loss 3.213290, forward nfe 8068, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 029, Runtime 25.284108, Loss 3.392750, forward nfe 8364, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 030, Runtime 24.649906, Loss 3.054770, forward nfe 8660, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 031, Runtime 25.387528, Loss 3.277400, forward nfe 8956, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 032, Runtime 25.148426, Loss 3.088721, forward nfe 9252, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 033, Runtime 25.836479, Loss 3.037959, forward nfe 9548, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 034, Runtime 26.315690, Loss 3.254628, forward nfe 9844, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 035, Runtime 25.740481, Loss 3.387959, forward nfe 10140, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 036, Runtime 26.224263, Loss 3.323318, forward nfe 10436, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 037, Runtime 26.416859, Loss 3.240973, forward nfe 10732, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 038, Runtime 26.658002, Loss 3.078206, forward nfe 11028, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 039, Runtime 26.847197, Loss 3.336395, forward nfe 11324, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 040, Runtime 26.928800, Loss 3.056007, forward nfe 11620, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 041, Runtime 27.111662, Loss 2.840927, forward nfe 11916, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 042, Runtime 27.017407, Loss 2.933353, forward nfe 12212, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 043, Runtime 27.188738, Loss 3.018777, forward nfe 12508, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 044, Runtime 27.415075, Loss 3.386125, forward nfe 12804, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 045, Runtime 27.110203, Loss 3.004521, forward nfe 13100, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 046, Runtime 27.118840, Loss 2.953924, forward nfe 13396, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 047, Runtime 27.321509, Loss 2.936234, forward nfe 13692, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 048, Runtime 27.331409, Loss 3.124570, forward nfe 13988, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 049, Runtime 27.820227, Loss 3.001694, forward nfe 14284, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 050, Runtime 27.877556, Loss 3.172600, forward nfe 14580, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 051, Runtime 28.194202, Loss 3.083812, forward nfe 14876, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 052, Runtime 28.387244, Loss 2.986639, forward nfe 15172, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 053, Runtime 28.807944, Loss 2.814914, forward nfe 15468, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 054, Runtime 28.728489, Loss 3.027817, forward nfe 15764, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 055, Runtime 29.083811, Loss 2.739136, forward nfe 16060, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 056, Runtime 25.813639, Loss 2.922239, forward nfe 16356, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 057, Runtime 19.116204, Loss 2.844721, forward nfe 16652, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 058, Runtime 19.629459, Loss 2.630761, forward nfe 16948, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 059, Runtime 19.959396, Loss 3.000088, forward nfe 17244, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 060, Runtime 20.812497, Loss 2.699640, forward nfe 17540, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 061, Runtime 21.711868, Loss 2.756680, forward nfe 17836, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 062, Runtime 21.884914, Loss 2.692018, forward nfe 18132, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 063, Runtime 22.508247, Loss 3.022746, forward nfe 18428, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 064, Runtime 23.289174, Loss 2.808957, forward nfe 18724, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 065, Runtime 24.157209, Loss 2.825700, forward nfe 19020, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 066, Runtime 24.287308, Loss 3.088606, forward nfe 19316, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 067, Runtime 24.705971, Loss 2.809870, forward nfe 19612, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 068, Runtime 24.629616, Loss 2.751238, forward nfe 19908, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 069, Runtime 24.766788, Loss 2.858988, forward nfe 20204, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 070, Runtime 25.112652, Loss 2.608250, forward nfe 20500, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 071, Runtime 25.446024, Loss 2.602273, forward nfe 20796, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 072, Runtime 25.651983, Loss 2.908515, forward nfe 21092, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 073, Runtime 25.928550, Loss 2.796484, forward nfe 21388, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 074, Runtime 26.132591, Loss 2.640307, forward nfe 21684, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 075, Runtime 26.641025, Loss 2.648065, forward nfe 21980, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 076, Runtime 26.713142, Loss 2.979874, forward nfe 22276, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 077, Runtime 27.476959, Loss 2.532992, forward nfe 22572, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 078, Runtime 28.440230, Loss 2.744031, forward nfe 22868, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 079, Runtime 28.278706, Loss 2.461699, forward nfe 23164, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 080, Runtime 28.776472, Loss 2.598936, forward nfe 23460, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 081, Runtime 28.757094, Loss 2.782831, forward nfe 23756, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 082, Runtime 29.109649, Loss 2.500592, forward nfe 24052, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 083, Runtime 29.240556, Loss 2.890828, forward nfe 24348, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 084, Runtime 29.741510, Loss 2.772305, forward nfe 24644, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 085, Runtime 25.809149, Loss 2.468057, forward nfe 24940, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 086, Runtime 19.334628, Loss 2.576214, forward nfe 25236, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 087, Runtime 20.200360, Loss 2.757197, forward nfe 25532, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 088, Runtime 20.618595, Loss 2.747423, forward nfe 25828, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 089, Runtime 20.974315, Loss 2.625789, forward nfe 26124, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 090, Runtime 22.238625, Loss 2.513104, forward nfe 26420, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 091, Runtime 22.437158, Loss 2.609351, forward nfe 26716, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 092, Runtime 23.044891, Loss 2.628458, forward nfe 27012, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 093, Runtime 23.748457, Loss 2.801905, forward nfe 27308, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 094, Runtime 23.479415, Loss 2.488550, forward nfe 27604, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 095, Runtime 24.430203, Loss 2.668799, forward nfe 27900, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 096, Runtime 24.956166, Loss 2.685493, forward nfe 28196, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 097, Runtime 25.122549, Loss 2.657204, forward nfe 28492, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 098, Runtime 25.610042, Loss 2.523678, forward nfe 28788, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 099, Runtime 25.778522, Loss 2.800577, forward nfe 29084, backward nfe 0, Train: 0.1857, Val: 0.3066, Test: 0.2944, Best time: 18.2948
best val accuracy 0.306618 with test accuracy 0.294416 at epoch 3 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.2416243654822335
Entropy Threshold: 2 Test accuracy: 0.23147208121827412
Entropy Threshold: 1.6 Test accuracy: 0.22741116751269036
Entropy Threshold: 1.5 Test accuracy: 0.2233502538071066
Entropy Threshold: 1.4 Test accuracy: 0.2104722792607803
Entropy Threshold: 1.3 Test accuracy: 0.2339688041594454
Entropy Threshold: 1.2 Test accuracy: 0.18478260869565216
Entropy Threshold: 1.1 Test accuracy: 0.17073170731707318
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
