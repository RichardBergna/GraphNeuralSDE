[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 4.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 21.053027, Loss 2.960651, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1081, Test: 0.1208, Best time: 1.0000
Epoch: 002, Runtime 35.564229, Loss 23.826124, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1191, Test: 0.1239, Best time: 18.2948
Epoch: 003, Runtime 16.514202, Loss 3.501593, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1419, Test: 0.1421, Best time: 18.2948
Epoch: 004, Runtime 16.120710, Loss 3.454777, forward nfe 964, backward nfe 0, Train: 0.0929, Val: 0.1721, Test: 0.1624, Best time: 18.2948
Epoch: 005, Runtime 17.156109, Loss 3.488188, forward nfe 1260, backward nfe 0, Train: 0.1214, Val: 0.1831, Test: 0.1909, Best time: 18.2948
Epoch: 006, Runtime 18.376285, Loss 3.702994, forward nfe 1556, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 007, Runtime 19.777298, Loss 3.861909, forward nfe 1852, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 008, Runtime 20.903624, Loss 3.483476, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 009, Runtime 21.420086, Loss 3.306702, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 010, Runtime 21.719203, Loss 3.171857, forward nfe 2740, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 011, Runtime 22.719567, Loss 2.988578, forward nfe 3036, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 012, Runtime 22.989905, Loss 2.910422, forward nfe 3332, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 013, Runtime 23.564094, Loss 3.124432, forward nfe 3628, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 014, Runtime 24.124804, Loss 2.648453, forward nfe 3924, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 015, Runtime 23.889277, Loss 2.850029, forward nfe 4220, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 016, Runtime 23.656517, Loss 2.761287, forward nfe 4516, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 017, Runtime 23.833017, Loss 2.773975, forward nfe 4812, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 018, Runtime 24.166287, Loss 2.841451, forward nfe 5108, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 019, Runtime 23.963038, Loss 2.704604, forward nfe 5404, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 020, Runtime 24.096256, Loss 2.638038, forward nfe 5700, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 021, Runtime 24.078807, Loss 2.622903, forward nfe 5996, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 022, Runtime 24.728050, Loss 2.463882, forward nfe 6292, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 023, Runtime 25.174917, Loss 2.488919, forward nfe 6588, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 024, Runtime 24.953538, Loss 2.708947, forward nfe 6884, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 025, Runtime 25.396950, Loss 2.651797, forward nfe 7180, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 026, Runtime 25.602468, Loss 2.444312, forward nfe 7476, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 027, Runtime 25.788230, Loss 2.577779, forward nfe 7772, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 028, Runtime 25.762917, Loss 2.620327, forward nfe 8068, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 029, Runtime 25.833230, Loss 2.525494, forward nfe 8364, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 030, Runtime 25.895811, Loss 2.536002, forward nfe 8660, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 031, Runtime 26.208410, Loss 2.385579, forward nfe 8956, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 032, Runtime 26.099841, Loss 2.546867, forward nfe 9252, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 033, Runtime 25.793522, Loss 2.511944, forward nfe 9548, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 034, Runtime 26.044599, Loss 2.508102, forward nfe 9844, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 035, Runtime 26.247106, Loss 2.470737, forward nfe 10140, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 036, Runtime 26.434704, Loss 2.499287, forward nfe 10436, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 037, Runtime 26.228267, Loss 2.466010, forward nfe 10732, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 038, Runtime 22.946087, Loss 2.556330, forward nfe 11028, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 039, Runtime 17.579608, Loss 2.376658, forward nfe 11324, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 040, Runtime 18.437032, Loss 2.562845, forward nfe 11620, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 041, Runtime 18.758980, Loss 2.366508, forward nfe 11916, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 042, Runtime 19.157587, Loss 2.528657, forward nfe 12212, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 043, Runtime 20.233442, Loss 2.450018, forward nfe 12508, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 044, Runtime 20.250609, Loss 2.447824, forward nfe 12804, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 045, Runtime 20.740091, Loss 2.494070, forward nfe 13100, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 046, Runtime 21.306638, Loss 2.395911, forward nfe 13396, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 047, Runtime 21.643746, Loss 2.365000, forward nfe 13692, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 048, Runtime 21.974133, Loss 2.473140, forward nfe 13988, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 049, Runtime 22.665618, Loss 2.323562, forward nfe 14284, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 050, Runtime 23.052773, Loss 2.540924, forward nfe 14580, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 051, Runtime 23.118488, Loss 2.500541, forward nfe 14876, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 052, Runtime 23.623730, Loss 2.345796, forward nfe 15172, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 053, Runtime 24.047267, Loss 2.388889, forward nfe 15468, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 054, Runtime 24.222624, Loss 2.393174, forward nfe 15764, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 055, Runtime 24.476179, Loss 2.281516, forward nfe 16060, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 056, Runtime 24.612381, Loss 2.349809, forward nfe 16356, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 057, Runtime 24.813196, Loss 2.322356, forward nfe 16652, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 058, Runtime 25.057787, Loss 2.424458, forward nfe 16948, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 059, Runtime 24.897070, Loss 2.350771, forward nfe 17244, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 060, Runtime 24.837254, Loss 2.372593, forward nfe 17540, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 061, Runtime 24.688457, Loss 2.490235, forward nfe 17836, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 062, Runtime 25.217986, Loss 2.210965, forward nfe 18132, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 063, Runtime 25.236483, Loss 2.136278, forward nfe 18428, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 064, Runtime 25.484212, Loss 2.348098, forward nfe 18724, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 065, Runtime 22.459544, Loss 2.372477, forward nfe 19020, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 066, Runtime 17.118916, Loss 2.389346, forward nfe 19316, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 067, Runtime 17.169800, Loss 2.308371, forward nfe 19612, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 068, Runtime 17.449324, Loss 2.258570, forward nfe 19908, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 069, Runtime 17.889709, Loss 2.345608, forward nfe 20204, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 070, Runtime 18.013290, Loss 2.347371, forward nfe 20500, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 071, Runtime 18.281474, Loss 2.356118, forward nfe 20796, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 072, Runtime 18.733417, Loss 2.175446, forward nfe 21092, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 073, Runtime 18.963190, Loss 2.194559, forward nfe 21388, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 074, Runtime 19.179263, Loss 2.262726, forward nfe 21684, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 075, Runtime 19.821863, Loss 2.444011, forward nfe 21980, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 076, Runtime 19.935905, Loss 2.271881, forward nfe 22276, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 077, Runtime 19.889477, Loss 2.316185, forward nfe 22572, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 078, Runtime 20.499398, Loss 2.383863, forward nfe 22868, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 079, Runtime 20.599196, Loss 2.393386, forward nfe 23164, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 080, Runtime 20.969279, Loss 2.336048, forward nfe 23460, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 081, Runtime 21.279516, Loss 2.152718, forward nfe 23756, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 082, Runtime 21.256597, Loss 2.505852, forward nfe 24052, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 083, Runtime 21.691736, Loss 2.203862, forward nfe 24348, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 084, Runtime 22.026376, Loss 2.259631, forward nfe 24644, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 085, Runtime 22.300508, Loss 2.267376, forward nfe 24940, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 086, Runtime 22.669521, Loss 2.343846, forward nfe 25236, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 087, Runtime 22.795456, Loss 2.202877, forward nfe 25532, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 088, Runtime 22.835077, Loss 2.473590, forward nfe 25828, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 089, Runtime 23.206868, Loss 2.361209, forward nfe 26124, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 090, Runtime 23.345530, Loss 2.154367, forward nfe 26420, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 091, Runtime 23.261794, Loss 2.276343, forward nfe 26716, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 092, Runtime 23.365120, Loss 2.271658, forward nfe 27012, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 093, Runtime 23.693923, Loss 2.341088, forward nfe 27308, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 094, Runtime 23.867535, Loss 2.332162, forward nfe 27604, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 095, Runtime 24.732856, Loss 2.188168, forward nfe 27900, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 096, Runtime 24.485040, Loss 2.240545, forward nfe 28196, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 097, Runtime 24.617368, Loss 2.256224, forward nfe 28492, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 098, Runtime 25.017878, Loss 2.242777, forward nfe 28788, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
Epoch: 099, Runtime 25.189873, Loss 2.273944, forward nfe 29084, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.2071, Best time: 18.2948
best val accuracy 0.211029 with test accuracy 0.207107 at epoch 6 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.2436548223350254
Entropy Threshold: 2 Test accuracy: 0.2436548223350254
Entropy Threshold: 1.6 Test accuracy: 0.23632610939112486
Entropy Threshold: 1.5 Test accuracy: 0.22661870503597123
Entropy Threshold: 1.4 Test accuracy: 0.3225806451612903
Entropy Threshold: 1.3 Test accuracy: 0.45454545454545453
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
