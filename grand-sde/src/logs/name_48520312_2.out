[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 11.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 57.862653, Loss 16.983778, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2924, Best time: 18.2948
Epoch: 002, Runtime 67.510027, Loss 43.617111, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2924, Best time: 18.2948
Epoch: 003, Runtime 28.856483, Loss 6.431218, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2924, Best time: 18.2948
Epoch: 004, Runtime 28.719959, Loss 7.253094, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 26.0000
Epoch: 005, Runtime 27.991056, Loss 5.657607, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 006, Runtime 28.471746, Loss 5.351829, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 007, Runtime 29.378482, Loss 5.318188, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 008, Runtime 29.525481, Loss 4.850578, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 009, Runtime 30.460770, Loss 4.885374, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 010, Runtime 32.442237, Loss 4.682490, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 011, Runtime 33.696024, Loss 4.362709, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 012, Runtime 35.447473, Loss 4.194906, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 013, Runtime 35.405328, Loss 4.077684, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 014, Runtime 36.049064, Loss 3.907858, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 015, Runtime 37.356116, Loss 4.177309, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 016, Runtime 38.161807, Loss 4.320129, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 017, Runtime 38.184139, Loss 4.216913, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 018, Runtime 34.672998, Loss 3.757318, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 019, Runtime 27.414344, Loss 3.936136, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 020, Runtime 28.463206, Loss 3.373791, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 021, Runtime 29.796730, Loss 3.546706, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 022, Runtime 30.778360, Loss 3.443989, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 023, Runtime 31.850164, Loss 3.754349, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 024, Runtime 33.110741, Loss 3.541568, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 025, Runtime 33.098309, Loss 3.514259, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 026, Runtime 34.305811, Loss 3.368742, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 027, Runtime 34.076290, Loss 3.663293, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 028, Runtime 34.958166, Loss 3.208332, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 029, Runtime 35.195981, Loss 3.342437, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 030, Runtime 35.712422, Loss 3.456545, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 031, Runtime 35.829454, Loss 3.340754, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 032, Runtime 36.194158, Loss 3.544981, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 033, Runtime 36.377667, Loss 3.707025, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 034, Runtime 36.155484, Loss 3.372715, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 035, Runtime 31.881937, Loss 3.560613, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 036, Runtime 24.207264, Loss 3.862835, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 037, Runtime 24.862997, Loss 3.524516, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 038, Runtime 26.210708, Loss 3.199920, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 039, Runtime 27.315747, Loss 3.403596, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 040, Runtime 27.073514, Loss 3.295223, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 041, Runtime 27.586564, Loss 3.015872, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 042, Runtime 29.076763, Loss 3.538019, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 043, Runtime 29.610211, Loss 3.323602, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 044, Runtime 30.668497, Loss 3.398228, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 045, Runtime 31.378502, Loss 3.277077, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 046, Runtime 31.040957, Loss 3.474378, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 047, Runtime 31.651035, Loss 3.498214, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 048, Runtime 32.575211, Loss 3.600508, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 049, Runtime 33.742103, Loss 3.106409, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 050, Runtime 33.661329, Loss 3.052936, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 051, Runtime 34.193653, Loss 3.585942, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 052, Runtime 34.342562, Loss 3.445566, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 053, Runtime 34.566659, Loss 3.005425, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 054, Runtime 34.351481, Loss 3.252681, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 055, Runtime 31.815807, Loss 3.065255, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 056, Runtime 23.542593, Loss 3.138296, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 057, Runtime 23.526991, Loss 3.321249, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 058, Runtime 23.749963, Loss 3.157459, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 059, Runtime 24.311444, Loss 3.347579, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 060, Runtime 25.204735, Loss 3.038876, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 061, Runtime 26.054926, Loss 3.101487, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 062, Runtime 27.194844, Loss 3.252800, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 063, Runtime 27.686049, Loss 3.171334, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 064, Runtime 28.044625, Loss 3.146794, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 065, Runtime 28.752239, Loss 3.070241, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 066, Runtime 29.494184, Loss 2.959113, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 067, Runtime 30.133253, Loss 3.235454, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 068, Runtime 30.634951, Loss 2.789392, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 069, Runtime 30.220184, Loss 3.281742, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 070, Runtime 31.282292, Loss 3.097332, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 071, Runtime 31.241514, Loss 3.113056, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 072, Runtime 32.478824, Loss 3.055281, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 073, Runtime 32.810098, Loss 3.047990, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 074, Runtime 33.180671, Loss 3.271959, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 075, Runtime 33.505667, Loss 3.113904, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 076, Runtime 33.678053, Loss 3.217439, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 077, Runtime 33.731467, Loss 3.073617, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 078, Runtime 32.625189, Loss 3.279749, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 079, Runtime 34.297436, Loss 2.915272, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 080, Runtime 34.910546, Loss 2.777603, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 081, Runtime 35.196804, Loss 2.847818, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 082, Runtime 34.121822, Loss 2.889612, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 083, Runtime 30.298844, Loss 3.042308, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 084, Runtime 22.207913, Loss 2.903871, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 085, Runtime 22.592538, Loss 3.022856, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 086, Runtime 24.149052, Loss 3.118367, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 087, Runtime 24.089093, Loss 3.314078, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 088, Runtime 25.608402, Loss 3.236173, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 089, Runtime 27.218490, Loss 3.103046, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 090, Runtime 27.935479, Loss 3.025900, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 091, Runtime 29.028329, Loss 3.001385, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 092, Runtime 30.021457, Loss 2.831638, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 093, Runtime 30.243875, Loss 3.100712, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 094, Runtime 30.748193, Loss 3.166729, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 095, Runtime 31.321705, Loss 2.972242, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 096, Runtime 31.603862, Loss 3.314989, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 097, Runtime 32.539591, Loss 2.894115, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 098, Runtime 33.507638, Loss 3.298378, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
Epoch: 099, Runtime 33.493345, Loss 3.115548, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3081, Test: 0.2924, Best time: 18.2948
best val accuracy 0.308088 with test accuracy 0.292386 at epoch 4 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.14822335025380712
Entropy Threshold: 2 Test accuracy: 0.14923857868020304
Entropy Threshold: 1.6 Test accuracy: 0.14822335025380712
Entropy Threshold: 1.5 Test accuracy: 0.1612565445026178
Entropy Threshold: 1.4 Test accuracy: 0.17012987012987013
Entropy Threshold: 1.3 Test accuracy: 0.1449814126394052
Entropy Threshold: 1.2 Test accuracy: 0.18705035971223022
Entropy Threshold: 1.1 Test accuracy: 0.1693548387096774
Entropy Threshold: 0.9 Test accuracy: 0.24324324324324326
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.08333333333333333
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: 0.0
