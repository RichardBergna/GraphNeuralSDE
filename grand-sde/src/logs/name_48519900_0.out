[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.5
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 20.135674, Loss 2.043652, forward nfe 76, backward nfe 0, Train: 0.2857, Val: 0.1419, Test: 0.1198, Best time: 1.0000
Epoch: 002, Runtime 21.121892, Loss 2.026617, forward nfe 372, backward nfe 0, Train: 0.5286, Val: 0.3596, Test: 0.3533, Best time: 2.0000
Epoch: 003, Runtime 19.895322, Loss 1.906262, forward nfe 668, backward nfe 0, Train: 0.6000, Val: 0.4118, Test: 0.4102, Best time: 2.0000
Epoch: 004, Runtime 19.246529, Loss 1.723696, forward nfe 964, backward nfe 0, Train: 0.7143, Val: 0.4669, Test: 0.4690, Best time: 4.0000
Epoch: 005, Runtime 19.230444, Loss 1.598419, forward nfe 1260, backward nfe 0, Train: 0.7714, Val: 0.5412, Test: 0.5371, Best time: 4.0000
Epoch: 006, Runtime 19.422782, Loss 1.478492, forward nfe 1556, backward nfe 0, Train: 0.8214, Val: 0.6184, Test: 0.6203, Best time: 7.0000
Epoch: 007, Runtime 19.202286, Loss 1.183773, forward nfe 1852, backward nfe 0, Train: 0.8500, Val: 0.6757, Test: 0.6751, Best time: 7.0000
Epoch: 008, Runtime 19.002963, Loss 1.027223, forward nfe 2148, backward nfe 0, Train: 0.8929, Val: 0.7118, Test: 0.7320, Best time: 8.0000
Epoch: 009, Runtime 19.434844, Loss 0.812562, forward nfe 2444, backward nfe 0, Train: 0.9214, Val: 0.7485, Test: 0.7584, Best time: 18.0000
Epoch: 010, Runtime 19.240825, Loss 0.654103, forward nfe 2740, backward nfe 0, Train: 0.9143, Val: 0.7618, Test: 0.7746, Best time: 15.0000
Epoch: 011, Runtime 18.970887, Loss 0.546970, forward nfe 3036, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 22.0000
Epoch: 012, Runtime 18.783597, Loss 0.440940, forward nfe 3332, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 013, Runtime 19.721280, Loss 0.418862, forward nfe 3628, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 014, Runtime 19.501172, Loss 0.340874, forward nfe 3924, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 015, Runtime 19.468810, Loss 0.392048, forward nfe 4220, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 016, Runtime 20.897514, Loss 0.354642, forward nfe 4516, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 017, Runtime 20.513789, Loss 0.383452, forward nfe 4812, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 018, Runtime 20.882333, Loss 0.324181, forward nfe 5108, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 019, Runtime 21.822241, Loss 0.291050, forward nfe 5404, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 020, Runtime 21.361395, Loss 0.392201, forward nfe 5700, backward nfe 0, Train: 0.9286, Val: 0.7647, Test: 0.7736, Best time: 18.2948
Epoch: 021, Runtime 21.818089, Loss 0.280821, forward nfe 5996, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 022, Runtime 19.195157, Loss 0.364551, forward nfe 6292, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 023, Runtime 19.198602, Loss 0.265517, forward nfe 6588, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 024, Runtime 19.126199, Loss 0.310359, forward nfe 6884, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 025, Runtime 19.013608, Loss 0.269445, forward nfe 7180, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 026, Runtime 19.766978, Loss 0.266352, forward nfe 7476, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 027, Runtime 19.814666, Loss 0.262688, forward nfe 7772, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 028, Runtime 19.839837, Loss 0.296197, forward nfe 8068, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 029, Runtime 20.799697, Loss 0.229991, forward nfe 8364, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 030, Runtime 20.412717, Loss 0.308573, forward nfe 8660, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 031, Runtime 20.839040, Loss 0.250169, forward nfe 8956, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 032, Runtime 21.481757, Loss 0.262304, forward nfe 9252, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 033, Runtime 21.229405, Loss 0.230629, forward nfe 9548, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 034, Runtime 21.073097, Loss 0.240966, forward nfe 9844, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 035, Runtime 21.674765, Loss 0.278742, forward nfe 10140, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 036, Runtime 21.580559, Loss 0.212944, forward nfe 10436, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 037, Runtime 21.568078, Loss 0.256093, forward nfe 10732, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 038, Runtime 22.371923, Loss 0.233325, forward nfe 11028, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 039, Runtime 22.309439, Loss 0.192223, forward nfe 11324, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 040, Runtime 22.398695, Loss 0.265436, forward nfe 11620, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 041, Runtime 22.817899, Loss 0.242728, forward nfe 11916, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 042, Runtime 22.746426, Loss 0.260439, forward nfe 12212, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 043, Runtime 22.627311, Loss 0.170708, forward nfe 12508, backward nfe 0, Train: 0.9643, Val: 0.7684, Test: 0.7848, Best time: 18.2948
Epoch: 044, Runtime 22.922504, Loss 0.199706, forward nfe 12804, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.0000
Epoch: 045, Runtime 18.250957, Loss 0.240748, forward nfe 13100, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 046, Runtime 18.911119, Loss 0.195846, forward nfe 13396, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 047, Runtime 18.865823, Loss 0.206123, forward nfe 13692, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 048, Runtime 18.854756, Loss 0.244764, forward nfe 13988, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 049, Runtime 19.784977, Loss 0.219812, forward nfe 14284, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 050, Runtime 19.386620, Loss 0.364822, forward nfe 14580, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 051, Runtime 19.469909, Loss 0.234741, forward nfe 14876, backward nfe 0, Train: 0.9929, Val: 0.7721, Test: 0.7777, Best time: 18.2948
Epoch: 052, Runtime 20.512024, Loss 0.254159, forward nfe 15172, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 43.0000
Epoch: 053, Runtime 17.988361, Loss 0.202026, forward nfe 15468, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 054, Runtime 18.599517, Loss 0.209869, forward nfe 15764, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 055, Runtime 18.644995, Loss 0.193267, forward nfe 16060, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 056, Runtime 18.654624, Loss 0.256874, forward nfe 16356, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 057, Runtime 19.453607, Loss 0.200895, forward nfe 16652, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 058, Runtime 19.244275, Loss 0.191907, forward nfe 16948, backward nfe 0, Train: 0.9857, Val: 0.7735, Test: 0.7878, Best time: 18.2948
Epoch: 059, Runtime 19.781322, Loss 0.172933, forward nfe 17244, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 49.0000
Epoch: 060, Runtime 18.100136, Loss 0.245194, forward nfe 17540, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 061, Runtime 18.723433, Loss 0.185493, forward nfe 17836, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 062, Runtime 18.648229, Loss 0.163683, forward nfe 18132, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 063, Runtime 18.773914, Loss 0.150856, forward nfe 18428, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 064, Runtime 18.706147, Loss 0.236125, forward nfe 18724, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 065, Runtime 17.901934, Loss 0.178962, forward nfe 19020, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 066, Runtime 14.225852, Loss 0.130816, forward nfe 19316, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 067, Runtime 14.526126, Loss 0.123095, forward nfe 19612, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 068, Runtime 14.416070, Loss 0.213166, forward nfe 19908, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 069, Runtime 14.539690, Loss 0.225004, forward nfe 20204, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 070, Runtime 14.951229, Loss 0.291198, forward nfe 20500, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 071, Runtime 14.967367, Loss 0.213031, forward nfe 20796, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 072, Runtime 14.996563, Loss 0.215494, forward nfe 21092, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 073, Runtime 15.356642, Loss 0.201912, forward nfe 21388, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 074, Runtime 15.532927, Loss 0.229489, forward nfe 21684, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 075, Runtime 16.114993, Loss 0.152635, forward nfe 21980, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 076, Runtime 16.474487, Loss 0.173235, forward nfe 22276, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 077, Runtime 16.522401, Loss 0.169530, forward nfe 22572, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 078, Runtime 16.528719, Loss 0.192583, forward nfe 22868, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 079, Runtime 16.897749, Loss 0.230447, forward nfe 23164, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 080, Runtime 16.956261, Loss 0.200375, forward nfe 23460, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 081, Runtime 16.888250, Loss 0.122707, forward nfe 23756, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 082, Runtime 17.026843, Loss 0.208820, forward nfe 24052, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 083, Runtime 17.034780, Loss 0.152315, forward nfe 24348, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 084, Runtime 17.007185, Loss 0.191757, forward nfe 24644, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 085, Runtime 17.309113, Loss 0.151919, forward nfe 24940, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 086, Runtime 17.309456, Loss 0.236604, forward nfe 25236, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 087, Runtime 17.211483, Loss 0.177375, forward nfe 25532, backward nfe 0, Train: 0.9714, Val: 0.7801, Test: 0.7909, Best time: 18.2948
Epoch: 088, Runtime 17.619167, Loss 0.131500, forward nfe 25828, backward nfe 0, Train: 0.9571, Val: 0.7809, Test: 0.8213, Best time: 18.2948
Epoch: 089, Runtime 14.242985, Loss 0.236408, forward nfe 26124, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 090, Runtime 14.319723, Loss 0.150005, forward nfe 26420, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 091, Runtime 15.874480, Loss 0.159923, forward nfe 26716, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 092, Runtime 16.221869, Loss 0.204280, forward nfe 27012, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 093, Runtime 16.404427, Loss 0.133470, forward nfe 27308, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 094, Runtime 16.991940, Loss 0.224399, forward nfe 27604, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 095, Runtime 16.793838, Loss 0.145376, forward nfe 27900, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 096, Runtime 16.862013, Loss 0.131428, forward nfe 28196, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 097, Runtime 17.521564, Loss 0.146339, forward nfe 28492, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 098, Runtime 17.403959, Loss 0.206200, forward nfe 28788, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
Epoch: 099, Runtime 17.564276, Loss 0.161231, forward nfe 29084, backward nfe 0, Train: 0.9714, Val: 0.8125, Test: 0.8284, Best time: 18.2948
best val accuracy 0.812500 with test accuracy 0.828426 at epoch 89 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8345177664974619
Entropy Threshold: 2 Test accuracy: 0.833502538071066
Entropy Threshold: 1.6 Test accuracy: 0.8373983739837398
Entropy Threshold: 1.5 Test accuracy: 0.8336734693877551
Entropy Threshold: 1.4 Test accuracy: 0.8393039918116684
Entropy Threshold: 1.3 Test accuracy: 0.8398760330578512
Entropy Threshold: 1.2 Test accuracy: 0.8475289169295478
Entropy Threshold: 1.1 Test accuracy: 0.8522483940042827
Entropy Threshold: 0.9 Test accuracy: 0.8628318584070797
Entropy Threshold: 0.8 Test accuracy: 0.8745724059293044
Entropy Threshold: 0.7 Test accuracy: 0.8905882352941177
Entropy Threshold: 0.6 Test accuracy: 0.898034398034398
Entropy Threshold: 0.5 Test accuracy: 0.9016393442622951
Entropy Threshold: 0.4 Test accuracy: 0.9093264248704663
Entropy Threshold: 0.3 Test accuracy: 0.9129834254143646
Entropy Threshold: 0.2 Test accuracy: 0.9247467438494935
Entropy Threshold: 0.1 Test accuracy: 0.9351701782820098
