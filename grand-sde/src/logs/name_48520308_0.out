[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 8.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 33.490222, Loss 4.032269, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1551, Test: 0.1777, Best time: 18.2948
Epoch: 002, Runtime 43.500369, Loss 47.130302, forward nfe 372, backward nfe 0, Train: 0.1357, Val: 0.1566, Test: 0.1787, Best time: 48.0000
Epoch: 003, Runtime 21.935672, Loss 4.743970, forward nfe 668, backward nfe 0, Train: 0.1357, Val: 0.1566, Test: 0.1787, Best time: 18.2948
Epoch: 004, Runtime 22.144599, Loss 4.989677, forward nfe 964, backward nfe 0, Train: 0.1357, Val: 0.1566, Test: 0.1787, Best time: 18.2948
Epoch: 005, Runtime 22.478722, Loss 4.266547, forward nfe 1260, backward nfe 0, Train: 0.1357, Val: 0.1566, Test: 0.1787, Best time: 18.2948
Epoch: 006, Runtime 23.459770, Loss 4.134133, forward nfe 1556, backward nfe 0, Train: 0.1143, Val: 0.1993, Test: 0.1655, Best time: 1.0000
Epoch: 007, Runtime 21.952654, Loss 3.911896, forward nfe 1852, backward nfe 0, Train: 0.1214, Val: 0.2713, Test: 0.2162, Best time: 1.0000
Epoch: 008, Runtime 21.750401, Loss 3.611457, forward nfe 2148, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 1.0000
Epoch: 009, Runtime 22.322888, Loss 3.798715, forward nfe 2444, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 010, Runtime 23.226212, Loss 3.511650, forward nfe 2740, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 011, Runtime 23.385415, Loss 3.596973, forward nfe 3036, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 012, Runtime 23.348903, Loss 3.463899, forward nfe 3332, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 013, Runtime 23.703575, Loss 3.533430, forward nfe 3628, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 014, Runtime 24.938415, Loss 3.310522, forward nfe 3924, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 015, Runtime 25.408966, Loss 3.151694, forward nfe 4220, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 016, Runtime 26.080484, Loss 3.447680, forward nfe 4516, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 017, Runtime 27.167645, Loss 3.371210, forward nfe 4812, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 018, Runtime 26.960093, Loss 3.026147, forward nfe 5108, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 019, Runtime 26.932220, Loss 3.051527, forward nfe 5404, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 020, Runtime 27.267329, Loss 2.896011, forward nfe 5700, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 021, Runtime 27.633876, Loss 3.140039, forward nfe 5996, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 022, Runtime 27.794988, Loss 3.350216, forward nfe 6292, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 023, Runtime 28.068204, Loss 3.188816, forward nfe 6588, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 024, Runtime 28.778702, Loss 3.174553, forward nfe 6884, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 025, Runtime 28.682709, Loss 2.772601, forward nfe 7180, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 026, Runtime 29.063735, Loss 3.201262, forward nfe 7476, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 027, Runtime 29.696455, Loss 2.896629, forward nfe 7772, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 028, Runtime 28.926852, Loss 2.961966, forward nfe 8068, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 029, Runtime 29.604098, Loss 3.199766, forward nfe 8364, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 030, Runtime 28.805021, Loss 3.157401, forward nfe 8660, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 031, Runtime 29.315453, Loss 3.452086, forward nfe 8956, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 032, Runtime 19.888396, Loss 3.033075, forward nfe 9252, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 033, Runtime 18.676097, Loss 2.979069, forward nfe 9548, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 034, Runtime 19.125829, Loss 2.974028, forward nfe 9844, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 035, Runtime 19.922944, Loss 3.048260, forward nfe 10140, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 036, Runtime 20.158870, Loss 2.969633, forward nfe 10436, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 037, Runtime 20.350382, Loss 2.911304, forward nfe 10732, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 038, Runtime 20.862716, Loss 2.985950, forward nfe 11028, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 039, Runtime 21.865793, Loss 2.906672, forward nfe 11324, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 040, Runtime 21.549804, Loss 3.047761, forward nfe 11620, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 041, Runtime 22.040417, Loss 3.062892, forward nfe 11916, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 042, Runtime 22.401437, Loss 2.871997, forward nfe 12212, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 043, Runtime 23.424347, Loss 2.911007, forward nfe 12508, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 044, Runtime 23.177271, Loss 2.929369, forward nfe 12804, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 045, Runtime 23.504875, Loss 2.998862, forward nfe 13100, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 046, Runtime 23.865467, Loss 2.905262, forward nfe 13396, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 047, Runtime 24.714843, Loss 2.640765, forward nfe 13692, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 048, Runtime 24.672363, Loss 2.789316, forward nfe 13988, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 049, Runtime 25.489116, Loss 2.967350, forward nfe 14284, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 050, Runtime 25.298409, Loss 2.927831, forward nfe 14580, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 051, Runtime 25.593490, Loss 2.817660, forward nfe 14876, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 052, Runtime 26.072901, Loss 2.763622, forward nfe 15172, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 053, Runtime 26.633400, Loss 2.867054, forward nfe 15468, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 054, Runtime 26.222513, Loss 2.845963, forward nfe 15764, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 055, Runtime 26.293874, Loss 2.899167, forward nfe 16060, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 056, Runtime 26.858878, Loss 2.830103, forward nfe 16356, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 057, Runtime 27.075390, Loss 2.816583, forward nfe 16652, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 058, Runtime 27.097910, Loss 2.534914, forward nfe 16948, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 059, Runtime 27.660949, Loss 2.742713, forward nfe 17244, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 060, Runtime 27.203017, Loss 2.855696, forward nfe 17540, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 061, Runtime 27.964859, Loss 2.561056, forward nfe 17836, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 062, Runtime 27.831154, Loss 2.707842, forward nfe 18132, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 063, Runtime 28.193824, Loss 2.851505, forward nfe 18428, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 064, Runtime 27.881680, Loss 2.560377, forward nfe 18724, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 065, Runtime 27.847760, Loss 2.417475, forward nfe 19020, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 066, Runtime 28.746168, Loss 2.654457, forward nfe 19316, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 067, Runtime 18.848935, Loss 2.562733, forward nfe 19612, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 068, Runtime 18.567514, Loss 2.603553, forward nfe 19908, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 069, Runtime 18.210817, Loss 2.528674, forward nfe 20204, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 070, Runtime 19.581043, Loss 2.529825, forward nfe 20500, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 071, Runtime 20.042820, Loss 2.559081, forward nfe 20796, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 072, Runtime 20.438059, Loss 2.402549, forward nfe 21092, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 073, Runtime 21.060044, Loss 2.538016, forward nfe 21388, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 074, Runtime 21.621982, Loss 2.592246, forward nfe 21684, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 075, Runtime 22.251259, Loss 2.605648, forward nfe 21980, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 076, Runtime 22.933818, Loss 2.719941, forward nfe 22276, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 077, Runtime 23.110983, Loss 2.411584, forward nfe 22572, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 078, Runtime 23.568863, Loss 2.458430, forward nfe 22868, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 079, Runtime 24.040029, Loss 2.567770, forward nfe 23164, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 080, Runtime 23.540156, Loss 2.693549, forward nfe 23460, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 081, Runtime 23.079719, Loss 2.725679, forward nfe 23756, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 082, Runtime 23.983354, Loss 2.436334, forward nfe 24052, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 083, Runtime 24.220518, Loss 2.728294, forward nfe 24348, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 084, Runtime 24.532631, Loss 2.725998, forward nfe 24644, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 085, Runtime 24.635231, Loss 2.777332, forward nfe 24940, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 086, Runtime 25.064752, Loss 2.599070, forward nfe 25236, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 087, Runtime 25.191905, Loss 2.561122, forward nfe 25532, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 088, Runtime 25.571476, Loss 2.409281, forward nfe 25828, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 089, Runtime 25.531928, Loss 2.384823, forward nfe 26124, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 090, Runtime 25.982967, Loss 2.432491, forward nfe 26420, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 091, Runtime 26.095475, Loss 2.514901, forward nfe 26716, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 092, Runtime 26.206676, Loss 2.594080, forward nfe 27012, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 093, Runtime 26.530078, Loss 2.546894, forward nfe 27308, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 094, Runtime 26.919677, Loss 2.339223, forward nfe 27604, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 095, Runtime 26.434901, Loss 2.392426, forward nfe 27900, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 096, Runtime 26.974015, Loss 2.446228, forward nfe 28196, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 097, Runtime 27.266397, Loss 2.436012, forward nfe 28492, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 098, Runtime 27.284938, Loss 2.501762, forward nfe 28788, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
Epoch: 099, Runtime 27.793143, Loss 2.577242, forward nfe 29084, backward nfe 0, Train: 0.1143, Val: 0.2912, Test: 0.2365, Best time: 18.2948
best val accuracy 0.291176 with test accuracy 0.236548 at epoch 8 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1401015228426396
Entropy Threshold: 2 Test accuracy: 0.14923857868020304
Entropy Threshold: 1.6 Test accuracy: 0.1425661914460285
Entropy Threshold: 1.5 Test accuracy: 0.13201663201663202
Entropy Threshold: 1.4 Test accuracy: 0.14675767918088736
Entropy Threshold: 1.3 Test accuracy: 0.13259668508287292
Entropy Threshold: 1.2 Test accuracy: 0.12410071942446044
Entropy Threshold: 1.1 Test accuracy: 0.12398921832884097
Entropy Threshold: 0.9 Test accuracy: 0.10526315789473684
Entropy Threshold: 0.8 Test accuracy: 0.125
Entropy Threshold: 0.7 Test accuracy: 0.07407407407407407
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: None
