[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 3.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 18.921345, Loss 2.679715, forward nfe 76, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 1.0000
Epoch: 002, Runtime 29.791638, Loss 7.304835, forward nfe 372, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 003, Runtime 16.694431, Loss 2.926080, forward nfe 668, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 004, Runtime 16.261077, Loss 2.909977, forward nfe 964, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 005, Runtime 17.401640, Loss 3.012873, forward nfe 1260, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 006, Runtime 19.144907, Loss 2.856853, forward nfe 1556, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 007, Runtime 20.715904, Loss 2.878963, forward nfe 1852, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 008, Runtime 21.875726, Loss 2.683486, forward nfe 2148, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 009, Runtime 22.499477, Loss 2.659111, forward nfe 2444, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 010, Runtime 22.155997, Loss 2.709830, forward nfe 2740, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 011, Runtime 22.284926, Loss 2.557354, forward nfe 3036, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 012, Runtime 22.225502, Loss 2.637809, forward nfe 3332, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 013, Runtime 22.212862, Loss 2.585863, forward nfe 3628, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 014, Runtime 21.931786, Loss 2.645209, forward nfe 3924, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 015, Runtime 22.358203, Loss 2.387457, forward nfe 4220, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 016, Runtime 23.044713, Loss 2.574354, forward nfe 4516, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 017, Runtime 23.405525, Loss 2.449852, forward nfe 4812, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 018, Runtime 23.168929, Loss 2.461866, forward nfe 5108, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 019, Runtime 23.433118, Loss 2.531555, forward nfe 5404, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 020, Runtime 23.491683, Loss 2.381568, forward nfe 5700, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 021, Runtime 23.571860, Loss 2.355357, forward nfe 5996, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 022, Runtime 23.534509, Loss 2.395813, forward nfe 6292, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 023, Runtime 23.720463, Loss 2.431229, forward nfe 6588, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 024, Runtime 23.443094, Loss 2.397900, forward nfe 6884, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 025, Runtime 23.392590, Loss 2.457331, forward nfe 7180, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 026, Runtime 23.287112, Loss 2.279064, forward nfe 7476, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 027, Runtime 23.105865, Loss 2.292601, forward nfe 7772, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 028, Runtime 23.439198, Loss 2.345504, forward nfe 8068, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 029, Runtime 21.755524, Loss 2.333435, forward nfe 8364, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 030, Runtime 21.477267, Loss 2.355194, forward nfe 8660, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 031, Runtime 21.810791, Loss 2.291593, forward nfe 8956, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 032, Runtime 21.855367, Loss 2.372965, forward nfe 9252, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 033, Runtime 21.958856, Loss 2.344054, forward nfe 9548, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 034, Runtime 22.051758, Loss 2.245435, forward nfe 9844, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 035, Runtime 22.076693, Loss 2.346186, forward nfe 10140, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 036, Runtime 22.582875, Loss 2.115659, forward nfe 10436, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 037, Runtime 21.809227, Loss 2.271316, forward nfe 10732, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 038, Runtime 22.429233, Loss 2.305418, forward nfe 11028, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 039, Runtime 22.305775, Loss 2.209413, forward nfe 11324, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 040, Runtime 22.631616, Loss 2.203347, forward nfe 11620, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 041, Runtime 22.416619, Loss 2.222215, forward nfe 11916, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 042, Runtime 18.905943, Loss 2.320814, forward nfe 12212, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 043, Runtime 15.145363, Loss 2.200655, forward nfe 12508, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 044, Runtime 15.075521, Loss 2.157317, forward nfe 12804, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 045, Runtime 15.257621, Loss 2.194913, forward nfe 13100, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 046, Runtime 15.597529, Loss 2.241166, forward nfe 13396, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 047, Runtime 17.231159, Loss 2.134472, forward nfe 13692, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 048, Runtime 17.918058, Loss 2.185615, forward nfe 13988, backward nfe 0, Train: 0.4000, Val: 0.2625, Test: 0.2822, Best time: 18.2948
Epoch: 049, Runtime 18.585739, Loss 2.142311, forward nfe 14284, backward nfe 0, Train: 0.3643, Val: 0.2669, Test: 0.2599, Best time: 1.0000
Epoch: 050, Runtime 16.230953, Loss 2.083899, forward nfe 14580, backward nfe 0, Train: 0.3714, Val: 0.2743, Test: 0.2680, Best time: 2.0000
Epoch: 051, Runtime 16.284292, Loss 2.171212, forward nfe 14876, backward nfe 0, Train: 0.3786, Val: 0.2816, Test: 0.2812, Best time: 2.0000
Epoch: 052, Runtime 16.031872, Loss 2.164626, forward nfe 15172, backward nfe 0, Train: 0.4000, Val: 0.2868, Test: 0.2904, Best time: 1.0000
Epoch: 053, Runtime 16.112842, Loss 2.097668, forward nfe 15468, backward nfe 0, Train: 0.4286, Val: 0.2941, Test: 0.3036, Best time: 1.0000
Epoch: 054, Runtime 16.152080, Loss 2.203652, forward nfe 15764, backward nfe 0, Train: 0.4286, Val: 0.2971, Test: 0.3107, Best time: 1.0000
Epoch: 055, Runtime 16.083039, Loss 2.184354, forward nfe 16060, backward nfe 0, Train: 0.4214, Val: 0.3037, Test: 0.3218, Best time: 1.0000
Epoch: 056, Runtime 16.020086, Loss 2.088243, forward nfe 16356, backward nfe 0, Train: 0.4357, Val: 0.3118, Test: 0.3360, Best time: 3.0000
Epoch: 057, Runtime 16.087246, Loss 2.166479, forward nfe 16652, backward nfe 0, Train: 0.4500, Val: 0.3228, Test: 0.3401, Best time: 2.0000
Epoch: 058, Runtime 16.100151, Loss 2.128481, forward nfe 16948, backward nfe 0, Train: 0.4643, Val: 0.3287, Test: 0.3563, Best time: 7.0000
Epoch: 059, Runtime 15.978010, Loss 2.116359, forward nfe 17244, backward nfe 0, Train: 0.4643, Val: 0.3375, Test: 0.3604, Best time: 6.0000
Epoch: 060, Runtime 16.131848, Loss 2.121457, forward nfe 17540, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 8.0000
Epoch: 061, Runtime 15.951400, Loss 2.118519, forward nfe 17836, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 062, Runtime 16.023590, Loss 2.040053, forward nfe 18132, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 063, Runtime 16.719060, Loss 2.033182, forward nfe 18428, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 064, Runtime 17.005157, Loss 2.143296, forward nfe 18724, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 065, Runtime 17.399952, Loss 2.115203, forward nfe 19020, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 066, Runtime 17.563246, Loss 2.069544, forward nfe 19316, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 067, Runtime 17.910205, Loss 2.168448, forward nfe 19612, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 068, Runtime 18.241377, Loss 2.208547, forward nfe 19908, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 069, Runtime 18.471573, Loss 2.060757, forward nfe 20204, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 070, Runtime 18.728489, Loss 2.096989, forward nfe 20500, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 071, Runtime 19.079977, Loss 2.155666, forward nfe 20796, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 072, Runtime 19.446272, Loss 2.131663, forward nfe 21092, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 073, Runtime 20.020122, Loss 2.117998, forward nfe 21388, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 074, Runtime 20.388069, Loss 2.024990, forward nfe 21684, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 075, Runtime 20.582621, Loss 2.165647, forward nfe 21980, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 076, Runtime 20.894392, Loss 2.135253, forward nfe 22276, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 077, Runtime 21.237424, Loss 2.094633, forward nfe 22572, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 078, Runtime 21.211325, Loss 2.178728, forward nfe 22868, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 079, Runtime 21.376583, Loss 2.121403, forward nfe 23164, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 080, Runtime 22.155720, Loss 2.026407, forward nfe 23460, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 081, Runtime 21.133241, Loss 2.201279, forward nfe 23756, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 082, Runtime 20.667143, Loss 2.174194, forward nfe 24052, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 083, Runtime 20.866757, Loss 2.097044, forward nfe 24348, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 084, Runtime 21.008980, Loss 2.049540, forward nfe 24644, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 085, Runtime 21.252719, Loss 2.086463, forward nfe 24940, backward nfe 0, Train: 0.4643, Val: 0.3412, Test: 0.3655, Best time: 18.2948
Epoch: 086, Runtime 21.450612, Loss 1.982227, forward nfe 25236, backward nfe 0, Train: 0.4214, Val: 0.3426, Test: 0.3716, Best time: 1.0000
Epoch: 087, Runtime 15.104145, Loss 2.034171, forward nfe 25532, backward nfe 0, Train: 0.4214, Val: 0.3478, Test: 0.3706, Best time: 1.0000
Epoch: 088, Runtime 14.924109, Loss 2.025725, forward nfe 25828, backward nfe 0, Train: 0.4214, Val: 0.3485, Test: 0.3746, Best time: 1.0000
Epoch: 089, Runtime 14.961192, Loss 2.104487, forward nfe 26124, backward nfe 0, Train: 0.4286, Val: 0.3507, Test: 0.3736, Best time: 1.0000
Epoch: 090, Runtime 14.994926, Loss 2.185207, forward nfe 26420, backward nfe 0, Train: 0.4286, Val: 0.3515, Test: 0.3756, Best time: 1.0000
Epoch: 091, Runtime 14.773634, Loss 2.069683, forward nfe 26716, backward nfe 0, Train: 0.4286, Val: 0.3515, Test: 0.3756, Best time: 18.2948
Epoch: 092, Runtime 15.326453, Loss 2.077160, forward nfe 27012, backward nfe 0, Train: 0.4286, Val: 0.3515, Test: 0.3756, Best time: 18.2948
Epoch: 093, Runtime 15.707030, Loss 2.091396, forward nfe 27308, backward nfe 0, Train: 0.4286, Val: 0.3515, Test: 0.3756, Best time: 18.2948
Epoch: 094, Runtime 15.906301, Loss 1.934910, forward nfe 27604, backward nfe 0, Train: 0.4286, Val: 0.3515, Test: 0.3756, Best time: 18.2948
Epoch: 095, Runtime 16.535709, Loss 1.984608, forward nfe 27900, backward nfe 0, Train: 0.4357, Val: 0.3559, Test: 0.3777, Best time: 1.0000
Epoch: 096, Runtime 15.270336, Loss 2.071134, forward nfe 28196, backward nfe 0, Train: 0.4429, Val: 0.3581, Test: 0.3797, Best time: 1.0000
Epoch: 097, Runtime 15.194731, Loss 2.111372, forward nfe 28492, backward nfe 0, Train: 0.4429, Val: 0.3588, Test: 0.3797, Best time: 1.0000
Epoch: 098, Runtime 15.146475, Loss 2.065618, forward nfe 28788, backward nfe 0, Train: 0.4429, Val: 0.3588, Test: 0.3797, Best time: 18.2948
Epoch: 099, Runtime 15.228562, Loss 2.080743, forward nfe 29084, backward nfe 0, Train: 0.4429, Val: 0.3588, Test: 0.3797, Best time: 18.2948
best val accuracy 0.358824 with test accuracy 0.379695 at epoch 97 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.16040609137055836
Entropy Threshold: 2 Test accuracy: 0.12588832487309645
Entropy Threshold: 1.6 Test accuracy: None
Entropy Threshold: 1.5 Test accuracy: None
Entropy Threshold: 1.4 Test accuracy: None
Entropy Threshold: 1.3 Test accuracy: None
Entropy Threshold: 1.2 Test accuracy: None
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
