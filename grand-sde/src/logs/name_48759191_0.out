[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.6
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 8.888941, Loss 2.118796, forward nfe 76, backward nfe 0, Train: 0.2429, Val: 0.1904, Test: 0.1838, Best time: 1.0000
Epoch: 002, Runtime 8.170879, Loss 2.472487, forward nfe 372, backward nfe 0, Train: 0.4071, Val: 0.3515, Test: 0.3289, Best time: 1.0000
Epoch: 003, Runtime 7.979429, Loss 1.949567, forward nfe 668, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 5.0000
Epoch: 004, Runtime 7.832765, Loss 2.010299, forward nfe 964, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 005, Runtime 8.569772, Loss 1.890603, forward nfe 1260, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 006, Runtime 8.354030, Loss 1.885910, forward nfe 1556, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 007, Runtime 8.164515, Loss 1.767335, forward nfe 1852, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 008, Runtime 9.524933, Loss 1.861134, forward nfe 2148, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 009, Runtime 9.905198, Loss 1.780650, forward nfe 2444, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 010, Runtime 9.364920, Loss 1.700599, forward nfe 2740, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 011, Runtime 9.338547, Loss 1.585206, forward nfe 3036, backward nfe 0, Train: 0.4857, Val: 0.3993, Test: 0.3959, Best time: 18.2948
Epoch: 012, Runtime 9.763995, Loss 1.478876, forward nfe 3332, backward nfe 0, Train: 0.5000, Val: 0.4096, Test: 0.4629, Best time: 18.2948
Epoch: 013, Runtime 8.674731, Loss 1.344579, forward nfe 3628, backward nfe 0, Train: 0.5571, Val: 0.4485, Test: 0.4660, Best time: 18.2948
Epoch: 014, Runtime 8.688797, Loss 1.374558, forward nfe 3924, backward nfe 0, Train: 0.5000, Val: 0.4787, Test: 0.5096, Best time: 18.2948
Epoch: 015, Runtime 8.691751, Loss 1.223784, forward nfe 4220, backward nfe 0, Train: 0.6643, Val: 0.5537, Test: 0.5584, Best time: 18.2948
Epoch: 016, Runtime 8.606052, Loss 1.108060, forward nfe 4516, backward nfe 0, Train: 0.6714, Val: 0.6118, Test: 0.6264, Best time: 18.2948
Epoch: 017, Runtime 8.623307, Loss 1.068909, forward nfe 4812, backward nfe 0, Train: 0.7357, Val: 0.6471, Test: 0.6721, Best time: 18.2948
Epoch: 018, Runtime 8.594992, Loss 0.905530, forward nfe 5108, backward nfe 0, Train: 0.7786, Val: 0.6765, Test: 0.6822, Best time: 18.2948
Epoch: 019, Runtime 8.638748, Loss 0.917419, forward nfe 5404, backward nfe 0, Train: 0.7714, Val: 0.6971, Test: 0.7198, Best time: 18.2948
Epoch: 020, Runtime 8.635286, Loss 0.796075, forward nfe 5700, backward nfe 0, Train: 0.8214, Val: 0.7154, Test: 0.7127, Best time: 18.2948
Epoch: 021, Runtime 8.454694, Loss 0.706239, forward nfe 5996, backward nfe 0, Train: 0.8214, Val: 0.7154, Test: 0.7127, Best time: 18.2948
Epoch: 022, Runtime 8.743117, Loss 0.702904, forward nfe 6292, backward nfe 0, Train: 0.8214, Val: 0.7154, Test: 0.7127, Best time: 18.2948
Epoch: 023, Runtime 8.897228, Loss 0.728771, forward nfe 6588, backward nfe 0, Train: 0.8786, Val: 0.7272, Test: 0.7391, Best time: 18.2948
Epoch: 024, Runtime 8.728964, Loss 0.643032, forward nfe 6884, backward nfe 0, Train: 0.8786, Val: 0.7272, Test: 0.7391, Best time: 18.2948
Epoch: 025, Runtime 9.356063, Loss 0.612711, forward nfe 7180, backward nfe 0, Train: 0.8714, Val: 0.7353, Test: 0.7563, Best time: 18.2948
Epoch: 026, Runtime 9.320533, Loss 0.580097, forward nfe 7476, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 027, Runtime 8.917390, Loss 0.572502, forward nfe 7772, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 028, Runtime 9.195646, Loss 0.627227, forward nfe 8068, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 029, Runtime 9.138450, Loss 0.539665, forward nfe 8364, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 030, Runtime 9.171457, Loss 0.502220, forward nfe 8660, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 031, Runtime 9.476808, Loss 0.586319, forward nfe 8956, backward nfe 0, Train: 0.9000, Val: 0.7485, Test: 0.7543, Best time: 18.2948
Epoch: 032, Runtime 9.626967, Loss 0.527034, forward nfe 9252, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 033, Runtime 8.842059, Loss 0.541048, forward nfe 9548, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 034, Runtime 9.247964, Loss 0.490987, forward nfe 9844, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 035, Runtime 9.163197, Loss 0.497942, forward nfe 10140, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 036, Runtime 9.182771, Loss 0.441646, forward nfe 10436, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 037, Runtime 9.489762, Loss 0.553308, forward nfe 10732, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 038, Runtime 9.413686, Loss 0.488169, forward nfe 11028, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 039, Runtime 9.534811, Loss 0.458573, forward nfe 11324, backward nfe 0, Train: 0.9214, Val: 0.7640, Test: 0.7614, Best time: 18.2948
Epoch: 040, Runtime 10.001849, Loss 0.442428, forward nfe 11620, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 041, Runtime 8.848634, Loss 0.524918, forward nfe 11916, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 042, Runtime 9.189332, Loss 0.448387, forward nfe 12212, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 043, Runtime 9.180950, Loss 0.457527, forward nfe 12508, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 044, Runtime 9.254937, Loss 0.430096, forward nfe 12804, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 045, Runtime 9.562323, Loss 0.382479, forward nfe 13100, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 046, Runtime 9.543513, Loss 0.426212, forward nfe 13396, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 047, Runtime 9.537433, Loss 0.355827, forward nfe 13692, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 048, Runtime 9.907030, Loss 0.356962, forward nfe 13988, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 049, Runtime 9.839009, Loss 0.399773, forward nfe 14284, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 050, Runtime 9.874919, Loss 0.368382, forward nfe 14580, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 051, Runtime 10.181313, Loss 0.312441, forward nfe 14876, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 052, Runtime 10.152834, Loss 0.433557, forward nfe 15172, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 053, Runtime 10.224792, Loss 0.408308, forward nfe 15468, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 054, Runtime 10.480140, Loss 0.393437, forward nfe 15764, backward nfe 0, Train: 0.8857, Val: 0.7757, Test: 0.7716, Best time: 18.2948
Epoch: 055, Runtime 10.578620, Loss 0.292377, forward nfe 16060, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7706, Best time: 18.2948
Epoch: 056, Runtime 9.131671, Loss 0.328508, forward nfe 16356, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 057, Runtime 8.885985, Loss 0.344236, forward nfe 16652, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 058, Runtime 9.212829, Loss 0.371626, forward nfe 16948, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 059, Runtime 9.194186, Loss 0.381383, forward nfe 17244, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 060, Runtime 9.195099, Loss 0.338066, forward nfe 17540, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 061, Runtime 9.589272, Loss 0.290578, forward nfe 17836, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 062, Runtime 9.494125, Loss 0.270508, forward nfe 18132, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 063, Runtime 9.527599, Loss 0.264115, forward nfe 18428, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 064, Runtime 9.835884, Loss 0.352478, forward nfe 18724, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 065, Runtime 9.763792, Loss 0.289164, forward nfe 19020, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 066, Runtime 9.890266, Loss 0.294262, forward nfe 19316, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 067, Runtime 10.135100, Loss 0.280549, forward nfe 19612, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 068, Runtime 10.190283, Loss 0.274288, forward nfe 19908, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 069, Runtime 10.128326, Loss 0.343271, forward nfe 20204, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 070, Runtime 10.334985, Loss 0.332554, forward nfe 20500, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 071, Runtime 10.333963, Loss 0.274379, forward nfe 20796, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 072, Runtime 10.395515, Loss 0.266416, forward nfe 21092, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 073, Runtime 10.467997, Loss 0.342339, forward nfe 21388, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 074, Runtime 10.438511, Loss 0.302654, forward nfe 21684, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 075, Runtime 10.427328, Loss 0.339599, forward nfe 21980, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 076, Runtime 10.598637, Loss 0.256732, forward nfe 22276, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 077, Runtime 10.654966, Loss 0.279515, forward nfe 22572, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 078, Runtime 10.300296, Loss 0.270707, forward nfe 22868, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 079, Runtime 10.513409, Loss 0.288972, forward nfe 23164, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 080, Runtime 10.536656, Loss 0.315791, forward nfe 23460, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 081, Runtime 10.543142, Loss 0.308182, forward nfe 23756, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 082, Runtime 10.194932, Loss 0.294708, forward nfe 24052, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 083, Runtime 10.059085, Loss 0.274885, forward nfe 24348, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 084, Runtime 10.168254, Loss 0.342119, forward nfe 24644, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 085, Runtime 10.276137, Loss 0.248254, forward nfe 24940, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 086, Runtime 10.159423, Loss 0.364102, forward nfe 25236, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 087, Runtime 10.096077, Loss 0.208649, forward nfe 25532, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 088, Runtime 10.183889, Loss 0.207287, forward nfe 25828, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 089, Runtime 10.379996, Loss 0.326585, forward nfe 26124, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 090, Runtime 10.292572, Loss 0.218735, forward nfe 26420, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 091, Runtime 10.381082, Loss 0.219529, forward nfe 26716, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 092, Runtime 10.371497, Loss 0.244599, forward nfe 27012, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 093, Runtime 10.289909, Loss 0.250445, forward nfe 27308, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 094, Runtime 10.469560, Loss 0.265368, forward nfe 27604, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 095, Runtime 10.447516, Loss 0.258228, forward nfe 27900, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 096, Runtime 10.297085, Loss 0.235374, forward nfe 28196, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 097, Runtime 10.545081, Loss 0.213615, forward nfe 28492, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 098, Runtime 10.504718, Loss 0.193934, forward nfe 28788, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
Epoch: 099, Runtime 10.414406, Loss 0.192540, forward nfe 29084, backward nfe 0, Train: 0.9429, Val: 0.7846, Test: 0.7533, Best time: 18.2948
best val accuracy 0.784559 with test accuracy 0.753299 at epoch 56 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8050761421319796
Entropy Threshold: 2 Test accuracy: 0.8030456852791878
Entropy Threshold: 1.6 Test accuracy: 0.8036998972250771
Entropy Threshold: 1.5 Test accuracy: 0.8128898128898129
Entropy Threshold: 1.4 Test accuracy: 0.8117770767613038
Entropy Threshold: 1.3 Test accuracy: 0.8223896663078579
Entropy Threshold: 1.2 Test accuracy: 0.834070796460177
Entropy Threshold: 1.1 Test accuracy: 0.8371040723981901
Entropy Threshold: 0.9 Test accuracy: 0.8522167487684729
Entropy Threshold: 0.8 Test accuracy: 0.8707571801566579
Entropy Threshold: 0.7 Test accuracy: 0.8831710709318498
Entropy Threshold: 0.6 Test accuracy: 0.8924889543446245
Entropy Threshold: 0.5 Test accuracy: 0.910828025477707
Entropy Threshold: 0.4 Test accuracy: 0.910958904109589
Entropy Threshold: 0.3 Test accuracy: 0.9191176470588235
Entropy Threshold: 0.2 Test accuracy: 0.9298969072164949
Entropy Threshold: 0.1 Test accuracy: 0.9292929292929293
