[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.896178, Loss 2.173520, forward nfe 76, backward nfe 0, Train: 0.2571, Val: 0.3860, Test: 0.3675, Best time: 1.0000
Epoch: 002, Runtime 16.978919, Loss 2.429746, forward nfe 372, backward nfe 0, Train: 0.5643, Val: 0.4890, Test: 0.4843, Best time: 1.0000
Epoch: 003, Runtime 13.333897, Loss 2.088407, forward nfe 668, backward nfe 0, Train: 0.5643, Val: 0.4890, Test: 0.4843, Best time: 18.2948
Epoch: 004, Runtime 12.958824, Loss 2.043510, forward nfe 964, backward nfe 0, Train: 0.5500, Val: 0.5375, Test: 0.5299, Best time: 3.0000
Epoch: 005, Runtime 12.470576, Loss 2.189194, forward nfe 1260, backward nfe 0, Train: 0.6214, Val: 0.6228, Test: 0.6203, Best time: 2.0000
Epoch: 006, Runtime 14.075069, Loss 2.147062, forward nfe 1556, backward nfe 0, Train: 0.6214, Val: 0.6228, Test: 0.6203, Best time: 18.2948
Epoch: 007, Runtime 15.095266, Loss 1.950748, forward nfe 1852, backward nfe 0, Train: 0.6214, Val: 0.6228, Test: 0.6203, Best time: 18.2948
Epoch: 008, Runtime 14.484653, Loss 1.929348, forward nfe 2148, backward nfe 0, Train: 0.6214, Val: 0.6228, Test: 0.6203, Best time: 18.2948
Epoch: 009, Runtime 14.805544, Loss 1.894063, forward nfe 2444, backward nfe 0, Train: 0.6786, Val: 0.6529, Test: 0.6274, Best time: 4.0000
Epoch: 010, Runtime 13.951809, Loss 1.751359, forward nfe 2740, backward nfe 0, Train: 0.6929, Val: 0.7257, Test: 0.7076, Best time: 10.0000
Epoch: 011, Runtime 13.887457, Loss 1.613459, forward nfe 3036, backward nfe 0, Train: 0.7143, Val: 0.7750, Test: 0.7472, Best time: 27.0000
Epoch: 012, Runtime 13.903006, Loss 1.489217, forward nfe 3332, backward nfe 0, Train: 0.8286, Val: 0.8044, Test: 0.8030, Best time: 12.0000
Epoch: 013, Runtime 13.912321, Loss 1.315737, forward nfe 3628, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 11.0000
Epoch: 014, Runtime 13.836089, Loss 1.121918, forward nfe 3924, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 015, Runtime 14.252139, Loss 1.181787, forward nfe 4220, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 016, Runtime 14.177073, Loss 0.944834, forward nfe 4516, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 017, Runtime 14.320244, Loss 0.828056, forward nfe 4812, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 018, Runtime 14.779066, Loss 0.750931, forward nfe 5108, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 019, Runtime 14.905769, Loss 0.766318, forward nfe 5404, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 020, Runtime 14.751303, Loss 0.675026, forward nfe 5700, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 021, Runtime 15.132137, Loss 0.617596, forward nfe 5996, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 022, Runtime 14.585583, Loss 0.664798, forward nfe 6292, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 023, Runtime 15.146170, Loss 0.514772, forward nfe 6588, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 024, Runtime 15.180040, Loss 0.616960, forward nfe 6884, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 025, Runtime 14.718145, Loss 0.513347, forward nfe 7180, backward nfe 0, Train: 0.8786, Val: 0.8162, Test: 0.8152, Best time: 18.2948
Epoch: 026, Runtime 14.384714, Loss 0.475454, forward nfe 7476, backward nfe 0, Train: 0.9500, Val: 0.8199, Test: 0.8203, Best time: 23.0000
Epoch: 027, Runtime 12.643362, Loss 0.502172, forward nfe 7772, backward nfe 0, Train: 0.9500, Val: 0.8250, Test: 0.8254, Best time: 26.0000
Epoch: 028, Runtime 12.556156, Loss 0.534689, forward nfe 8068, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8294, Best time: 27.0000
Epoch: 029, Runtime 12.315413, Loss 0.498182, forward nfe 8364, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8294, Best time: 18.2948
Epoch: 030, Runtime 12.851582, Loss 0.501954, forward nfe 8660, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8294, Best time: 18.2948
Epoch: 031, Runtime 12.861254, Loss 0.508226, forward nfe 8956, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8294, Best time: 18.2948
Epoch: 032, Runtime 12.774113, Loss 0.496631, forward nfe 9252, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8294, Best time: 18.2948
Epoch: 033, Runtime 13.305346, Loss 0.461605, forward nfe 9548, backward nfe 0, Train: 0.9857, Val: 0.8316, Test: 0.8142, Best time: 24.0000
Epoch: 034, Runtime 12.843604, Loss 0.455613, forward nfe 9844, backward nfe 0, Train: 0.9714, Val: 0.8324, Test: 0.8305, Best time: 43.0000
Epoch: 035, Runtime 13.061474, Loss 0.417913, forward nfe 10140, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 54.0000
Epoch: 036, Runtime 12.976196, Loss 0.419656, forward nfe 10436, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 037, Runtime 13.344147, Loss 0.286454, forward nfe 10732, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 038, Runtime 12.679819, Loss 0.390826, forward nfe 11028, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 039, Runtime 12.773848, Loss 0.429073, forward nfe 11324, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 040, Runtime 13.306775, Loss 0.309822, forward nfe 11620, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 041, Runtime 13.157962, Loss 0.292993, forward nfe 11916, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 042, Runtime 13.207576, Loss 0.441288, forward nfe 12212, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 043, Runtime 13.081670, Loss 0.360745, forward nfe 12508, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 044, Runtime 12.916591, Loss 0.374813, forward nfe 12804, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 045, Runtime 12.960357, Loss 0.282707, forward nfe 13100, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 046, Runtime 13.374327, Loss 0.322442, forward nfe 13396, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 047, Runtime 13.378399, Loss 0.310923, forward nfe 13692, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 048, Runtime 13.634236, Loss 0.393432, forward nfe 13988, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 049, Runtime 13.779805, Loss 0.382040, forward nfe 14284, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 050, Runtime 13.743486, Loss 0.343603, forward nfe 14580, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 051, Runtime 13.832919, Loss 0.287676, forward nfe 14876, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 052, Runtime 14.214440, Loss 0.354480, forward nfe 15172, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 053, Runtime 14.048041, Loss 0.229698, forward nfe 15468, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 054, Runtime 14.183938, Loss 0.276902, forward nfe 15764, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 055, Runtime 14.341186, Loss 0.179697, forward nfe 16060, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 056, Runtime 14.236004, Loss 0.321160, forward nfe 16356, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 057, Runtime 14.287165, Loss 0.266128, forward nfe 16652, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 058, Runtime 14.250346, Loss 0.285301, forward nfe 16948, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 059, Runtime 14.170785, Loss 0.292080, forward nfe 17244, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 060, Runtime 14.294366, Loss 0.248419, forward nfe 17540, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 061, Runtime 14.969849, Loss 0.302575, forward nfe 17836, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 062, Runtime 14.897585, Loss 0.265781, forward nfe 18132, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 063, Runtime 14.627315, Loss 0.255124, forward nfe 18428, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 064, Runtime 14.500077, Loss 0.317073, forward nfe 18724, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 065, Runtime 14.381608, Loss 0.254519, forward nfe 19020, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 066, Runtime 14.503722, Loss 0.157223, forward nfe 19316, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 067, Runtime 14.518300, Loss 0.197989, forward nfe 19612, backward nfe 0, Train: 0.9714, Val: 0.8346, Test: 0.8325, Best time: 18.2948
Epoch: 068, Runtime 14.585770, Loss 0.152065, forward nfe 19908, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 54.8843
Epoch: 069, Runtime 11.428011, Loss 0.246538, forward nfe 20204, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 070, Runtime 11.722470, Loss 0.244623, forward nfe 20500, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 071, Runtime 11.702119, Loss 0.254568, forward nfe 20796, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 072, Runtime 11.808316, Loss 0.176460, forward nfe 21092, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 073, Runtime 12.252996, Loss 0.214805, forward nfe 21388, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 074, Runtime 12.086957, Loss 0.247069, forward nfe 21684, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 075, Runtime 12.140496, Loss 0.172037, forward nfe 21980, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 076, Runtime 12.622013, Loss 0.143895, forward nfe 22276, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 077, Runtime 12.426536, Loss 0.218860, forward nfe 22572, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 078, Runtime 12.632803, Loss 0.230808, forward nfe 22868, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 079, Runtime 12.922838, Loss 0.207610, forward nfe 23164, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 080, Runtime 16.756527, Loss 0.250508, forward nfe 23460, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 081, Runtime 18.363887, Loss 0.269663, forward nfe 23756, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 082, Runtime 18.740978, Loss 0.173587, forward nfe 24052, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 083, Runtime 18.603670, Loss 0.186955, forward nfe 24348, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 084, Runtime 18.535374, Loss 0.233326, forward nfe 24644, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 085, Runtime 17.034028, Loss 0.231846, forward nfe 24940, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 086, Runtime 16.205189, Loss 0.234198, forward nfe 25236, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 087, Runtime 16.246581, Loss 0.165794, forward nfe 25532, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 088, Runtime 16.465194, Loss 0.220700, forward nfe 25828, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 089, Runtime 16.383378, Loss 0.188516, forward nfe 26124, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 090, Runtime 16.457921, Loss 0.168457, forward nfe 26420, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 091, Runtime 16.692015, Loss 0.147323, forward nfe 26716, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 092, Runtime 16.560853, Loss 0.270312, forward nfe 27012, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 093, Runtime 16.933500, Loss 0.228242, forward nfe 27308, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 094, Runtime 18.605184, Loss 0.113711, forward nfe 27604, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 095, Runtime 20.214973, Loss 0.195441, forward nfe 27900, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 096, Runtime 20.390867, Loss 0.248082, forward nfe 28196, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 097, Runtime 20.895983, Loss 0.219812, forward nfe 28492, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 098, Runtime 21.565381, Loss 0.178173, forward nfe 28788, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
Epoch: 099, Runtime 21.466803, Loss 0.191809, forward nfe 29084, backward nfe 0, Train: 0.9857, Val: 0.8382, Test: 0.8335, Best time: 18.2948
best val accuracy 0.838235 with test accuracy 0.833503 at epoch 68 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8203045685279188
Entropy Threshold: 2 Test accuracy: 0.8223350253807107
Entropy Threshold: 1.6 Test accuracy: 0.8247422680412371
Entropy Threshold: 1.5 Test accuracy: 0.8286604361370716
Entropy Threshold: 1.4 Test accuracy: 0.834920634920635
Entropy Threshold: 1.3 Test accuracy: 0.8365800865800865
Entropy Threshold: 1.2 Test accuracy: 0.8385300668151447
Entropy Threshold: 1.1 Test accuracy: 0.8507972665148064
Entropy Threshold: 0.9 Test accuracy: 0.8648648648648649
Entropy Threshold: 0.8 Test accuracy: 0.8775773195876289
Entropy Threshold: 0.7 Test accuracy: 0.8935879945429741
Entropy Threshold: 0.6 Test accuracy: 0.9035971223021583
Entropy Threshold: 0.5 Test accuracy: 0.9125766871165644
Entropy Threshold: 0.4 Test accuracy: 0.9088
Entropy Threshold: 0.3 Test accuracy: 0.9200680272108843
Entropy Threshold: 0.2 Test accuracy: 0.9166666666666666
Entropy Threshold: 0.1 Test accuracy: 0.9307359307359307
