[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 8.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 33.882832, Loss 6.146701, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 002, Runtime 79.891322, Loss 68.097572, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 003, Runtime 28.895777, Loss 4.765926, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 004, Runtime 29.356086, Loss 5.443177, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 005, Runtime 28.999775, Loss 5.604753, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 006, Runtime 31.045273, Loss 5.829760, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.1537, Test: 0.1523, Best time: 18.2948
Epoch: 007, Runtime 33.839983, Loss 5.932152, forward nfe 1852, backward nfe 0, Train: 0.1714, Val: 0.2647, Test: 0.2548, Best time: 54.8843
Epoch: 008, Runtime 29.817975, Loss 5.738187, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.3022, Test: 0.2782, Best time: 52.0000
Epoch: 009, Runtime 30.271658, Loss 5.375166, forward nfe 2444, backward nfe 0, Train: 0.1571, Val: 0.3066, Test: 0.2812, Best time: 46.0000
Epoch: 010, Runtime 29.682244, Loss 5.325775, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3074, Test: 0.2904, Best time: 54.8843
Epoch: 011, Runtime 29.978674, Loss 5.244632, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2924, Best time: 53.0000
Epoch: 012, Runtime 29.854522, Loss 4.738131, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2924, Best time: 18.2948
Epoch: 013, Runtime 30.631713, Loss 4.538190, forward nfe 3628, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 53.0000
Epoch: 014, Runtime 29.555155, Loss 4.488863, forward nfe 3924, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 015, Runtime 29.952823, Loss 4.510930, forward nfe 4220, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 016, Runtime 30.286919, Loss 4.110018, forward nfe 4516, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 017, Runtime 31.830873, Loss 3.839259, forward nfe 4812, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 018, Runtime 33.190979, Loss 3.926478, forward nfe 5108, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 019, Runtime 34.232570, Loss 3.909899, forward nfe 5404, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 020, Runtime 34.334497, Loss 3.799715, forward nfe 5700, backward nfe 0, Train: 0.1571, Val: 0.3132, Test: 0.2954, Best time: 18.2948
Epoch: 021, Runtime 34.875110, Loss 3.799380, forward nfe 5996, backward nfe 0, Train: 0.1571, Val: 0.3147, Test: 0.2944, Best time: 43.0000
Epoch: 022, Runtime 27.555245, Loss 3.852121, forward nfe 6292, backward nfe 0, Train: 0.1571, Val: 0.3147, Test: 0.2944, Best time: 18.2948
Epoch: 023, Runtime 27.621656, Loss 3.625189, forward nfe 6588, backward nfe 0, Train: 0.1571, Val: 0.3147, Test: 0.2944, Best time: 18.2948
Epoch: 024, Runtime 27.547462, Loss 3.472549, forward nfe 6884, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 42.0000
Epoch: 025, Runtime 26.132575, Loss 3.912586, forward nfe 7180, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 026, Runtime 27.140902, Loss 3.647477, forward nfe 7476, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 027, Runtime 27.465472, Loss 3.321202, forward nfe 7772, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 028, Runtime 27.523949, Loss 3.412125, forward nfe 8068, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 029, Runtime 27.369176, Loss 3.391423, forward nfe 8364, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 030, Runtime 29.144886, Loss 3.183284, forward nfe 8660, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 031, Runtime 30.371560, Loss 3.423818, forward nfe 8956, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 032, Runtime 30.811398, Loss 3.232149, forward nfe 9252, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 033, Runtime 32.317573, Loss 3.275890, forward nfe 9548, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 034, Runtime 33.255714, Loss 3.363392, forward nfe 9844, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 035, Runtime 33.339350, Loss 3.244302, forward nfe 10140, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 036, Runtime 35.049485, Loss 3.254101, forward nfe 10436, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 037, Runtime 36.323589, Loss 3.256421, forward nfe 10732, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 038, Runtime 36.549224, Loss 3.179194, forward nfe 11028, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 039, Runtime 36.735164, Loss 3.165925, forward nfe 11324, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 040, Runtime 37.034159, Loss 3.484417, forward nfe 11620, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 041, Runtime 37.221416, Loss 2.995942, forward nfe 11916, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 042, Runtime 37.749293, Loss 3.557916, forward nfe 12212, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 043, Runtime 37.136142, Loss 3.454782, forward nfe 12508, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 044, Runtime 38.023849, Loss 2.941599, forward nfe 12804, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 045, Runtime 26.742728, Loss 3.138624, forward nfe 13100, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 046, Runtime 25.830008, Loss 3.185471, forward nfe 13396, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 047, Runtime 26.173368, Loss 3.098860, forward nfe 13692, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 048, Runtime 27.301018, Loss 2.878572, forward nfe 13988, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 049, Runtime 28.747845, Loss 2.808401, forward nfe 14284, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 050, Runtime 29.534286, Loss 2.837066, forward nfe 14580, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 051, Runtime 30.516901, Loss 3.062232, forward nfe 14876, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 052, Runtime 31.023322, Loss 3.455969, forward nfe 15172, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 053, Runtime 31.372565, Loss 3.116566, forward nfe 15468, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 054, Runtime 32.393319, Loss 3.124406, forward nfe 15764, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 055, Runtime 33.151514, Loss 2.924345, forward nfe 16060, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 056, Runtime 33.991604, Loss 2.852937, forward nfe 16356, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 057, Runtime 34.617212, Loss 3.143348, forward nfe 16652, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 058, Runtime 34.496011, Loss 2.862903, forward nfe 16948, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 059, Runtime 34.841639, Loss 3.014268, forward nfe 17244, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 060, Runtime 35.314253, Loss 3.101701, forward nfe 17540, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 061, Runtime 36.641343, Loss 3.065617, forward nfe 17836, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 062, Runtime 36.488605, Loss 2.729088, forward nfe 18132, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 063, Runtime 36.608820, Loss 2.830500, forward nfe 18428, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 064, Runtime 36.388325, Loss 3.186420, forward nfe 18724, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 065, Runtime 37.032499, Loss 3.008391, forward nfe 19020, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 066, Runtime 37.729684, Loss 2.936031, forward nfe 19316, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 067, Runtime 34.023740, Loss 3.016635, forward nfe 19612, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 068, Runtime 25.626544, Loss 3.256587, forward nfe 19908, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 069, Runtime 25.783895, Loss 2.834210, forward nfe 20204, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 070, Runtime 26.019710, Loss 3.182842, forward nfe 20500, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 071, Runtime 26.797114, Loss 2.883717, forward nfe 20796, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 072, Runtime 27.582900, Loss 2.959469, forward nfe 21092, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 073, Runtime 26.957530, Loss 3.209748, forward nfe 21388, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 074, Runtime 27.673007, Loss 3.036573, forward nfe 21684, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 075, Runtime 28.643652, Loss 2.938692, forward nfe 21980, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 076, Runtime 28.719516, Loss 3.201665, forward nfe 22276, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 077, Runtime 28.306711, Loss 2.996113, forward nfe 22572, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 078, Runtime 29.126529, Loss 2.977616, forward nfe 22868, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 079, Runtime 29.992415, Loss 2.814003, forward nfe 23164, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 080, Runtime 30.680426, Loss 3.102784, forward nfe 23460, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 081, Runtime 30.663818, Loss 2.925663, forward nfe 23756, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 082, Runtime 31.199583, Loss 2.931616, forward nfe 24052, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 083, Runtime 31.028329, Loss 2.806637, forward nfe 24348, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 084, Runtime 30.754296, Loss 2.919278, forward nfe 24644, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 085, Runtime 31.464480, Loss 3.087902, forward nfe 24940, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 086, Runtime 32.109405, Loss 2.998366, forward nfe 25236, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 087, Runtime 32.962319, Loss 2.480819, forward nfe 25532, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 088, Runtime 33.835622, Loss 2.889618, forward nfe 25828, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 089, Runtime 33.876936, Loss 2.964551, forward nfe 26124, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 090, Runtime 34.123996, Loss 3.079059, forward nfe 26420, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 091, Runtime 34.626848, Loss 2.982669, forward nfe 26716, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 092, Runtime 34.974816, Loss 2.959802, forward nfe 27012, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 093, Runtime 34.391721, Loss 3.060643, forward nfe 27308, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 094, Runtime 34.689231, Loss 3.145023, forward nfe 27604, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 095, Runtime 31.297489, Loss 3.129671, forward nfe 27900, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 096, Runtime 23.230169, Loss 2.890538, forward nfe 28196, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 097, Runtime 24.355829, Loss 2.777885, forward nfe 28492, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 098, Runtime 25.419335, Loss 2.873499, forward nfe 28788, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
Epoch: 099, Runtime 25.604112, Loss 2.859428, forward nfe 29084, backward nfe 0, Train: 0.1571, Val: 0.3154, Test: 0.2944, Best time: 18.2948
best val accuracy 0.315441 with test accuracy 0.294416 at epoch 24 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.14822335025380712
Entropy Threshold: 2 Test accuracy: 0.14619289340101524
Entropy Threshold: 1.6 Test accuracy: 0.15384615384615385
Entropy Threshold: 1.5 Test accuracy: 0.058823529411764705
Entropy Threshold: 1.4 Test accuracy: 0.0
Entropy Threshold: 1.3 Test accuracy: 0.2
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
