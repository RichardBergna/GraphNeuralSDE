[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 8.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.863131, Loss 6.979169, forward nfe 76, backward nfe 0, Train: 0.4071, Val: 0.2471, Test: 0.2355, Best time: 1.0000
Epoch: 002, Runtime 14.612571, Loss 7.070800, forward nfe 372, backward nfe 0, Train: 0.6286, Val: 0.4154, Test: 0.4457, Best time: 9.0000
Epoch: 003, Runtime 14.039537, Loss 5.461893, forward nfe 668, backward nfe 0, Train: 0.5857, Val: 0.4228, Test: 0.4457, Best time: 2.0000
Epoch: 004, Runtime 14.501715, Loss 4.768044, forward nfe 964, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 3.0000
Epoch: 005, Runtime 15.101800, Loss 4.838555, forward nfe 1260, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 006, Runtime 15.094888, Loss 4.336321, forward nfe 1556, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 007, Runtime 15.730631, Loss 3.964392, forward nfe 1852, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 008, Runtime 15.832751, Loss 3.577267, forward nfe 2148, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 009, Runtime 16.506403, Loss 3.877085, forward nfe 2444, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 010, Runtime 16.370115, Loss 3.414691, forward nfe 2740, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 011, Runtime 16.471043, Loss 3.008706, forward nfe 3036, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 012, Runtime 16.622040, Loss 2.893468, forward nfe 3332, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 013, Runtime 16.226321, Loss 2.785688, forward nfe 3628, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 014, Runtime 16.714412, Loss 2.634668, forward nfe 3924, backward nfe 0, Train: 0.6357, Val: 0.4471, Test: 0.4701, Best time: 18.2948
Epoch: 015, Runtime 16.649833, Loss 2.412255, forward nfe 4220, backward nfe 0, Train: 0.6857, Val: 0.5316, Test: 0.5716, Best time: 22.0000
Epoch: 016, Runtime 14.592364, Loss 2.848511, forward nfe 4516, backward nfe 0, Train: 0.7143, Val: 0.6397, Test: 0.6701, Best time: 32.0000
Epoch: 017, Runtime 14.538451, Loss 2.536543, forward nfe 4812, backward nfe 0, Train: 0.7214, Val: 0.6706, Test: 0.7117, Best time: 33.0000
Epoch: 018, Runtime 14.527885, Loss 2.228491, forward nfe 5108, backward nfe 0, Train: 0.8000, Val: 0.7243, Test: 0.7584, Best time: 18.0000
Epoch: 019, Runtime 14.529327, Loss 2.239216, forward nfe 5404, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 13.0000
Epoch: 020, Runtime 14.670085, Loss 2.206834, forward nfe 5700, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 021, Runtime 14.643008, Loss 2.336518, forward nfe 5996, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 022, Runtime 14.670500, Loss 2.312409, forward nfe 6292, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 023, Runtime 14.640358, Loss 2.168899, forward nfe 6588, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 024, Runtime 14.544268, Loss 2.189280, forward nfe 6884, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 025, Runtime 15.056411, Loss 2.197647, forward nfe 7180, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 026, Runtime 14.839858, Loss 1.945827, forward nfe 7476, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 027, Runtime 15.076100, Loss 2.119208, forward nfe 7772, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 028, Runtime 15.666436, Loss 2.072859, forward nfe 8068, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 029, Runtime 15.850313, Loss 2.096900, forward nfe 8364, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 030, Runtime 15.886178, Loss 1.934240, forward nfe 8660, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 031, Runtime 15.435176, Loss 1.981679, forward nfe 8956, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 032, Runtime 14.752216, Loss 2.019924, forward nfe 9252, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 033, Runtime 14.665339, Loss 2.163737, forward nfe 9548, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 034, Runtime 14.581689, Loss 1.887587, forward nfe 9844, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 035, Runtime 14.543324, Loss 1.980577, forward nfe 10140, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 036, Runtime 14.466468, Loss 1.928621, forward nfe 10436, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 037, Runtime 14.485420, Loss 1.979623, forward nfe 10732, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 038, Runtime 16.054408, Loss 1.995128, forward nfe 11028, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 039, Runtime 17.060050, Loss 1.914294, forward nfe 11324, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 040, Runtime 17.508899, Loss 1.954358, forward nfe 11620, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 041, Runtime 17.307937, Loss 2.089861, forward nfe 11916, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 042, Runtime 17.480742, Loss 1.810522, forward nfe 12212, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 043, Runtime 17.609550, Loss 1.810736, forward nfe 12508, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 044, Runtime 17.816893, Loss 1.967548, forward nfe 12804, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 045, Runtime 18.021166, Loss 1.763798, forward nfe 13100, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 046, Runtime 17.812248, Loss 1.735716, forward nfe 13396, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 047, Runtime 18.027377, Loss 1.559259, forward nfe 13692, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 048, Runtime 18.083741, Loss 1.812725, forward nfe 13988, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 049, Runtime 18.067847, Loss 1.842780, forward nfe 14284, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 050, Runtime 18.152828, Loss 1.549443, forward nfe 14580, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 051, Runtime 18.266242, Loss 1.621231, forward nfe 14876, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 052, Runtime 18.475074, Loss 1.790450, forward nfe 15172, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 053, Runtime 18.430280, Loss 1.874620, forward nfe 15468, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 054, Runtime 18.455444, Loss 1.660494, forward nfe 15764, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 055, Runtime 19.109370, Loss 1.767210, forward nfe 16060, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 056, Runtime 19.296727, Loss 1.760789, forward nfe 16356, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 057, Runtime 19.463919, Loss 1.621829, forward nfe 16652, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 058, Runtime 18.813831, Loss 1.531346, forward nfe 16948, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 059, Runtime 18.965434, Loss 1.579437, forward nfe 17244, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 060, Runtime 19.010536, Loss 1.540652, forward nfe 17540, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 061, Runtime 18.931623, Loss 1.418392, forward nfe 17836, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 062, Runtime 18.979749, Loss 1.536781, forward nfe 18132, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 063, Runtime 19.160510, Loss 1.606873, forward nfe 18428, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 064, Runtime 18.354104, Loss 1.540332, forward nfe 18724, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 065, Runtime 17.853015, Loss 1.422141, forward nfe 19020, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 066, Runtime 17.837785, Loss 1.269114, forward nfe 19316, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 067, Runtime 17.562698, Loss 1.502941, forward nfe 19612, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 068, Runtime 18.168715, Loss 1.305991, forward nfe 19908, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 069, Runtime 17.950662, Loss 1.361384, forward nfe 20204, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 070, Runtime 18.159604, Loss 1.214732, forward nfe 20500, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 071, Runtime 17.726576, Loss 1.224639, forward nfe 20796, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 072, Runtime 17.849978, Loss 1.463098, forward nfe 21092, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 073, Runtime 15.404958, Loss 1.222110, forward nfe 21388, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 074, Runtime 15.837831, Loss 1.422289, forward nfe 21684, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 075, Runtime 15.375868, Loss 1.174918, forward nfe 21980, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 076, Runtime 16.303110, Loss 1.246797, forward nfe 22276, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 077, Runtime 15.947447, Loss 1.294645, forward nfe 22572, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 078, Runtime 16.053516, Loss 1.342274, forward nfe 22868, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 079, Runtime 16.444103, Loss 1.117988, forward nfe 23164, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 080, Runtime 16.806857, Loss 1.215602, forward nfe 23460, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 081, Runtime 16.644810, Loss 1.326607, forward nfe 23756, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 082, Runtime 16.900683, Loss 1.195669, forward nfe 24052, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 083, Runtime 16.875582, Loss 1.156409, forward nfe 24348, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 084, Runtime 17.129813, Loss 0.990300, forward nfe 24644, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 085, Runtime 17.192487, Loss 1.280672, forward nfe 24940, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 086, Runtime 17.527989, Loss 1.344014, forward nfe 25236, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 087, Runtime 17.093941, Loss 1.188859, forward nfe 25532, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 088, Runtime 17.275398, Loss 1.229530, forward nfe 25828, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 089, Runtime 17.526468, Loss 1.069600, forward nfe 26124, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 090, Runtime 17.492987, Loss 0.941728, forward nfe 26420, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 091, Runtime 17.627569, Loss 1.022735, forward nfe 26716, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 092, Runtime 17.905599, Loss 0.937208, forward nfe 27012, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 093, Runtime 17.817513, Loss 1.060953, forward nfe 27308, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 094, Runtime 17.702790, Loss 1.071041, forward nfe 27604, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 095, Runtime 17.827661, Loss 0.914957, forward nfe 27900, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 096, Runtime 18.005078, Loss 0.898652, forward nfe 28196, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 097, Runtime 17.712381, Loss 1.063913, forward nfe 28492, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 098, Runtime 17.884027, Loss 1.141227, forward nfe 28788, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
Epoch: 099, Runtime 18.171883, Loss 1.117325, forward nfe 29084, backward nfe 0, Train: 0.7857, Val: 0.7257, Test: 0.7411, Best time: 18.2948
best val accuracy 0.725735 with test accuracy 0.741117 at epoch 19 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.4862944162436548
Entropy Threshold: 2 Test accuracy: 0.4446700507614213
Entropy Threshold: 1.6 Test accuracy: 0.8227848101265823
Entropy Threshold: 1.5 Test accuracy: 0.8085106382978723
Entropy Threshold: 1.4 Test accuracy: 0.8333333333333334
Entropy Threshold: 1.3 Test accuracy: 0.9285714285714286
Entropy Threshold: 1.2 Test accuracy: 0.95
Entropy Threshold: 1.1 Test accuracy: 0.9375
Entropy Threshold: 0.9 Test accuracy: 0.75
Entropy Threshold: 0.8 Test accuracy: 1.0
Entropy Threshold: 0.7 Test accuracy: 1.0
Entropy Threshold: 0.6 Test accuracy: 1.0
Entropy Threshold: 0.5 Test accuracy: 1.0
Entropy Threshold: 0.4 Test accuracy: 1.0
Entropy Threshold: 0.3 Test accuracy: 1.0
Entropy Threshold: 0.2 Test accuracy: 1.0
Entropy Threshold: 0.1 Test accuracy: 1.0
