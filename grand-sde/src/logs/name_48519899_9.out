[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.1
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.624536, Loss 1.951077, forward nfe 76, backward nfe 0, Train: 0.4214, Val: 0.3272, Test: 0.3157, Best time: 1.0000
Epoch: 002, Runtime 14.341401, Loss 1.903035, forward nfe 372, backward nfe 0, Train: 0.6143, Val: 0.4147, Test: 0.4081, Best time: 1.0000
Epoch: 003, Runtime 14.112086, Loss 1.784257, forward nfe 668, backward nfe 0, Train: 0.6643, Val: 0.4331, Test: 0.4437, Best time: 1.0000
Epoch: 004, Runtime 14.444123, Loss 1.631010, forward nfe 964, backward nfe 0, Train: 0.7857, Val: 0.5654, Test: 0.5635, Best time: 7.0000
Epoch: 005, Runtime 14.379882, Loss 1.421895, forward nfe 1260, backward nfe 0, Train: 0.8286, Val: 0.7066, Test: 0.6985, Best time: 7.0000
Epoch: 006, Runtime 14.547917, Loss 1.144769, forward nfe 1556, backward nfe 0, Train: 0.8857, Val: 0.7713, Test: 0.7695, Best time: 11.0000
Epoch: 007, Runtime 14.453486, Loss 0.907519, forward nfe 1852, backward nfe 0, Train: 0.8929, Val: 0.8044, Test: 0.8071, Best time: 25.0000
Epoch: 008, Runtime 14.113143, Loss 0.703499, forward nfe 2148, backward nfe 0, Train: 0.8929, Val: 0.8044, Test: 0.8071, Best time: 18.2948
Epoch: 009, Runtime 14.681412, Loss 0.563294, forward nfe 2444, backward nfe 0, Train: 0.8929, Val: 0.8044, Test: 0.8071, Best time: 18.2948
Epoch: 010, Runtime 15.151968, Loss 0.453445, forward nfe 2740, backward nfe 0, Train: 0.9071, Val: 0.8088, Test: 0.8132, Best time: 54.8843
Epoch: 011, Runtime 14.131865, Loss 0.339893, forward nfe 3036, backward nfe 0, Train: 0.9214, Val: 0.8169, Test: 0.8213, Best time: 43.0000
Epoch: 012, Runtime 14.451259, Loss 0.321143, forward nfe 3332, backward nfe 0, Train: 0.9429, Val: 0.8265, Test: 0.8325, Best time: 25.0000
Epoch: 013, Runtime 14.146624, Loss 0.290407, forward nfe 3628, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 014, Runtime 13.883105, Loss 0.265594, forward nfe 3924, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 015, Runtime 14.276639, Loss 0.244713, forward nfe 4220, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 016, Runtime 14.788254, Loss 0.221324, forward nfe 4516, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 017, Runtime 14.356945, Loss 0.324491, forward nfe 4812, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 018, Runtime 14.484630, Loss 0.235186, forward nfe 5108, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 019, Runtime 14.908065, Loss 0.226556, forward nfe 5404, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 020, Runtime 15.317212, Loss 0.247699, forward nfe 5700, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 021, Runtime 14.737418, Loss 0.248399, forward nfe 5996, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 022, Runtime 14.775575, Loss 0.271753, forward nfe 6292, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 023, Runtime 15.045823, Loss 0.266735, forward nfe 6588, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 024, Runtime 15.453445, Loss 0.256633, forward nfe 6884, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 025, Runtime 15.263363, Loss 0.287564, forward nfe 7180, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 026, Runtime 15.079679, Loss 0.239500, forward nfe 7476, backward nfe 0, Train: 0.9214, Val: 0.8279, Test: 0.8284, Best time: 18.2948
Epoch: 027, Runtime 15.632270, Loss 0.254148, forward nfe 7772, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 52.0000
Epoch: 028, Runtime 13.648329, Loss 0.217943, forward nfe 8068, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 029, Runtime 14.255837, Loss 0.216058, forward nfe 8364, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 030, Runtime 14.701354, Loss 0.246974, forward nfe 8660, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 031, Runtime 14.174543, Loss 0.286145, forward nfe 8956, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 032, Runtime 14.062871, Loss 0.195005, forward nfe 9252, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 033, Runtime 14.514556, Loss 0.169411, forward nfe 9548, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 034, Runtime 14.758898, Loss 0.208707, forward nfe 9844, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 035, Runtime 14.454262, Loss 0.282292, forward nfe 10140, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 036, Runtime 14.431075, Loss 0.221945, forward nfe 10436, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 037, Runtime 14.829157, Loss 0.184680, forward nfe 10732, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 038, Runtime 15.218337, Loss 0.196576, forward nfe 11028, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 039, Runtime 14.821684, Loss 0.166813, forward nfe 11324, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 040, Runtime 14.739217, Loss 0.143784, forward nfe 11620, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 041, Runtime 15.063645, Loss 0.164112, forward nfe 11916, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 042, Runtime 15.324535, Loss 0.150336, forward nfe 12212, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 043, Runtime 15.097771, Loss 0.189434, forward nfe 12508, backward nfe 0, Train: 0.9500, Val: 0.8353, Test: 0.8325, Best time: 18.2948
Epoch: 044, Runtime 15.284669, Loss 0.156260, forward nfe 12804, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 045, Runtime 13.349262, Loss 0.165845, forward nfe 13100, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 046, Runtime 13.658159, Loss 0.189120, forward nfe 13396, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 047, Runtime 14.140589, Loss 0.166078, forward nfe 13692, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 048, Runtime 13.859261, Loss 0.177853, forward nfe 13988, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 049, Runtime 13.817636, Loss 0.192333, forward nfe 14284, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 050, Runtime 14.234581, Loss 0.175365, forward nfe 14580, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 051, Runtime 14.772524, Loss 0.214105, forward nfe 14876, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 052, Runtime 14.528761, Loss 0.194765, forward nfe 15172, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 053, Runtime 14.519990, Loss 0.166652, forward nfe 15468, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 054, Runtime 14.990017, Loss 0.188975, forward nfe 15764, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 055, Runtime 15.127148, Loss 0.207957, forward nfe 16060, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 056, Runtime 15.012298, Loss 0.170785, forward nfe 16356, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 057, Runtime 15.106574, Loss 0.167522, forward nfe 16652, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 058, Runtime 15.151026, Loss 0.174736, forward nfe 16948, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 059, Runtime 15.241884, Loss 0.146690, forward nfe 17244, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 060, Runtime 15.169753, Loss 0.136658, forward nfe 17540, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 061, Runtime 15.116053, Loss 0.156825, forward nfe 17836, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 062, Runtime 15.193984, Loss 0.152780, forward nfe 18132, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 063, Runtime 15.594002, Loss 0.170496, forward nfe 18428, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 064, Runtime 15.624670, Loss 0.183299, forward nfe 18724, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 065, Runtime 15.306192, Loss 0.229370, forward nfe 19020, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 066, Runtime 15.455696, Loss 0.165336, forward nfe 19316, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 067, Runtime 15.717304, Loss 0.198792, forward nfe 19612, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 068, Runtime 15.705208, Loss 0.146103, forward nfe 19908, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 069, Runtime 15.504911, Loss 0.132535, forward nfe 20204, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 070, Runtime 15.535741, Loss 0.167105, forward nfe 20500, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 071, Runtime 15.626524, Loss 0.173529, forward nfe 20796, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 072, Runtime 15.765753, Loss 0.118506, forward nfe 21092, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 073, Runtime 15.748795, Loss 0.168372, forward nfe 21388, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 074, Runtime 15.850196, Loss 0.158413, forward nfe 21684, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 075, Runtime 15.910330, Loss 0.131274, forward nfe 21980, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 076, Runtime 15.836676, Loss 0.149221, forward nfe 22276, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 077, Runtime 15.654035, Loss 0.105957, forward nfe 22572, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 078, Runtime 15.799634, Loss 0.113647, forward nfe 22868, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 079, Runtime 15.957816, Loss 0.151750, forward nfe 23164, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 080, Runtime 16.107875, Loss 0.105131, forward nfe 23460, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 081, Runtime 16.105324, Loss 0.165222, forward nfe 23756, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 082, Runtime 16.014307, Loss 0.104797, forward nfe 24052, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 083, Runtime 16.056726, Loss 0.094833, forward nfe 24348, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 084, Runtime 16.225327, Loss 0.146835, forward nfe 24644, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 085, Runtime 16.123271, Loss 0.115460, forward nfe 24940, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 086, Runtime 15.210070, Loss 0.114286, forward nfe 25236, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 087, Runtime 14.970050, Loss 0.155144, forward nfe 25532, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 088, Runtime 11.846876, Loss 0.109106, forward nfe 25828, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 089, Runtime 11.608214, Loss 0.115000, forward nfe 26124, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 090, Runtime 11.611100, Loss 0.177236, forward nfe 26420, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 091, Runtime 11.780609, Loss 0.182826, forward nfe 26716, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 092, Runtime 11.650822, Loss 0.135309, forward nfe 27012, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 093, Runtime 11.609703, Loss 0.149485, forward nfe 27308, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 094, Runtime 11.740554, Loss 0.139997, forward nfe 27604, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 095, Runtime 11.822839, Loss 0.154256, forward nfe 27900, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 096, Runtime 11.726565, Loss 0.090234, forward nfe 28196, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 097, Runtime 11.754806, Loss 0.120213, forward nfe 28492, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 098, Runtime 11.810150, Loss 0.094384, forward nfe 28788, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
Epoch: 099, Runtime 12.279697, Loss 0.146740, forward nfe 29084, backward nfe 0, Train: 0.9500, Val: 0.8368, Test: 0.8416, Best time: 18.2948
best val accuracy 0.836765 with test accuracy 0.841624 at epoch 44 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8446700507614213
Entropy Threshold: 2 Test accuracy: 0.8436548223350254
Entropy Threshold: 1.6 Test accuracy: 0.8453713123092573
Entropy Threshold: 1.5 Test accuracy: 0.8467824310520939
Entropy Threshold: 1.4 Test accuracy: 0.8486707566462167
Entropy Threshold: 1.3 Test accuracy: 0.8520041109969168
Entropy Threshold: 1.2 Test accuracy: 0.8586278586278586
Entropy Threshold: 1.1 Test accuracy: 0.8604407135362014
Entropy Threshold: 0.9 Test accuracy: 0.8784227820372399
Entropy Threshold: 0.8 Test accuracy: 0.8876404494382022
Entropy Threshold: 0.7 Test accuracy: 0.9014084507042254
Entropy Threshold: 0.6 Test accuracy: 0.9156479217603912
Entropy Threshold: 0.5 Test accuracy: 0.9263959390862944
Entropy Threshold: 0.4 Test accuracy: 0.9388297872340425
Entropy Threshold: 0.3 Test accuracy: 0.9442896935933147
Entropy Threshold: 0.2 Test accuracy: 0.9454277286135693
Entropy Threshold: 0.1 Test accuracy: 0.9514563106796117
