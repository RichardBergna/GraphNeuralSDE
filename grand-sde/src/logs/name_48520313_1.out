[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 12.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 76.481763, Loss 13.137482, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1610, Test: 0.1543, Best time: 54.8843
Epoch: 002, Runtime 76.847789, Loss 29.617428, forward nfe 372, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 003, Runtime 35.250988, Loss 4.195786, forward nfe 668, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 004, Runtime 35.812432, Loss 4.096549, forward nfe 964, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 005, Runtime 37.057621, Loss 4.102607, forward nfe 1260, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 006, Runtime 36.506801, Loss 4.592888, forward nfe 1556, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 007, Runtime 37.453133, Loss 4.684530, forward nfe 1852, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 008, Runtime 38.291919, Loss 4.617576, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 009, Runtime 37.962534, Loss 4.620590, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 010, Runtime 39.070768, Loss 4.646568, forward nfe 2740, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 011, Runtime 40.007179, Loss 4.434012, forward nfe 3036, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 012, Runtime 40.201334, Loss 4.442962, forward nfe 3332, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 013, Runtime 40.483002, Loss 4.689654, forward nfe 3628, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 014, Runtime 41.734118, Loss 3.995834, forward nfe 3924, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 015, Runtime 42.476682, Loss 3.997874, forward nfe 4220, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 016, Runtime 41.910520, Loss 4.352087, forward nfe 4516, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 017, Runtime 43.331513, Loss 3.896265, forward nfe 4812, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 018, Runtime 43.998724, Loss 4.052799, forward nfe 5108, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 019, Runtime 43.173152, Loss 4.041783, forward nfe 5404, backward nfe 0, Train: 0.1500, Val: 0.1978, Test: 0.2132, Best time: 18.2948
Epoch: 020, Runtime 30.432497, Loss 4.026780, forward nfe 5700, backward nfe 0, Train: 0.1286, Val: 0.2022, Test: 0.2051, Best time: 18.2948
Epoch: 021, Runtime 28.437583, Loss 3.902364, forward nfe 5996, backward nfe 0, Train: 0.1286, Val: 0.2022, Test: 0.2051, Best time: 18.2948
Epoch: 022, Runtime 28.957417, Loss 4.076598, forward nfe 6292, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 023, Runtime 28.158842, Loss 3.912548, forward nfe 6588, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 024, Runtime 29.124698, Loss 4.023776, forward nfe 6884, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 025, Runtime 30.218164, Loss 4.214571, forward nfe 7180, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 026, Runtime 29.947017, Loss 4.050141, forward nfe 7476, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 027, Runtime 31.382075, Loss 4.110301, forward nfe 7772, backward nfe 0, Train: 0.1000, Val: 0.2103, Test: 0.2030, Best time: 18.2948
Epoch: 028, Runtime 32.469847, Loss 4.100438, forward nfe 8068, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.1909, Best time: 18.2948
Epoch: 029, Runtime 27.283079, Loss 3.996423, forward nfe 8364, backward nfe 0, Train: 0.1500, Val: 0.2110, Test: 0.1909, Best time: 18.2948
Epoch: 030, Runtime 27.664168, Loss 3.980839, forward nfe 8660, backward nfe 0, Train: 0.1643, Val: 0.2140, Test: 0.2183, Best time: 18.2948
Epoch: 031, Runtime 27.037071, Loss 3.631916, forward nfe 8956, backward nfe 0, Train: 0.1643, Val: 0.2140, Test: 0.2183, Best time: 18.2948
Epoch: 032, Runtime 27.765451, Loss 3.654186, forward nfe 9252, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 033, Runtime 26.719638, Loss 3.760230, forward nfe 9548, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 034, Runtime 26.966665, Loss 3.672746, forward nfe 9844, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 035, Runtime 27.384903, Loss 3.591833, forward nfe 10140, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 036, Runtime 28.106382, Loss 3.812392, forward nfe 10436, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 037, Runtime 28.027308, Loss 3.780938, forward nfe 10732, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 038, Runtime 27.528062, Loss 3.506177, forward nfe 11028, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 039, Runtime 28.952166, Loss 3.439407, forward nfe 11324, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 040, Runtime 29.440637, Loss 3.512045, forward nfe 11620, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 041, Runtime 29.479614, Loss 3.457600, forward nfe 11916, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 042, Runtime 30.056038, Loss 3.434314, forward nfe 12212, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 043, Runtime 31.384428, Loss 3.484065, forward nfe 12508, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 044, Runtime 32.292865, Loss 3.792913, forward nfe 12804, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 045, Runtime 33.309857, Loss 3.461387, forward nfe 13100, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 046, Runtime 33.134888, Loss 3.718667, forward nfe 13396, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 047, Runtime 32.619379, Loss 3.593512, forward nfe 13692, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 048, Runtime 32.692478, Loss 3.396498, forward nfe 13988, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 049, Runtime 34.190000, Loss 3.429383, forward nfe 14284, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 050, Runtime 34.753370, Loss 3.580664, forward nfe 14580, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 051, Runtime 35.111307, Loss 3.542403, forward nfe 14876, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 052, Runtime 35.540256, Loss 3.691140, forward nfe 15172, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 053, Runtime 35.580745, Loss 3.323702, forward nfe 15468, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 054, Runtime 35.629563, Loss 3.055291, forward nfe 15764, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 055, Runtime 36.628316, Loss 3.445079, forward nfe 16060, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 056, Runtime 36.717253, Loss 3.253378, forward nfe 16356, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 057, Runtime 37.062330, Loss 3.278931, forward nfe 16652, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 058, Runtime 37.390167, Loss 3.158534, forward nfe 16948, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 059, Runtime 38.378065, Loss 3.300425, forward nfe 17244, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 060, Runtime 34.035068, Loss 3.066617, forward nfe 17540, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 061, Runtime 26.801243, Loss 3.489231, forward nfe 17836, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 062, Runtime 27.624603, Loss 3.342962, forward nfe 18132, backward nfe 0, Train: 0.1500, Val: 0.2257, Test: 0.1817, Best time: 18.2948
Epoch: 063, Runtime 28.756350, Loss 2.966833, forward nfe 18428, backward nfe 0, Train: 0.1929, Val: 0.2331, Test: 0.2396, Best time: 1.0000
Epoch: 064, Runtime 25.285368, Loss 3.049381, forward nfe 18724, backward nfe 0, Train: 0.1929, Val: 0.2426, Test: 0.2416, Best time: 1.0000
Epoch: 065, Runtime 24.293746, Loss 3.403015, forward nfe 19020, backward nfe 0, Train: 0.1929, Val: 0.2537, Test: 0.2548, Best time: 1.0000
Epoch: 066, Runtime 23.726706, Loss 3.458164, forward nfe 19316, backward nfe 0, Train: 0.1929, Val: 0.2676, Test: 0.2670, Best time: 1.0000
Epoch: 067, Runtime 24.090014, Loss 3.161501, forward nfe 19612, backward nfe 0, Train: 0.1929, Val: 0.2713, Test: 0.2741, Best time: 1.0000
Epoch: 068, Runtime 24.098857, Loss 3.196778, forward nfe 19908, backward nfe 0, Train: 0.2000, Val: 0.2765, Test: 0.2761, Best time: 1.0000
Epoch: 069, Runtime 23.879076, Loss 3.214733, forward nfe 20204, backward nfe 0, Train: 0.2000, Val: 0.2831, Test: 0.2772, Best time: 1.0000
Epoch: 070, Runtime 24.219497, Loss 3.021314, forward nfe 20500, backward nfe 0, Train: 0.1857, Val: 0.2846, Test: 0.2741, Best time: 1.0000
Epoch: 071, Runtime 24.211392, Loss 3.255288, forward nfe 20796, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 1.0000
Epoch: 072, Runtime 24.924929, Loss 3.509258, forward nfe 21092, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 073, Runtime 25.330336, Loss 3.363389, forward nfe 21388, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 074, Runtime 26.427299, Loss 3.127774, forward nfe 21684, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 075, Runtime 27.524692, Loss 3.210015, forward nfe 21980, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 076, Runtime 28.228325, Loss 3.162040, forward nfe 22276, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 077, Runtime 28.646476, Loss 2.808992, forward nfe 22572, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 078, Runtime 29.415569, Loss 2.987823, forward nfe 22868, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 079, Runtime 30.632648, Loss 3.157511, forward nfe 23164, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 080, Runtime 31.652024, Loss 3.084477, forward nfe 23460, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 081, Runtime 31.454816, Loss 3.342229, forward nfe 23756, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 082, Runtime 30.831269, Loss 2.700845, forward nfe 24052, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 083, Runtime 31.704913, Loss 3.104065, forward nfe 24348, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 084, Runtime 33.466787, Loss 3.022261, forward nfe 24644, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 085, Runtime 33.705204, Loss 3.202217, forward nfe 24940, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 086, Runtime 34.423009, Loss 2.991910, forward nfe 25236, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 087, Runtime 35.168095, Loss 2.941891, forward nfe 25532, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 088, Runtime 35.957700, Loss 3.090543, forward nfe 25828, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 089, Runtime 35.804168, Loss 2.678593, forward nfe 26124, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 090, Runtime 35.584232, Loss 3.017763, forward nfe 26420, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 091, Runtime 35.139737, Loss 3.008462, forward nfe 26716, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 092, Runtime 35.098169, Loss 3.028157, forward nfe 27012, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 093, Runtime 34.811856, Loss 3.139838, forward nfe 27308, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 094, Runtime 34.851759, Loss 3.148519, forward nfe 27604, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 095, Runtime 36.307057, Loss 3.083514, forward nfe 27900, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 096, Runtime 36.983112, Loss 2.995690, forward nfe 28196, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 097, Runtime 37.014387, Loss 2.804346, forward nfe 28492, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 098, Runtime 37.224749, Loss 2.833217, forward nfe 28788, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
Epoch: 099, Runtime 32.683661, Loss 3.270594, forward nfe 29084, backward nfe 0, Train: 0.1714, Val: 0.2897, Test: 0.2832, Best time: 18.2948
best val accuracy 0.289706 with test accuracy 0.283249 at epoch 71 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1766497461928934
Entropy Threshold: 2 Test accuracy: 0.18375634517766498
Entropy Threshold: 1.6 Test accuracy: 0.13861386138613863
Entropy Threshold: 1.5 Test accuracy: 0.12280701754385964
Entropy Threshold: 1.4 Test accuracy: 0.0
Entropy Threshold: 1.3 Test accuracy: 0.0
Entropy Threshold: 1.2 Test accuracy: 0.125
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
