[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.4
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 10.682985, Loss 2.148746, forward nfe 76, backward nfe 0, Train: 0.4214, Val: 0.4213, Test: 0.3787, Best time: 6.0000
Epoch: 002, Runtime 9.575224, Loss 2.377031, forward nfe 372, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 3.0000
Epoch: 003, Runtime 9.482560, Loss 2.094786, forward nfe 668, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 18.2948
Epoch: 004, Runtime 9.853194, Loss 2.149449, forward nfe 964, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 18.2948
Epoch: 005, Runtime 9.821582, Loss 1.995850, forward nfe 1260, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 18.2948
Epoch: 006, Runtime 9.772225, Loss 1.942407, forward nfe 1556, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 18.2948
Epoch: 007, Runtime 10.154294, Loss 1.910840, forward nfe 1852, backward nfe 0, Train: 0.6429, Val: 0.4809, Test: 0.4914, Best time: 18.2948
Epoch: 008, Runtime 10.231810, Loss 1.758785, forward nfe 2148, backward nfe 0, Train: 0.7000, Val: 0.5088, Test: 0.5269, Best time: 2.0000
Epoch: 009, Runtime 9.630930, Loss 1.623604, forward nfe 2444, backward nfe 0, Train: 0.7286, Val: 0.5529, Test: 0.5635, Best time: 4.0000
Epoch: 010, Runtime 9.608093, Loss 1.516330, forward nfe 2740, backward nfe 0, Train: 0.7571, Val: 0.5985, Test: 0.6091, Best time: 7.0000
Epoch: 011, Runtime 9.594861, Loss 1.418906, forward nfe 3036, backward nfe 0, Train: 0.8000, Val: 0.6485, Test: 0.6477, Best time: 4.0000
Epoch: 012, Runtime 9.588115, Loss 1.175074, forward nfe 3332, backward nfe 0, Train: 0.8500, Val: 0.6846, Test: 0.6883, Best time: 7.0000
Epoch: 013, Runtime 9.607617, Loss 1.039665, forward nfe 3628, backward nfe 0, Train: 0.8571, Val: 0.7140, Test: 0.7137, Best time: 6.0000
Epoch: 014, Runtime 9.583772, Loss 1.080345, forward nfe 3924, backward nfe 0, Train: 0.8500, Val: 0.7346, Test: 0.7259, Best time: 7.0000
Epoch: 015, Runtime 9.646804, Loss 0.972416, forward nfe 4220, backward nfe 0, Train: 0.8929, Val: 0.7368, Test: 0.7249, Best time: 5.0000
Epoch: 016, Runtime 9.541773, Loss 0.926722, forward nfe 4516, backward nfe 0, Train: 0.8929, Val: 0.7368, Test: 0.7249, Best time: 18.2948
Epoch: 017, Runtime 9.867897, Loss 0.843878, forward nfe 4812, backward nfe 0, Train: 0.8929, Val: 0.7368, Test: 0.7249, Best time: 18.2948
Epoch: 018, Runtime 9.664797, Loss 0.811833, forward nfe 5108, backward nfe 0, Train: 0.8643, Val: 0.7397, Test: 0.7259, Best time: 5.0000
Epoch: 019, Runtime 9.312396, Loss 0.752480, forward nfe 5404, backward nfe 0, Train: 0.8786, Val: 0.7610, Test: 0.7431, Best time: 6.0000
Epoch: 020, Runtime 9.641204, Loss 0.749787, forward nfe 5700, backward nfe 0, Train: 0.8929, Val: 0.7706, Test: 0.7614, Best time: 7.0000
Epoch: 021, Runtime 9.385064, Loss 0.683305, forward nfe 5996, backward nfe 0, Train: 0.8929, Val: 0.7816, Test: 0.7736, Best time: 11.0000
Epoch: 022, Runtime 9.416232, Loss 0.646191, forward nfe 6292, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 9.0000
Epoch: 023, Runtime 9.452902, Loss 0.645203, forward nfe 6588, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 024, Runtime 9.860798, Loss 0.526092, forward nfe 6884, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 025, Runtime 9.568805, Loss 0.589247, forward nfe 7180, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 026, Runtime 9.608963, Loss 0.589047, forward nfe 7476, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 027, Runtime 9.641253, Loss 0.510408, forward nfe 7772, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 028, Runtime 9.296036, Loss 0.509764, forward nfe 8068, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 029, Runtime 9.719765, Loss 0.527336, forward nfe 8364, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 030, Runtime 10.240510, Loss 0.475046, forward nfe 8660, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 031, Runtime 10.085268, Loss 0.482462, forward nfe 8956, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 032, Runtime 10.038179, Loss 0.486467, forward nfe 9252, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 033, Runtime 10.315691, Loss 0.433559, forward nfe 9548, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 034, Runtime 10.100852, Loss 0.412085, forward nfe 9844, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 035, Runtime 10.305723, Loss 0.393337, forward nfe 10140, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 036, Runtime 10.638177, Loss 0.401792, forward nfe 10436, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 037, Runtime 10.156521, Loss 0.322095, forward nfe 10732, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 038, Runtime 10.014366, Loss 0.407423, forward nfe 11028, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 039, Runtime 10.206467, Loss 0.417965, forward nfe 11324, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 040, Runtime 10.056850, Loss 0.334456, forward nfe 11620, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 041, Runtime 10.428193, Loss 0.347340, forward nfe 11916, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 042, Runtime 10.722130, Loss 0.399337, forward nfe 12212, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 043, Runtime 10.869401, Loss 0.334167, forward nfe 12508, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 044, Runtime 10.615441, Loss 0.302522, forward nfe 12804, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 045, Runtime 10.603771, Loss 0.329717, forward nfe 13100, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 046, Runtime 10.492005, Loss 0.363993, forward nfe 13396, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 047, Runtime 10.452956, Loss 0.313015, forward nfe 13692, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 048, Runtime 10.628138, Loss 0.329536, forward nfe 13988, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 049, Runtime 10.574285, Loss 0.259581, forward nfe 14284, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 050, Runtime 10.365322, Loss 0.232118, forward nfe 14580, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 051, Runtime 10.567621, Loss 0.307380, forward nfe 14876, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 052, Runtime 10.703125, Loss 0.348644, forward nfe 15172, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 053, Runtime 10.692282, Loss 0.361576, forward nfe 15468, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 054, Runtime 10.715713, Loss 0.327594, forward nfe 15764, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 055, Runtime 10.634603, Loss 0.332315, forward nfe 16060, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 056, Runtime 10.606405, Loss 0.363212, forward nfe 16356, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 057, Runtime 10.741758, Loss 0.419959, forward nfe 16652, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 058, Runtime 10.720513, Loss 0.320299, forward nfe 16948, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 059, Runtime 11.831756, Loss 0.247020, forward nfe 17244, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 060, Runtime 11.972023, Loss 0.241625, forward nfe 17540, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 061, Runtime 11.824557, Loss 0.159947, forward nfe 17836, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 062, Runtime 11.812780, Loss 0.267848, forward nfe 18132, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 063, Runtime 11.941547, Loss 0.265419, forward nfe 18428, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 064, Runtime 11.924891, Loss 0.282426, forward nfe 18724, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 065, Runtime 11.902173, Loss 0.255239, forward nfe 19020, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 066, Runtime 11.943132, Loss 0.209113, forward nfe 19316, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 067, Runtime 12.018610, Loss 0.340374, forward nfe 19612, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 068, Runtime 11.928268, Loss 0.250155, forward nfe 19908, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 069, Runtime 11.931362, Loss 0.265824, forward nfe 20204, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 070, Runtime 12.057348, Loss 0.238288, forward nfe 20500, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 071, Runtime 11.983766, Loss 0.231170, forward nfe 20796, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 072, Runtime 12.079890, Loss 0.205087, forward nfe 21092, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 073, Runtime 11.990512, Loss 0.232172, forward nfe 21388, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 074, Runtime 12.000853, Loss 0.268678, forward nfe 21684, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 075, Runtime 12.029541, Loss 0.221965, forward nfe 21980, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 076, Runtime 12.123480, Loss 0.317412, forward nfe 22276, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 077, Runtime 12.111104, Loss 0.284746, forward nfe 22572, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 078, Runtime 12.120851, Loss 0.249962, forward nfe 22868, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 079, Runtime 12.145202, Loss 0.296184, forward nfe 23164, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 080, Runtime 13.234785, Loss 0.288096, forward nfe 23460, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 081, Runtime 13.412901, Loss 0.194229, forward nfe 23756, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 082, Runtime 15.257712, Loss 0.237036, forward nfe 24052, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 083, Runtime 15.162851, Loss 0.198733, forward nfe 24348, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 084, Runtime 15.298917, Loss 0.195631, forward nfe 24644, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 085, Runtime 14.792661, Loss 0.238319, forward nfe 24940, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 086, Runtime 12.235663, Loss 0.185502, forward nfe 25236, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 087, Runtime 12.107167, Loss 0.181983, forward nfe 25532, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 088, Runtime 12.103892, Loss 0.254179, forward nfe 25828, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 089, Runtime 12.160711, Loss 0.175855, forward nfe 26124, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 090, Runtime 11.698953, Loss 0.257312, forward nfe 26420, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 091, Runtime 11.684012, Loss 0.202049, forward nfe 26716, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 092, Runtime 12.064760, Loss 0.252412, forward nfe 27012, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 093, Runtime 12.108273, Loss 0.192837, forward nfe 27308, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 094, Runtime 11.914290, Loss 0.261500, forward nfe 27604, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 095, Runtime 11.682383, Loss 0.282622, forward nfe 27900, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 096, Runtime 11.199633, Loss 0.176161, forward nfe 28196, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 097, Runtime 11.179006, Loss 0.242350, forward nfe 28492, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 098, Runtime 11.596024, Loss 0.267917, forward nfe 28788, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
Epoch: 099, Runtime 11.476610, Loss 0.173589, forward nfe 29084, backward nfe 0, Train: 0.8929, Val: 0.7882, Test: 0.7827, Best time: 18.2948
best val accuracy 0.788235 with test accuracy 0.782741 at epoch 22 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8030456852791878
Entropy Threshold: 2 Test accuracy: 0.8162436548223351
Entropy Threshold: 1.6 Test accuracy: 0.8144654088050315
Entropy Threshold: 1.5 Test accuracy: 0.824945295404814
Entropy Threshold: 1.4 Test accuracy: 0.8431151241534989
Entropy Threshold: 1.3 Test accuracy: 0.8488095238095238
Entropy Threshold: 1.2 Test accuracy: 0.8603773584905661
Entropy Threshold: 1.1 Test accuracy: 0.8758620689655172
Entropy Threshold: 0.9 Test accuracy: 0.9027552674230146
Entropy Threshold: 0.8 Test accuracy: 0.9154676258992805
Entropy Threshold: 0.7 Test accuracy: 0.9244186046511628
Entropy Threshold: 0.6 Test accuracy: 0.9453302961275627
Entropy Threshold: 0.5 Test accuracy: 0.9493670886075949
Entropy Threshold: 0.4 Test accuracy: 0.9465875370919882
Entropy Threshold: 0.3 Test accuracy: 0.9444444444444444
Entropy Threshold: 0.2 Test accuracy: 0.9504132231404959
Entropy Threshold: 0.1 Test accuracy: 0.9595375722543352
