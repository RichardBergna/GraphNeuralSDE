[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.5
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 10.848736, Loss 2.155364, forward nfe 76, backward nfe 0, Train: 0.2214, Val: 0.1706, Test: 0.1756, Best time: 1.0000
Epoch: 002, Runtime 9.771523, Loss 2.546940, forward nfe 372, backward nfe 0, Train: 0.3929, Val: 0.3463, Test: 0.3340, Best time: 1.0000
Epoch: 003, Runtime 9.706400, Loss 2.101312, forward nfe 668, backward nfe 0, Train: 0.3929, Val: 0.3463, Test: 0.3340, Best time: 18.2948
Epoch: 004, Runtime 10.060205, Loss 2.001725, forward nfe 964, backward nfe 0, Train: 0.3929, Val: 0.3463, Test: 0.3340, Best time: 18.2948
Epoch: 005, Runtime 9.899309, Loss 2.056049, forward nfe 1260, backward nfe 0, Train: 0.3929, Val: 0.3463, Test: 0.3340, Best time: 18.2948
Epoch: 006, Runtime 10.264687, Loss 1.987267, forward nfe 1556, backward nfe 0, Train: 0.4571, Val: 0.4346, Test: 0.3990, Best time: 1.0000
Epoch: 007, Runtime 9.894767, Loss 1.906796, forward nfe 1852, backward nfe 0, Train: 0.5643, Val: 0.5588, Test: 0.5239, Best time: 2.0000
Epoch: 008, Runtime 10.685447, Loss 1.819481, forward nfe 2148, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 3.0000
Epoch: 009, Runtime 11.068673, Loss 1.875987, forward nfe 2444, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 18.2948
Epoch: 010, Runtime 11.903470, Loss 1.663474, forward nfe 2740, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 18.2948
Epoch: 011, Runtime 11.790733, Loss 1.562405, forward nfe 3036, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 18.2948
Epoch: 012, Runtime 11.743818, Loss 1.490170, forward nfe 3332, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 18.2948
Epoch: 013, Runtime 12.225457, Loss 1.335086, forward nfe 3628, backward nfe 0, Train: 0.6071, Val: 0.6169, Test: 0.5746, Best time: 18.2948
Epoch: 014, Runtime 12.202188, Loss 1.264715, forward nfe 3924, backward nfe 0, Train: 0.7929, Val: 0.6471, Test: 0.6396, Best time: 5.0000
Epoch: 015, Runtime 11.464270, Loss 1.120657, forward nfe 4220, backward nfe 0, Train: 0.8000, Val: 0.6750, Test: 0.6670, Best time: 3.0000
Epoch: 016, Runtime 11.467899, Loss 1.083488, forward nfe 4516, backward nfe 0, Train: 0.8214, Val: 0.7331, Test: 0.7178, Best time: 6.0000
Epoch: 017, Runtime 11.404230, Loss 1.014648, forward nfe 4812, backward nfe 0, Train: 0.8357, Val: 0.7559, Test: 0.7289, Best time: 16.0000
Epoch: 018, Runtime 11.395737, Loss 0.936011, forward nfe 5108, backward nfe 0, Train: 0.8429, Val: 0.7632, Test: 0.7381, Best time: 15.0000
Epoch: 019, Runtime 11.284382, Loss 0.920896, forward nfe 5404, backward nfe 0, Train: 0.8643, Val: 0.7691, Test: 0.7482, Best time: 11.0000
Epoch: 020, Runtime 11.253310, Loss 0.798705, forward nfe 5700, backward nfe 0, Train: 0.8643, Val: 0.7691, Test: 0.7482, Best time: 18.2948
Epoch: 021, Runtime 11.697330, Loss 0.747788, forward nfe 5996, backward nfe 0, Train: 0.8643, Val: 0.7691, Test: 0.7482, Best time: 18.2948
Epoch: 022, Runtime 11.729124, Loss 0.766257, forward nfe 6292, backward nfe 0, Train: 0.8643, Val: 0.7691, Test: 0.7482, Best time: 18.2948
Epoch: 023, Runtime 11.842245, Loss 0.700477, forward nfe 6588, backward nfe 0, Train: 0.8643, Val: 0.7691, Test: 0.7482, Best time: 18.2948
Epoch: 024, Runtime 12.326244, Loss 0.590317, forward nfe 6884, backward nfe 0, Train: 0.9000, Val: 0.7787, Test: 0.7472, Best time: 14.0000
Epoch: 025, Runtime 11.321683, Loss 0.624016, forward nfe 7180, backward nfe 0, Train: 0.9000, Val: 0.7890, Test: 0.7635, Best time: 14.0000
Epoch: 026, Runtime 11.262311, Loss 0.661442, forward nfe 7476, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 027, Runtime 11.111387, Loss 0.686529, forward nfe 7772, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 028, Runtime 11.307403, Loss 0.556971, forward nfe 8068, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 029, Runtime 11.348677, Loss 0.544436, forward nfe 8364, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 030, Runtime 11.322010, Loss 0.600267, forward nfe 8660, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 031, Runtime 11.729442, Loss 0.602601, forward nfe 8956, backward nfe 0, Train: 0.8786, Val: 0.7919, Test: 0.7553, Best time: 18.2948
Epoch: 032, Runtime 11.632027, Loss 0.517904, forward nfe 9252, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 033, Runtime 10.655931, Loss 0.510232, forward nfe 9548, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 034, Runtime 10.718834, Loss 0.535773, forward nfe 9844, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 035, Runtime 10.701676, Loss 0.518541, forward nfe 10140, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 036, Runtime 10.615153, Loss 0.508106, forward nfe 10436, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 037, Runtime 10.796772, Loss 0.508302, forward nfe 10732, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 038, Runtime 10.764238, Loss 0.437786, forward nfe 11028, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 039, Runtime 10.682070, Loss 0.357499, forward nfe 11324, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 040, Runtime 11.002499, Loss 0.422027, forward nfe 11620, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 041, Runtime 10.960112, Loss 0.516392, forward nfe 11916, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 042, Runtime 10.994498, Loss 0.430041, forward nfe 12212, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 043, Runtime 11.256017, Loss 0.415116, forward nfe 12508, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 044, Runtime 11.589827, Loss 0.421444, forward nfe 12804, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 045, Runtime 12.580323, Loss 0.433670, forward nfe 13100, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 046, Runtime 12.878211, Loss 0.493520, forward nfe 13396, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 047, Runtime 12.865808, Loss 0.441999, forward nfe 13692, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 048, Runtime 12.768691, Loss 0.337961, forward nfe 13988, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 049, Runtime 13.020446, Loss 0.378786, forward nfe 14284, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 050, Runtime 12.963658, Loss 0.344300, forward nfe 14580, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 051, Runtime 13.014129, Loss 0.405173, forward nfe 14876, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 052, Runtime 13.352705, Loss 0.392976, forward nfe 15172, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 053, Runtime 13.159514, Loss 0.360953, forward nfe 15468, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 054, Runtime 13.293086, Loss 0.334853, forward nfe 15764, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 055, Runtime 13.326504, Loss 0.380035, forward nfe 16060, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 056, Runtime 13.303284, Loss 0.354891, forward nfe 16356, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 057, Runtime 13.476407, Loss 0.390753, forward nfe 16652, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 058, Runtime 13.568550, Loss 0.430803, forward nfe 16948, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 059, Runtime 13.486207, Loss 0.399337, forward nfe 17244, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 060, Runtime 13.500741, Loss 0.294078, forward nfe 17540, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 061, Runtime 13.595715, Loss 0.236944, forward nfe 17836, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 062, Runtime 13.654769, Loss 0.363269, forward nfe 18132, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 063, Runtime 13.572942, Loss 0.321269, forward nfe 18428, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 064, Runtime 13.705604, Loss 0.296084, forward nfe 18724, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 065, Runtime 13.808306, Loss 0.280657, forward nfe 19020, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 066, Runtime 13.787055, Loss 0.367299, forward nfe 19316, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 067, Runtime 13.871147, Loss 0.294607, forward nfe 19612, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 068, Runtime 13.860649, Loss 0.292580, forward nfe 19908, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 069, Runtime 13.666962, Loss 0.318951, forward nfe 20204, backward nfe 0, Train: 0.9214, Val: 0.8066, Test: 0.7706, Best time: 18.2948
Epoch: 070, Runtime 12.592014, Loss 0.376188, forward nfe 20500, backward nfe 0, Train: 0.9571, Val: 0.8103, Test: 0.7959, Best time: 18.2948
Epoch: 071, Runtime 9.647253, Loss 0.417065, forward nfe 20796, backward nfe 0, Train: 0.9571, Val: 0.8103, Test: 0.7959, Best time: 18.2948
Epoch: 072, Runtime 9.839795, Loss 0.360637, forward nfe 21092, backward nfe 0, Train: 0.9571, Val: 0.8103, Test: 0.7959, Best time: 18.2948
Epoch: 073, Runtime 9.791342, Loss 0.304672, forward nfe 21388, backward nfe 0, Train: 0.9571, Val: 0.8103, Test: 0.7959, Best time: 18.2948
Epoch: 074, Runtime 9.810567, Loss 0.285089, forward nfe 21684, backward nfe 0, Train: 0.9571, Val: 0.8103, Test: 0.7959, Best time: 18.2948
Epoch: 075, Runtime 10.302590, Loss 0.254570, forward nfe 21980, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 076, Runtime 9.530679, Loss 0.279963, forward nfe 22276, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 077, Runtime 9.818547, Loss 0.277285, forward nfe 22572, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 078, Runtime 9.729731, Loss 0.259428, forward nfe 22868, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 079, Runtime 9.732857, Loss 0.339324, forward nfe 23164, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 080, Runtime 9.558107, Loss 0.342081, forward nfe 23460, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 081, Runtime 9.347382, Loss 0.316815, forward nfe 23756, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 082, Runtime 9.336254, Loss 0.251773, forward nfe 24052, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 083, Runtime 9.896127, Loss 0.303683, forward nfe 24348, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 084, Runtime 10.197596, Loss 0.291120, forward nfe 24644, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 085, Runtime 10.307651, Loss 0.307353, forward nfe 24940, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 086, Runtime 10.516550, Loss 0.286262, forward nfe 25236, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 087, Runtime 10.094626, Loss 0.258573, forward nfe 25532, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 088, Runtime 10.402392, Loss 0.256314, forward nfe 25828, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 089, Runtime 10.080815, Loss 0.276198, forward nfe 26124, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 090, Runtime 9.846667, Loss 0.318257, forward nfe 26420, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 091, Runtime 10.253649, Loss 0.304814, forward nfe 26716, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 092, Runtime 10.110000, Loss 0.178235, forward nfe 27012, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 093, Runtime 10.353290, Loss 0.263464, forward nfe 27308, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 094, Runtime 10.230992, Loss 0.318524, forward nfe 27604, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 095, Runtime 10.442243, Loss 0.260945, forward nfe 27900, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 096, Runtime 10.180720, Loss 0.307814, forward nfe 28196, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 097, Runtime 10.503718, Loss 0.180055, forward nfe 28492, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 098, Runtime 11.558958, Loss 0.222441, forward nfe 28788, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
Epoch: 099, Runtime 11.561672, Loss 0.232510, forward nfe 29084, backward nfe 0, Train: 0.9571, Val: 0.8125, Test: 0.7787, Best time: 18.2948
best val accuracy 0.812500 with test accuracy 0.778680 at epoch 75 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8040609137055837
Entropy Threshold: 2 Test accuracy: 0.8
Entropy Threshold: 1.6 Test accuracy: 0.8010204081632653
Entropy Threshold: 1.5 Test accuracy: 0.8002049180327869
Entropy Threshold: 1.4 Test accuracy: 0.8084449021627188
Entropy Threshold: 1.3 Test accuracy: 0.8135416666666667
Entropy Threshold: 1.2 Test accuracy: 0.8109820485744457
Entropy Threshold: 1.1 Test accuracy: 0.8244274809160306
Entropy Threshold: 0.9 Test accuracy: 0.8406139315230224
Entropy Threshold: 0.8 Test accuracy: 0.8590852904820766
Entropy Threshold: 0.7 Test accuracy: 0.8602564102564103
Entropy Threshold: 0.6 Test accuracy: 0.8812154696132597
Entropy Threshold: 0.5 Test accuracy: 0.891970802919708
Entropy Threshold: 0.4 Test accuracy: 0.9071207430340558
Entropy Threshold: 0.3 Test accuracy: 0.9180602006688964
Entropy Threshold: 0.2 Test accuracy: 0.9225225225225225
Entropy Threshold: 0.1 Test accuracy: 0.9393939393939394
