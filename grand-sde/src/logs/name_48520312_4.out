[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 11.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 51.411744, Loss 10.620131, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.0463, Test: 0.0487, Best time: 18.2948
Epoch: 002, Runtime 89.787422, Loss 87.373535, forward nfe 372, backward nfe 0, Train: 0.1643, Val: 0.1206, Test: 0.1269, Best time: 18.2948
Epoch: 003, Runtime 26.475062, Loss 6.120701, forward nfe 668, backward nfe 0, Train: 0.1286, Val: 0.1368, Test: 0.1249, Best time: 18.2948
Epoch: 004, Runtime 26.706410, Loss 6.421358, forward nfe 964, backward nfe 0, Train: 0.1286, Val: 0.1750, Test: 0.1503, Best time: 18.2948
Epoch: 005, Runtime 25.993500, Loss 6.421088, forward nfe 1260, backward nfe 0, Train: 0.1286, Val: 0.1750, Test: 0.1503, Best time: 18.2948
Epoch: 006, Runtime 28.417746, Loss 6.227003, forward nfe 1556, backward nfe 0, Train: 0.1286, Val: 0.1809, Test: 0.1929, Best time: 18.2948
Epoch: 007, Runtime 27.590085, Loss 5.887956, forward nfe 1852, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 008, Runtime 26.128281, Loss 5.783780, forward nfe 2148, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 009, Runtime 27.810236, Loss 5.343915, forward nfe 2444, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 010, Runtime 29.258022, Loss 5.238237, forward nfe 2740, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 011, Runtime 30.712697, Loss 4.906192, forward nfe 3036, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 012, Runtime 31.561987, Loss 4.585037, forward nfe 3332, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 013, Runtime 32.649193, Loss 4.255904, forward nfe 3628, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 014, Runtime 33.889857, Loss 4.034023, forward nfe 3924, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 015, Runtime 35.174988, Loss 3.531526, forward nfe 4220, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 016, Runtime 35.020501, Loss 3.876092, forward nfe 4516, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 017, Runtime 37.319726, Loss 3.319432, forward nfe 4812, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 018, Runtime 37.745791, Loss 3.384919, forward nfe 5108, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 019, Runtime 38.131466, Loss 3.514942, forward nfe 5404, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 020, Runtime 38.990800, Loss 3.745446, forward nfe 5700, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 021, Runtime 39.637227, Loss 3.637237, forward nfe 5996, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 022, Runtime 26.429418, Loss 3.821849, forward nfe 6292, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 023, Runtime 26.028727, Loss 3.822500, forward nfe 6588, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 024, Runtime 27.456411, Loss 3.997696, forward nfe 6884, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 025, Runtime 29.308978, Loss 3.732217, forward nfe 7180, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 026, Runtime 29.563369, Loss 4.020972, forward nfe 7476, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 027, Runtime 31.106529, Loss 3.655323, forward nfe 7772, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 028, Runtime 32.384819, Loss 3.577016, forward nfe 8068, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 029, Runtime 32.470481, Loss 3.505163, forward nfe 8364, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 030, Runtime 33.920228, Loss 3.384034, forward nfe 8660, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 031, Runtime 34.894253, Loss 3.711375, forward nfe 8956, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 032, Runtime 35.653884, Loss 3.299802, forward nfe 9252, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 033, Runtime 25.979726, Loss 3.267441, forward nfe 9548, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 034, Runtime 23.896771, Loss 3.264715, forward nfe 9844, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 035, Runtime 25.195483, Loss 3.403589, forward nfe 10140, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 036, Runtime 25.329184, Loss 3.447090, forward nfe 10436, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 037, Runtime 25.171083, Loss 3.336404, forward nfe 10732, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 038, Runtime 25.071621, Loss 3.460920, forward nfe 11028, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 039, Runtime 25.196760, Loss 3.458555, forward nfe 11324, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 040, Runtime 25.363658, Loss 3.120416, forward nfe 11620, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 041, Runtime 26.567596, Loss 3.372802, forward nfe 11916, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 042, Runtime 27.455832, Loss 3.841492, forward nfe 12212, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 043, Runtime 28.805081, Loss 3.311415, forward nfe 12508, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 044, Runtime 29.293063, Loss 3.231198, forward nfe 12804, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 045, Runtime 30.886386, Loss 3.685827, forward nfe 13100, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 046, Runtime 30.345428, Loss 3.501005, forward nfe 13396, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 047, Runtime 31.404735, Loss 3.260850, forward nfe 13692, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 048, Runtime 31.540763, Loss 3.299718, forward nfe 13988, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 049, Runtime 31.700648, Loss 3.526408, forward nfe 14284, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 050, Runtime 30.968141, Loss 3.378112, forward nfe 14580, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 051, Runtime 30.992341, Loss 3.481884, forward nfe 14876, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 052, Runtime 31.460817, Loss 3.457259, forward nfe 15172, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 053, Runtime 31.787357, Loss 3.427379, forward nfe 15468, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 054, Runtime 34.855483, Loss 3.446138, forward nfe 15764, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 055, Runtime 37.134293, Loss 3.311277, forward nfe 16060, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 056, Runtime 37.042418, Loss 3.281861, forward nfe 16356, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 057, Runtime 33.750518, Loss 3.362560, forward nfe 16652, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 058, Runtime 25.485576, Loss 3.048266, forward nfe 16948, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 059, Runtime 25.899855, Loss 3.369857, forward nfe 17244, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 060, Runtime 27.212705, Loss 3.149762, forward nfe 17540, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 061, Runtime 27.304864, Loss 3.076673, forward nfe 17836, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 062, Runtime 27.830607, Loss 3.183902, forward nfe 18132, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 063, Runtime 28.657570, Loss 2.957043, forward nfe 18428, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 064, Runtime 29.690248, Loss 3.080823, forward nfe 18724, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 065, Runtime 30.784381, Loss 3.133241, forward nfe 19020, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 066, Runtime 31.610033, Loss 3.196774, forward nfe 19316, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 067, Runtime 32.636272, Loss 3.051342, forward nfe 19612, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 068, Runtime 33.644381, Loss 3.148935, forward nfe 19908, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 069, Runtime 34.565292, Loss 3.199252, forward nfe 20204, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 070, Runtime 35.296900, Loss 3.166851, forward nfe 20500, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 071, Runtime 35.832778, Loss 3.021033, forward nfe 20796, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 072, Runtime 36.129656, Loss 2.988561, forward nfe 21092, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 073, Runtime 36.365916, Loss 3.107754, forward nfe 21388, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 074, Runtime 41.075499, Loss 3.075005, forward nfe 21684, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 075, Runtime 43.227333, Loss 2.908760, forward nfe 21980, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 076, Runtime 43.624924, Loss 3.280459, forward nfe 22276, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 077, Runtime 44.164368, Loss 3.245027, forward nfe 22572, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 078, Runtime 38.910216, Loss 2.948662, forward nfe 22868, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 079, Runtime 29.784676, Loss 2.937038, forward nfe 23164, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 080, Runtime 30.890735, Loss 3.196479, forward nfe 23460, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 081, Runtime 31.956212, Loss 2.981174, forward nfe 23756, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 082, Runtime 33.477540, Loss 2.982423, forward nfe 24052, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 083, Runtime 35.021126, Loss 2.702784, forward nfe 24348, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 084, Runtime 34.613126, Loss 3.287000, forward nfe 24644, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 085, Runtime 34.845641, Loss 3.256428, forward nfe 24940, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 086, Runtime 36.139548, Loss 3.070248, forward nfe 25236, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 087, Runtime 37.169030, Loss 3.188951, forward nfe 25532, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 088, Runtime 38.161326, Loss 3.015738, forward nfe 25828, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 089, Runtime 39.280060, Loss 2.829153, forward nfe 26124, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 090, Runtime 39.814648, Loss 3.214842, forward nfe 26420, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 091, Runtime 40.605512, Loss 3.015277, forward nfe 26716, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 092, Runtime 41.743976, Loss 2.988064, forward nfe 27012, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 093, Runtime 42.430797, Loss 3.180173, forward nfe 27308, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 094, Runtime 42.845722, Loss 3.024924, forward nfe 27604, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 095, Runtime 42.924821, Loss 3.169824, forward nfe 27900, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 096, Runtime 43.377740, Loss 2.910641, forward nfe 28196, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 097, Runtime 43.356995, Loss 3.361592, forward nfe 28492, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 098, Runtime 36.958489, Loss 2.949590, forward nfe 28788, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
Epoch: 099, Runtime 30.524473, Loss 3.276751, forward nfe 29084, backward nfe 0, Train: 0.1286, Val: 0.2059, Test: 0.2112, Best time: 18.2948
best val accuracy 0.205882 with test accuracy 0.211168 at epoch 7 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.20913705583756345
Entropy Threshold: 2 Test accuracy: 0.19695431472081218
Entropy Threshold: 1.6 Test accuracy: 0.20880245649948823
Entropy Threshold: 1.5 Test accuracy: 0.21513513513513513
Entropy Threshold: 1.4 Test accuracy: 0.21224489795918366
Entropy Threshold: 1.3 Test accuracy: 0.2077922077922078
Entropy Threshold: 1.2 Test accuracy: 0.20476190476190476
Entropy Threshold: 1.1 Test accuracy: 0.125
Entropy Threshold: 0.9 Test accuracy: 0.3333333333333333
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
