[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 7.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 31.279655, Loss 4.569410, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1684, Test: 0.1594, Best time: 1.0000
Epoch: 002, Runtime 39.019363, Loss 20.599873, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1684, Test: 0.1594, Best time: 18.2948
Epoch: 003, Runtime 21.428099, Loss 4.541255, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1684, Test: 0.1594, Best time: 18.2948
Epoch: 004, Runtime 21.282292, Loss 4.048563, forward nfe 964, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 54.8843
Epoch: 005, Runtime 18.986103, Loss 3.207810, forward nfe 1260, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 006, Runtime 19.470387, Loss 3.106894, forward nfe 1556, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 007, Runtime 19.884386, Loss 3.076555, forward nfe 1852, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 008, Runtime 20.828431, Loss 3.165542, forward nfe 2148, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 009, Runtime 21.243817, Loss 3.229280, forward nfe 2444, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 010, Runtime 21.303665, Loss 3.060329, forward nfe 2740, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 011, Runtime 21.392828, Loss 3.045042, forward nfe 3036, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 012, Runtime 21.477549, Loss 3.186389, forward nfe 3332, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 013, Runtime 22.295692, Loss 2.911832, forward nfe 3628, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 014, Runtime 22.126780, Loss 2.786175, forward nfe 3924, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 015, Runtime 22.810701, Loss 2.760873, forward nfe 4220, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 016, Runtime 22.674493, Loss 3.048371, forward nfe 4516, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 017, Runtime 23.402105, Loss 2.921024, forward nfe 4812, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 018, Runtime 23.413078, Loss 2.898113, forward nfe 5108, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 019, Runtime 23.741758, Loss 3.080121, forward nfe 5404, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 020, Runtime 24.472622, Loss 2.903802, forward nfe 5700, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 021, Runtime 24.374081, Loss 2.906719, forward nfe 5996, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 022, Runtime 24.604477, Loss 2.883265, forward nfe 6292, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 023, Runtime 24.798945, Loss 2.963189, forward nfe 6588, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 024, Runtime 24.942118, Loss 3.016924, forward nfe 6884, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 025, Runtime 24.998368, Loss 2.939202, forward nfe 7180, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 026, Runtime 25.390424, Loss 2.673451, forward nfe 7476, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 027, Runtime 25.696181, Loss 2.906166, forward nfe 7772, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 028, Runtime 25.761315, Loss 2.771301, forward nfe 8068, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 029, Runtime 25.603007, Loss 2.753942, forward nfe 8364, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 030, Runtime 26.027256, Loss 2.587876, forward nfe 8660, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 031, Runtime 25.860410, Loss 2.755415, forward nfe 8956, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 032, Runtime 26.068593, Loss 2.703063, forward nfe 9252, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 033, Runtime 26.401537, Loss 2.750973, forward nfe 9548, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 034, Runtime 26.456075, Loss 2.967444, forward nfe 9844, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 035, Runtime 26.530414, Loss 2.688155, forward nfe 10140, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 036, Runtime 26.270809, Loss 2.883386, forward nfe 10436, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 037, Runtime 23.775027, Loss 2.603927, forward nfe 10732, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 038, Runtime 17.808777, Loss 2.784510, forward nfe 11028, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 039, Runtime 17.856509, Loss 2.603705, forward nfe 11324, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 040, Runtime 18.502618, Loss 2.603169, forward nfe 11620, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 041, Runtime 18.329968, Loss 2.697496, forward nfe 11916, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 042, Runtime 18.514599, Loss 2.494263, forward nfe 12212, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 043, Runtime 19.130800, Loss 2.629418, forward nfe 12508, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 044, Runtime 19.570999, Loss 2.671225, forward nfe 12804, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 045, Runtime 20.035740, Loss 2.733245, forward nfe 13100, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 046, Runtime 20.279921, Loss 2.681682, forward nfe 13396, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 047, Runtime 20.687360, Loss 2.536617, forward nfe 13692, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 048, Runtime 21.082119, Loss 2.489615, forward nfe 13988, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 049, Runtime 21.363869, Loss 2.677696, forward nfe 14284, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 050, Runtime 21.965069, Loss 2.768795, forward nfe 14580, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 051, Runtime 22.217766, Loss 2.734977, forward nfe 14876, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 052, Runtime 22.327331, Loss 2.665148, forward nfe 15172, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 053, Runtime 22.593128, Loss 2.489121, forward nfe 15468, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 054, Runtime 22.700124, Loss 2.612258, forward nfe 15764, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 055, Runtime 22.847805, Loss 2.578887, forward nfe 16060, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 056, Runtime 23.618244, Loss 2.749852, forward nfe 16356, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 057, Runtime 23.378584, Loss 2.579931, forward nfe 16652, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 058, Runtime 23.596841, Loss 2.549199, forward nfe 16948, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 059, Runtime 23.691531, Loss 2.786233, forward nfe 17244, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 060, Runtime 23.936727, Loss 2.667382, forward nfe 17540, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 061, Runtime 24.165714, Loss 2.772811, forward nfe 17836, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 062, Runtime 24.785552, Loss 2.596806, forward nfe 18132, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 063, Runtime 25.995050, Loss 2.584832, forward nfe 18428, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 064, Runtime 25.811668, Loss 2.429346, forward nfe 18724, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 065, Runtime 18.022242, Loss 2.485910, forward nfe 19020, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 066, Runtime 17.042409, Loss 2.594214, forward nfe 19316, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 067, Runtime 17.220487, Loss 2.535276, forward nfe 19612, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 068, Runtime 17.577357, Loss 2.346772, forward nfe 19908, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 069, Runtime 18.115052, Loss 2.393148, forward nfe 20204, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 070, Runtime 18.218555, Loss 2.655481, forward nfe 20500, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 071, Runtime 18.790971, Loss 2.429518, forward nfe 20796, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 072, Runtime 19.025201, Loss 2.521186, forward nfe 21092, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 073, Runtime 19.226525, Loss 2.379861, forward nfe 21388, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 074, Runtime 19.341311, Loss 2.537541, forward nfe 21684, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 075, Runtime 19.579171, Loss 2.541443, forward nfe 21980, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 076, Runtime 20.043232, Loss 2.339810, forward nfe 22276, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 077, Runtime 20.414315, Loss 2.480137, forward nfe 22572, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 078, Runtime 20.419000, Loss 2.427173, forward nfe 22868, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 079, Runtime 20.755468, Loss 2.416492, forward nfe 23164, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 080, Runtime 20.789151, Loss 2.407040, forward nfe 23460, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 081, Runtime 21.513606, Loss 2.479430, forward nfe 23756, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 082, Runtime 21.985979, Loss 2.479913, forward nfe 24052, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 083, Runtime 21.985720, Loss 2.516487, forward nfe 24348, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 084, Runtime 22.037525, Loss 2.560430, forward nfe 24644, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 085, Runtime 22.893346, Loss 2.299760, forward nfe 24940, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 086, Runtime 22.454855, Loss 2.595164, forward nfe 25236, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 087, Runtime 22.731041, Loss 2.427858, forward nfe 25532, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 088, Runtime 23.007342, Loss 2.385637, forward nfe 25828, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 089, Runtime 22.963222, Loss 2.476676, forward nfe 26124, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 090, Runtime 23.899453, Loss 2.411595, forward nfe 26420, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 091, Runtime 23.688284, Loss 2.517771, forward nfe 26716, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 092, Runtime 23.614808, Loss 2.431140, forward nfe 27012, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 093, Runtime 23.716910, Loss 2.440683, forward nfe 27308, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 094, Runtime 23.891818, Loss 2.314714, forward nfe 27604, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 095, Runtime 24.109956, Loss 2.395055, forward nfe 27900, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 096, Runtime 24.309148, Loss 2.270926, forward nfe 28196, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 097, Runtime 24.917262, Loss 2.204397, forward nfe 28492, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 098, Runtime 25.284049, Loss 2.573499, forward nfe 28788, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
Epoch: 099, Runtime 24.990474, Loss 2.498401, forward nfe 29084, backward nfe 0, Train: 0.1714, Val: 0.2912, Test: 0.2832, Best time: 18.2948
best val accuracy 0.291176 with test accuracy 0.283249 at epoch 4 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.28223350253807106
Entropy Threshold: 2 Test accuracy: 0.2781725888324873
Entropy Threshold: 1.6 Test accuracy: 0.28905109489051095
Entropy Threshold: 1.5 Test accuracy: 0.2652439024390244
Entropy Threshold: 1.4 Test accuracy: 0.3925233644859813
Entropy Threshold: 1.3 Test accuracy: 0.3333333333333333
Entropy Threshold: 1.2 Test accuracy: 0.5
Entropy Threshold: 1.1 Test accuracy: 0.5
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
