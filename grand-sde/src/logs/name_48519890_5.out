[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 2.5
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 15.594466, Loss 2.764108, forward nfe 76, backward nfe 0, Train: 0.3429, Val: 0.1463, Test: 0.1909, Best time: 1.0000
Epoch: 002, Runtime 15.744300, Loss 3.743641, forward nfe 372, backward nfe 0, Train: 0.5571, Val: 0.3596, Test: 0.3624, Best time: 2.0000
Epoch: 003, Runtime 14.947253, Loss 2.721826, forward nfe 668, backward nfe 0, Train: 0.5500, Val: 0.4566, Test: 0.4589, Best time: 3.0000
Epoch: 004, Runtime 14.760514, Loss 2.396509, forward nfe 964, backward nfe 0, Train: 0.5500, Val: 0.4566, Test: 0.4589, Best time: 18.2948
Epoch: 005, Runtime 15.179169, Loss 2.445998, forward nfe 1260, backward nfe 0, Train: 0.5500, Val: 0.4566, Test: 0.4589, Best time: 18.2948
Epoch: 006, Runtime 15.167088, Loss 2.115233, forward nfe 1556, backward nfe 0, Train: 0.6429, Val: 0.4868, Test: 0.5127, Best time: 4.0000
Epoch: 007, Runtime 14.847243, Loss 2.043009, forward nfe 1852, backward nfe 0, Train: 0.7000, Val: 0.5368, Test: 0.5614, Best time: 6.0000
Epoch: 008, Runtime 14.372532, Loss 1.926412, forward nfe 2148, backward nfe 0, Train: 0.7143, Val: 0.5882, Test: 0.6020, Best time: 4.0000
Epoch: 009, Runtime 14.185493, Loss 1.785291, forward nfe 2444, backward nfe 0, Train: 0.7357, Val: 0.6206, Test: 0.6406, Best time: 9.0000
Epoch: 010, Runtime 13.848508, Loss 1.719248, forward nfe 2740, backward nfe 0, Train: 0.7643, Val: 0.6316, Test: 0.6548, Best time: 10.0000
Epoch: 011, Runtime 13.810735, Loss 1.637275, forward nfe 3036, backward nfe 0, Train: 0.8214, Val: 0.6743, Test: 0.6924, Best time: 12.0000
Epoch: 012, Runtime 13.429559, Loss 1.475685, forward nfe 3332, backward nfe 0, Train: 0.8429, Val: 0.7441, Test: 0.7716, Best time: 30.0000
Epoch: 013, Runtime 13.426257, Loss 1.403448, forward nfe 3628, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 31.0000
Epoch: 014, Runtime 13.527440, Loss 1.180318, forward nfe 3924, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 015, Runtime 14.195864, Loss 1.272220, forward nfe 4220, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 016, Runtime 14.407974, Loss 1.114276, forward nfe 4516, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 017, Runtime 14.432812, Loss 0.930741, forward nfe 4812, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 018, Runtime 14.576131, Loss 1.027838, forward nfe 5108, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 019, Runtime 14.836065, Loss 0.905166, forward nfe 5404, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 020, Runtime 15.397454, Loss 0.831783, forward nfe 5700, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 021, Runtime 15.625812, Loss 0.821822, forward nfe 5996, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 022, Runtime 15.747844, Loss 0.666597, forward nfe 6292, backward nfe 0, Train: 0.8714, Val: 0.7750, Test: 0.7990, Best time: 18.2948
Epoch: 023, Runtime 16.545869, Loss 0.679582, forward nfe 6588, backward nfe 0, Train: 0.9071, Val: 0.7779, Test: 0.7939, Best time: 20.0000
Epoch: 024, Runtime 14.626994, Loss 0.667189, forward nfe 6884, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 16.0000
Epoch: 025, Runtime 14.495763, Loss 0.666568, forward nfe 7180, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 026, Runtime 14.891568, Loss 0.589345, forward nfe 7476, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 027, Runtime 14.641210, Loss 0.745164, forward nfe 7772, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 028, Runtime 14.948255, Loss 0.661733, forward nfe 8068, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 029, Runtime 15.122586, Loss 0.534821, forward nfe 8364, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 030, Runtime 15.139977, Loss 0.682161, forward nfe 8660, backward nfe 0, Train: 0.9000, Val: 0.7816, Test: 0.7878, Best time: 18.2948
Epoch: 031, Runtime 15.606005, Loss 0.541693, forward nfe 8956, backward nfe 0, Train: 0.9500, Val: 0.7956, Test: 0.8162, Best time: 19.0000
Epoch: 032, Runtime 14.868193, Loss 0.565131, forward nfe 9252, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 22.0000
Epoch: 033, Runtime 14.713321, Loss 0.689726, forward nfe 9548, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 034, Runtime 15.220877, Loss 0.557727, forward nfe 9844, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 035, Runtime 14.772972, Loss 0.525878, forward nfe 10140, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 036, Runtime 15.268620, Loss 0.543755, forward nfe 10436, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 037, Runtime 15.102784, Loss 0.469617, forward nfe 10732, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 038, Runtime 15.312516, Loss 0.572918, forward nfe 11028, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 039, Runtime 15.398528, Loss 0.480011, forward nfe 11324, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 040, Runtime 15.799397, Loss 0.468798, forward nfe 11620, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 041, Runtime 15.849769, Loss 0.507049, forward nfe 11916, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 042, Runtime 15.741648, Loss 0.518441, forward nfe 12212, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 043, Runtime 15.903467, Loss 0.481127, forward nfe 12508, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 044, Runtime 15.659225, Loss 0.567536, forward nfe 12804, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 045, Runtime 15.954875, Loss 0.405557, forward nfe 13100, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 046, Runtime 16.371682, Loss 0.510050, forward nfe 13396, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 047, Runtime 16.361157, Loss 0.463502, forward nfe 13692, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 048, Runtime 16.786286, Loss 0.611256, forward nfe 13988, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 049, Runtime 16.468356, Loss 0.477865, forward nfe 14284, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 050, Runtime 16.093213, Loss 0.396377, forward nfe 14580, backward nfe 0, Train: 0.9429, Val: 0.8059, Test: 0.8213, Best time: 18.2948
Epoch: 051, Runtime 16.555220, Loss 0.264354, forward nfe 14876, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 30.0000
Epoch: 052, Runtime 13.755180, Loss 0.591428, forward nfe 15172, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 053, Runtime 14.132913, Loss 0.360944, forward nfe 15468, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 054, Runtime 14.118200, Loss 0.557115, forward nfe 15764, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 055, Runtime 14.449701, Loss 0.343031, forward nfe 16060, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 056, Runtime 14.665120, Loss 0.451820, forward nfe 16356, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 057, Runtime 14.828639, Loss 0.465978, forward nfe 16652, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 058, Runtime 15.774090, Loss 0.443833, forward nfe 16948, backward nfe 0, Train: 0.9786, Val: 0.8066, Test: 0.8234, Best time: 18.2948
Epoch: 059, Runtime 15.696846, Loss 0.399268, forward nfe 17244, backward nfe 0, Train: 0.9857, Val: 0.8162, Test: 0.8254, Best time: 18.0000
Epoch: 060, Runtime 14.268725, Loss 0.376602, forward nfe 17540, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 27.0000
Epoch: 061, Runtime 14.286092, Loss 0.374432, forward nfe 17836, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 062, Runtime 14.688475, Loss 0.412278, forward nfe 18132, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 063, Runtime 14.265070, Loss 0.420646, forward nfe 18428, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 064, Runtime 14.684837, Loss 0.434857, forward nfe 18724, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 065, Runtime 14.526683, Loss 0.374521, forward nfe 19020, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 066, Runtime 14.677358, Loss 0.365804, forward nfe 19316, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 067, Runtime 14.734060, Loss 0.393082, forward nfe 19612, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 068, Runtime 14.714350, Loss 0.341605, forward nfe 19908, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 069, Runtime 15.591011, Loss 0.427128, forward nfe 20204, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 070, Runtime 14.923339, Loss 0.407151, forward nfe 20500, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 071, Runtime 15.536136, Loss 0.361627, forward nfe 20796, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 072, Runtime 15.284133, Loss 0.479220, forward nfe 21092, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 073, Runtime 15.640882, Loss 0.419002, forward nfe 21388, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 074, Runtime 15.997336, Loss 0.309647, forward nfe 21684, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 075, Runtime 15.580381, Loss 0.340380, forward nfe 21980, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 076, Runtime 16.098532, Loss 0.506593, forward nfe 22276, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 077, Runtime 15.800499, Loss 0.336575, forward nfe 22572, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 078, Runtime 15.894650, Loss 0.323344, forward nfe 22868, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 079, Runtime 16.135196, Loss 0.395635, forward nfe 23164, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 080, Runtime 16.245164, Loss 0.369966, forward nfe 23460, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 081, Runtime 16.668842, Loss 0.350280, forward nfe 23756, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 082, Runtime 16.452670, Loss 0.333158, forward nfe 24052, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 083, Runtime 16.470340, Loss 0.291607, forward nfe 24348, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 084, Runtime 16.566844, Loss 0.347093, forward nfe 24644, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 085, Runtime 16.931894, Loss 0.297030, forward nfe 24940, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 086, Runtime 17.044864, Loss 0.404907, forward nfe 25236, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 087, Runtime 16.792731, Loss 0.399476, forward nfe 25532, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 088, Runtime 17.105613, Loss 0.381337, forward nfe 25828, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 089, Runtime 17.014037, Loss 0.281268, forward nfe 26124, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 090, Runtime 17.052595, Loss 0.347434, forward nfe 26420, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 091, Runtime 17.103071, Loss 0.322134, forward nfe 26716, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 092, Runtime 16.752240, Loss 0.326838, forward nfe 27012, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 093, Runtime 16.960505, Loss 0.307198, forward nfe 27308, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 094, Runtime 16.989582, Loss 0.378149, forward nfe 27604, backward nfe 0, Train: 0.9786, Val: 0.8184, Test: 0.8365, Best time: 18.2948
Epoch: 095, Runtime 17.298337, Loss 0.331459, forward nfe 27900, backward nfe 0, Train: 0.9786, Val: 0.8235, Test: 0.8437, Best time: 52.0000
Epoch: 096, Runtime 13.492460, Loss 0.321313, forward nfe 28196, backward nfe 0, Train: 0.9786, Val: 0.8235, Test: 0.8437, Best time: 18.2948
Epoch: 097, Runtime 13.982398, Loss 0.297219, forward nfe 28492, backward nfe 0, Train: 0.9786, Val: 0.8235, Test: 0.8437, Best time: 18.2948
Epoch: 098, Runtime 13.855115, Loss 0.366655, forward nfe 28788, backward nfe 0, Train: 0.9786, Val: 0.8235, Test: 0.8437, Best time: 18.2948
Epoch: 099, Runtime 14.050122, Loss 0.341625, forward nfe 29084, backward nfe 0, Train: 0.9786, Val: 0.8235, Test: 0.8437, Best time: 18.2948
best val accuracy 0.823529 with test accuracy 0.843655 at epoch 95 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.849746192893401
Entropy Threshold: 2 Test accuracy: 0.8426395939086294
Entropy Threshold: 1.6 Test accuracy: 0.842479674796748
Entropy Threshold: 1.5 Test accuracy: 0.8448979591836735
Entropy Threshold: 1.4 Test accuracy: 0.8489208633093526
Entropy Threshold: 1.3 Test accuracy: 0.85625
Entropy Threshold: 1.2 Test accuracy: 0.8514225500526871
Entropy Threshold: 1.1 Test accuracy: 0.8624733475479744
Entropy Threshold: 0.9 Test accuracy: 0.8882488479262672
Entropy Threshold: 0.8 Test accuracy: 0.8939393939393939
Entropy Threshold: 0.7 Test accuracy: 0.8986402966625463
Entropy Threshold: 0.6 Test accuracy: 0.9108527131782945
Entropy Threshold: 0.5 Test accuracy: 0.931787175989086
Entropy Threshold: 0.4 Test accuracy: 0.9413489736070382
Entropy Threshold: 0.3 Test accuracy: 0.9485627836611196
Entropy Threshold: 0.2 Test accuracy: 0.9567307692307693
Entropy Threshold: 0.1 Test accuracy: 0.9628975265017667
