[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 13.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 73.605281, Loss 17.852331, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 14.0000
Epoch: 002, Runtime 154.940842, Loss 197.131912, forward nfe 372, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 003, Runtime 45.534916, Loss 14.944719, forward nfe 668, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 004, Runtime 40.049838, Loss 13.578818, forward nfe 964, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 005, Runtime 40.100176, Loss 11.981794, forward nfe 1260, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 006, Runtime 41.712479, Loss 9.668826, forward nfe 1556, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 007, Runtime 42.723470, Loss 7.275587, forward nfe 1852, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 008, Runtime 43.206306, Loss 6.634433, forward nfe 2148, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 009, Runtime 41.742726, Loss 7.040711, forward nfe 2444, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 010, Runtime 32.964424, Loss 6.445089, forward nfe 2740, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 011, Runtime 33.129506, Loss 6.775394, forward nfe 3036, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 012, Runtime 33.531793, Loss 5.956556, forward nfe 3332, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 013, Runtime 33.966734, Loss 5.203135, forward nfe 3628, backward nfe 0, Train: 0.1500, Val: 0.3044, Test: 0.2873, Best time: 18.2948
Epoch: 014, Runtime 34.754727, Loss 4.434934, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3051, Test: 0.2944, Best time: 2.0000
Epoch: 015, Runtime 30.235360, Loss 4.054541, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3051, Test: 0.2944, Best time: 18.2948
Epoch: 016, Runtime 28.802565, Loss 4.047859, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3059, Test: 0.2924, Best time: 6.0000
Epoch: 017, Runtime 28.454045, Loss 3.852472, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 4.0000
Epoch: 018, Runtime 27.845680, Loss 4.065802, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 019, Runtime 28.163381, Loss 4.276641, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 020, Runtime 30.169864, Loss 4.256125, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 021, Runtime 30.560861, Loss 4.157667, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 022, Runtime 32.516229, Loss 3.972524, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 023, Runtime 33.175415, Loss 4.386528, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 024, Runtime 33.081766, Loss 4.018044, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 025, Runtime 33.411340, Loss 3.929125, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 026, Runtime 34.518095, Loss 4.006559, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 027, Runtime 35.298418, Loss 3.554470, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 028, Runtime 36.277309, Loss 3.688718, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 029, Runtime 37.754565, Loss 3.772952, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 030, Runtime 38.204585, Loss 3.881310, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 031, Runtime 34.867473, Loss 3.791989, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 032, Runtime 26.176405, Loss 3.463835, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 033, Runtime 27.595416, Loss 3.591283, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 034, Runtime 28.860089, Loss 3.393731, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 035, Runtime 30.436965, Loss 3.496307, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 036, Runtime 31.611182, Loss 3.515291, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 037, Runtime 32.322115, Loss 3.693090, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 038, Runtime 33.115889, Loss 3.886271, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 039, Runtime 33.836599, Loss 3.487828, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 040, Runtime 35.624770, Loss 3.512580, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 041, Runtime 36.565335, Loss 3.836873, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 042, Runtime 37.225027, Loss 3.719383, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 043, Runtime 37.653158, Loss 3.456281, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 044, Runtime 38.072495, Loss 3.616205, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 045, Runtime 38.401700, Loss 3.647828, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 046, Runtime 38.626717, Loss 3.247919, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 047, Runtime 38.325141, Loss 3.748852, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 048, Runtime 39.878993, Loss 3.266433, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 049, Runtime 41.369797, Loss 3.349000, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 050, Runtime 40.861071, Loss 3.775131, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 051, Runtime 34.619939, Loss 3.295844, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 052, Runtime 25.703812, Loss 3.505641, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 053, Runtime 26.919089, Loss 3.516093, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 054, Runtime 28.182603, Loss 3.721750, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 055, Runtime 29.750023, Loss 3.313498, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 056, Runtime 30.376188, Loss 3.668255, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 057, Runtime 32.191022, Loss 3.569533, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 058, Runtime 32.963366, Loss 3.651880, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 059, Runtime 33.035160, Loss 3.482701, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 060, Runtime 33.999695, Loss 3.971329, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 061, Runtime 35.111129, Loss 3.345238, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 062, Runtime 35.607264, Loss 3.611905, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 063, Runtime 36.386960, Loss 3.327117, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 064, Runtime 37.030681, Loss 3.341374, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 065, Runtime 38.005450, Loss 3.685250, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 066, Runtime 38.898799, Loss 3.417660, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 067, Runtime 39.562115, Loss 3.481045, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 068, Runtime 39.363316, Loss 3.445538, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 069, Runtime 40.142294, Loss 3.548006, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 070, Runtime 40.499530, Loss 3.519531, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 071, Runtime 35.010686, Loss 3.399461, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 072, Runtime 25.681660, Loss 3.278137, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 073, Runtime 25.923907, Loss 3.476537, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 074, Runtime 27.642202, Loss 3.446301, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 075, Runtime 28.226633, Loss 3.602178, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 076, Runtime 29.154336, Loss 3.246624, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 077, Runtime 31.146211, Loss 3.477589, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 078, Runtime 31.876394, Loss 3.054473, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 079, Runtime 33.228382, Loss 3.582733, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 080, Runtime 33.823599, Loss 3.007442, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 081, Runtime 34.927581, Loss 3.622234, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 082, Runtime 35.859437, Loss 3.353533, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 083, Runtime 36.275691, Loss 3.365783, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 084, Runtime 36.734730, Loss 3.458322, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 085, Runtime 37.848168, Loss 3.370200, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 086, Runtime 37.072108, Loss 3.381590, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 087, Runtime 37.411070, Loss 3.501883, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 088, Runtime 33.369923, Loss 3.271824, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 089, Runtime 24.917493, Loss 3.177448, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 090, Runtime 25.990378, Loss 3.555903, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 091, Runtime 26.939777, Loss 3.630004, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 092, Runtime 28.238607, Loss 3.255785, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 093, Runtime 29.682616, Loss 3.379045, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 094, Runtime 30.432358, Loss 3.421063, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 095, Runtime 31.662301, Loss 3.227744, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 096, Runtime 32.111285, Loss 3.295782, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 097, Runtime 33.445632, Loss 3.422562, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 098, Runtime 34.048777, Loss 3.331103, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
Epoch: 099, Runtime 35.806148, Loss 3.539314, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2944, Best time: 18.2948
best val accuracy 0.306618 with test accuracy 0.294416 at epoch 17 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.12791878172588833
Entropy Threshold: 2 Test accuracy: 0.11979695431472082
Entropy Threshold: 1.6 Test accuracy: 0.11488250652741515
Entropy Threshold: 1.5 Test accuracy: 0.10572687224669604
Entropy Threshold: 1.4 Test accuracy: 0.14601769911504425
Entropy Threshold: 1.3 Test accuracy: 0.10091743119266056
Entropy Threshold: 1.2 Test accuracy: 0.03225806451612903
Entropy Threshold: 1.1 Test accuracy: 0.16666666666666666
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: None
