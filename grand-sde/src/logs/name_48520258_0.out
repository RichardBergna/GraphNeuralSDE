[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 6.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 27.687317, Loss 3.836329, forward nfe 76, backward nfe 0, Train: 0.1786, Val: 0.1279, Test: 0.1249, Best time: 18.2948
Epoch: 002, Runtime 43.017915, Loss 15.439363, forward nfe 372, backward nfe 0, Train: 0.1786, Val: 0.1279, Test: 0.1249, Best time: 18.2948
Epoch: 003, Runtime 22.452041, Loss 4.571137, forward nfe 668, backward nfe 0, Train: 0.1786, Val: 0.1279, Test: 0.1249, Best time: 18.2948
Epoch: 004, Runtime 22.217039, Loss 4.138647, forward nfe 964, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 7.0000
Epoch: 005, Runtime 19.420821, Loss 4.011396, forward nfe 1260, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 006, Runtime 19.722816, Loss 3.582867, forward nfe 1556, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 007, Runtime 20.487533, Loss 3.606812, forward nfe 1852, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 008, Runtime 21.404551, Loss 3.611281, forward nfe 2148, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 009, Runtime 21.716484, Loss 3.482193, forward nfe 2444, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 010, Runtime 22.056331, Loss 3.511365, forward nfe 2740, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 011, Runtime 22.581485, Loss 3.451073, forward nfe 3036, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 012, Runtime 23.668718, Loss 3.701471, forward nfe 3332, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 013, Runtime 23.879455, Loss 3.422203, forward nfe 3628, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 014, Runtime 23.869678, Loss 3.241315, forward nfe 3924, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 015, Runtime 24.289160, Loss 3.311259, forward nfe 4220, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 016, Runtime 24.894643, Loss 3.102214, forward nfe 4516, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 017, Runtime 24.982627, Loss 3.205912, forward nfe 4812, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 018, Runtime 25.396665, Loss 3.018386, forward nfe 5108, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 019, Runtime 25.670254, Loss 2.930209, forward nfe 5404, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 020, Runtime 26.500264, Loss 2.938743, forward nfe 5700, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 021, Runtime 26.348159, Loss 2.845792, forward nfe 5996, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 022, Runtime 26.164718, Loss 2.940770, forward nfe 6292, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 023, Runtime 26.272714, Loss 2.833185, forward nfe 6588, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 024, Runtime 27.032134, Loss 3.000948, forward nfe 6884, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 025, Runtime 26.970876, Loss 3.024906, forward nfe 7180, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 026, Runtime 24.853084, Loss 2.814315, forward nfe 7476, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 027, Runtime 25.140254, Loss 2.525087, forward nfe 7772, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 028, Runtime 25.323117, Loss 2.627552, forward nfe 8068, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 029, Runtime 25.172107, Loss 2.796525, forward nfe 8364, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 030, Runtime 25.122621, Loss 2.589260, forward nfe 8660, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 031, Runtime 25.217562, Loss 2.456984, forward nfe 8956, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 032, Runtime 25.135613, Loss 2.691182, forward nfe 9252, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 033, Runtime 25.652433, Loss 2.686854, forward nfe 9548, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 034, Runtime 25.971019, Loss 2.670828, forward nfe 9844, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 035, Runtime 25.781461, Loss 2.645844, forward nfe 10140, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 036, Runtime 17.769800, Loss 2.569300, forward nfe 10436, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 037, Runtime 17.034363, Loss 2.554075, forward nfe 10732, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 038, Runtime 17.258371, Loss 2.768795, forward nfe 11028, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 039, Runtime 17.564008, Loss 2.745214, forward nfe 11324, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 040, Runtime 18.048722, Loss 2.615890, forward nfe 11620, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 041, Runtime 18.353561, Loss 2.502272, forward nfe 11916, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 042, Runtime 18.465292, Loss 2.462658, forward nfe 12212, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 043, Runtime 18.702309, Loss 2.655149, forward nfe 12508, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 044, Runtime 19.246666, Loss 2.449889, forward nfe 12804, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 045, Runtime 19.108877, Loss 2.633297, forward nfe 13100, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 046, Runtime 19.416845, Loss 2.596647, forward nfe 13396, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 047, Runtime 19.806078, Loss 2.622943, forward nfe 13692, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 048, Runtime 19.719782, Loss 2.619641, forward nfe 13988, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 049, Runtime 20.091904, Loss 2.573980, forward nfe 14284, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 050, Runtime 20.607709, Loss 2.418681, forward nfe 14580, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 051, Runtime 20.452226, Loss 2.392025, forward nfe 14876, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 052, Runtime 20.809861, Loss 2.690304, forward nfe 15172, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 053, Runtime 21.232033, Loss 2.437718, forward nfe 15468, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 054, Runtime 21.418975, Loss 2.603898, forward nfe 15764, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 055, Runtime 21.690780, Loss 2.674009, forward nfe 16060, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 056, Runtime 22.050753, Loss 2.522710, forward nfe 16356, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 057, Runtime 22.121733, Loss 2.577443, forward nfe 16652, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 058, Runtime 22.147640, Loss 2.588957, forward nfe 16948, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 059, Runtime 22.451975, Loss 2.459799, forward nfe 17244, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 060, Runtime 22.562494, Loss 2.537839, forward nfe 17540, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 061, Runtime 22.883297, Loss 2.600724, forward nfe 17836, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 062, Runtime 22.960768, Loss 2.407717, forward nfe 18132, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 063, Runtime 23.007488, Loss 2.404289, forward nfe 18428, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 064, Runtime 23.373203, Loss 2.358707, forward nfe 18724, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 065, Runtime 23.651432, Loss 2.358676, forward nfe 19020, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 066, Runtime 23.770188, Loss 2.479451, forward nfe 19316, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 067, Runtime 23.822268, Loss 2.422062, forward nfe 19612, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 068, Runtime 23.913055, Loss 2.648921, forward nfe 19908, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 069, Runtime 23.996975, Loss 2.517015, forward nfe 20204, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 070, Runtime 24.362010, Loss 2.433640, forward nfe 20500, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 071, Runtime 24.418015, Loss 2.525820, forward nfe 20796, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 072, Runtime 24.372128, Loss 2.575076, forward nfe 21092, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 073, Runtime 24.557603, Loss 2.408906, forward nfe 21388, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 074, Runtime 24.207156, Loss 2.491173, forward nfe 21684, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 075, Runtime 24.335954, Loss 2.414492, forward nfe 21980, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 076, Runtime 24.967860, Loss 2.517094, forward nfe 22276, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 077, Runtime 24.644425, Loss 2.408733, forward nfe 22572, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 078, Runtime 24.633648, Loss 2.432108, forward nfe 22868, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 079, Runtime 25.605552, Loss 2.358985, forward nfe 23164, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 080, Runtime 29.039762, Loss 2.425010, forward nfe 23460, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 081, Runtime 28.629920, Loss 2.329654, forward nfe 23756, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 082, Runtime 29.371233, Loss 2.386166, forward nfe 24052, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 083, Runtime 29.300932, Loss 2.514170, forward nfe 24348, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 084, Runtime 29.411262, Loss 2.384757, forward nfe 24644, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 085, Runtime 29.543633, Loss 2.404896, forward nfe 24940, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 086, Runtime 29.555244, Loss 2.392457, forward nfe 25236, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 087, Runtime 29.801259, Loss 2.342676, forward nfe 25532, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 088, Runtime 30.060280, Loss 2.420771, forward nfe 25828, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 089, Runtime 30.023500, Loss 2.460325, forward nfe 26124, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 090, Runtime 29.997905, Loss 2.314140, forward nfe 26420, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 091, Runtime 26.701373, Loss 2.271955, forward nfe 26716, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 092, Runtime 20.973442, Loss 2.482456, forward nfe 27012, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 093, Runtime 21.222363, Loss 2.403955, forward nfe 27308, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 094, Runtime 21.619108, Loss 2.358911, forward nfe 27604, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 095, Runtime 22.767999, Loss 2.375709, forward nfe 27900, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 096, Runtime 23.115322, Loss 2.340066, forward nfe 28196, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 097, Runtime 23.659905, Loss 2.257313, forward nfe 28492, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 098, Runtime 24.642647, Loss 2.435192, forward nfe 28788, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
Epoch: 099, Runtime 25.148443, Loss 2.365882, forward nfe 29084, backward nfe 0, Train: 0.1286, Val: 0.2757, Test: 0.2650, Best time: 18.2948
best val accuracy 0.275735 with test accuracy 0.264975 at epoch 4 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.15126903553299492
Entropy Threshold: 2 Test accuracy: 0.14517766497461929
Entropy Threshold: 1.6 Test accuracy: 0.1377497371188223
Entropy Threshold: 1.5 Test accuracy: 0.13598901098901098
Entropy Threshold: 1.4 Test accuracy: 0.1557632398753894
Entropy Threshold: 1.3 Test accuracy: 0.17582417582417584
Entropy Threshold: 1.2 Test accuracy: 0.125
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
