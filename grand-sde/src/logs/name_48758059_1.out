[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 7.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 11.242986, Loss 5.480754, forward nfe 76, backward nfe 0, Train: 0.4857, Val: 0.2882, Test: 0.3107, Best time: 1.0000
Epoch: 002, Runtime 10.703580, Loss 6.709144, forward nfe 372, backward nfe 0, Train: 0.5214, Val: 0.4787, Test: 0.4660, Best time: 2.0000
Epoch: 003, Runtime 10.712106, Loss 4.807140, forward nfe 668, backward nfe 0, Train: 0.5214, Val: 0.4787, Test: 0.4660, Best time: 18.2948
Epoch: 004, Runtime 11.082791, Loss 5.123389, forward nfe 964, backward nfe 0, Train: 0.5571, Val: 0.5691, Test: 0.5655, Best time: 5.0000
Epoch: 005, Runtime 10.608731, Loss 4.642505, forward nfe 1260, backward nfe 0, Train: 0.6214, Val: 0.6140, Test: 0.5949, Best time: 7.0000
Epoch: 006, Runtime 10.808563, Loss 3.853949, forward nfe 1556, backward nfe 0, Train: 0.7286, Val: 0.6162, Test: 0.6020, Best time: 4.0000
Epoch: 007, Runtime 10.301117, Loss 3.447410, forward nfe 1852, backward nfe 0, Train: 0.8143, Val: 0.6551, Test: 0.6772, Best time: 4.0000
Epoch: 008, Runtime 10.512804, Loss 3.096967, forward nfe 2148, backward nfe 0, Train: 0.8286, Val: 0.6684, Test: 0.6964, Best time: 4.0000
Epoch: 009, Runtime 10.229490, Loss 3.137400, forward nfe 2444, backward nfe 0, Train: 0.8286, Val: 0.6684, Test: 0.6964, Best time: 18.2948
Epoch: 010, Runtime 10.399880, Loss 2.658922, forward nfe 2740, backward nfe 0, Train: 0.8286, Val: 0.6684, Test: 0.6964, Best time: 18.2948
Epoch: 011, Runtime 10.417742, Loss 2.828996, forward nfe 3036, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 4.0000
Epoch: 012, Runtime 9.754051, Loss 2.721370, forward nfe 3332, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 013, Runtime 9.994069, Loss 2.466121, forward nfe 3628, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 014, Runtime 9.624615, Loss 2.124320, forward nfe 3924, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 015, Runtime 9.847876, Loss 2.190799, forward nfe 4220, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 016, Runtime 9.882357, Loss 2.232191, forward nfe 4516, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 017, Runtime 9.569979, Loss 2.010307, forward nfe 4812, backward nfe 0, Train: 0.7571, Val: 0.6956, Test: 0.6914, Best time: 18.2948
Epoch: 018, Runtime 10.057504, Loss 1.850735, forward nfe 5108, backward nfe 0, Train: 0.8286, Val: 0.7250, Test: 0.7340, Best time: 5.0000
Epoch: 019, Runtime 9.370725, Loss 1.871082, forward nfe 5404, backward nfe 0, Train: 0.8571, Val: 0.7610, Test: 0.7766, Best time: 12.0000
Epoch: 020, Runtime 9.348823, Loss 1.952566, forward nfe 5700, backward nfe 0, Train: 0.8429, Val: 0.7743, Test: 0.7838, Best time: 13.0000
Epoch: 021, Runtime 9.396422, Loss 1.879714, forward nfe 5996, backward nfe 0, Train: 0.8429, Val: 0.7743, Test: 0.7838, Best time: 18.2948
Epoch: 022, Runtime 9.924967, Loss 1.789158, forward nfe 6292, backward nfe 0, Train: 0.8429, Val: 0.7743, Test: 0.7838, Best time: 18.2948
Epoch: 023, Runtime 9.559601, Loss 1.745621, forward nfe 6588, backward nfe 0, Train: 0.8429, Val: 0.7743, Test: 0.7838, Best time: 18.2948
Epoch: 024, Runtime 9.670635, Loss 1.847762, forward nfe 6884, backward nfe 0, Train: 0.8429, Val: 0.7743, Test: 0.7838, Best time: 18.2948
Epoch: 025, Runtime 9.921994, Loss 1.523210, forward nfe 7180, backward nfe 0, Train: 0.8500, Val: 0.7794, Test: 0.7685, Best time: 11.0000
Epoch: 026, Runtime 9.662273, Loss 1.511781, forward nfe 7476, backward nfe 0, Train: 0.8571, Val: 0.7831, Test: 0.8000, Best time: 11.0000
Epoch: 027, Runtime 9.373531, Loss 1.607921, forward nfe 7772, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 10.0000
Epoch: 028, Runtime 9.258158, Loss 1.589441, forward nfe 8068, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 029, Runtime 9.766852, Loss 1.330963, forward nfe 8364, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 030, Runtime 9.484931, Loss 1.519655, forward nfe 8660, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 031, Runtime 9.698952, Loss 1.633705, forward nfe 8956, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 032, Runtime 9.788399, Loss 1.510094, forward nfe 9252, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 033, Runtime 10.017082, Loss 1.363122, forward nfe 9548, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 034, Runtime 10.706450, Loss 1.532234, forward nfe 9844, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 035, Runtime 10.090061, Loss 1.398387, forward nfe 10140, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 036, Runtime 10.947698, Loss 1.369720, forward nfe 10436, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 037, Runtime 10.575207, Loss 1.406624, forward nfe 10732, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 038, Runtime 10.713305, Loss 1.515252, forward nfe 11028, backward nfe 0, Train: 0.8643, Val: 0.7897, Test: 0.8061, Best time: 18.2948
Epoch: 039, Runtime 11.157501, Loss 1.428507, forward nfe 11324, backward nfe 0, Train: 0.8714, Val: 0.8007, Test: 0.8020, Best time: 41.0000
Epoch: 040, Runtime 9.828965, Loss 1.213793, forward nfe 11620, backward nfe 0, Train: 0.9000, Val: 0.8147, Test: 0.8142, Best time: 39.0000
Epoch: 041, Runtime 9.930551, Loss 1.266575, forward nfe 11916, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 40.0000
Epoch: 042, Runtime 9.813632, Loss 1.348706, forward nfe 12212, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 043, Runtime 10.371790, Loss 1.268545, forward nfe 12508, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 044, Runtime 9.903066, Loss 1.153024, forward nfe 12804, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 045, Runtime 10.177726, Loss 1.143845, forward nfe 13100, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 046, Runtime 10.312463, Loss 1.151085, forward nfe 13396, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 047, Runtime 10.191699, Loss 1.226051, forward nfe 13692, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 048, Runtime 10.609083, Loss 1.148246, forward nfe 13988, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 049, Runtime 10.764388, Loss 1.033407, forward nfe 14284, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 050, Runtime 11.719137, Loss 1.276547, forward nfe 14580, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 051, Runtime 11.652523, Loss 1.184129, forward nfe 14876, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 052, Runtime 11.841809, Loss 1.117145, forward nfe 15172, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 053, Runtime 12.596321, Loss 1.251209, forward nfe 15468, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 054, Runtime 13.230652, Loss 1.166911, forward nfe 15764, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 055, Runtime 13.610902, Loss 1.181733, forward nfe 16060, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 056, Runtime 13.204838, Loss 1.032369, forward nfe 16356, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 057, Runtime 14.068414, Loss 1.170279, forward nfe 16652, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 058, Runtime 14.088442, Loss 1.156567, forward nfe 16948, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 059, Runtime 14.047700, Loss 1.141067, forward nfe 17244, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 060, Runtime 14.725289, Loss 0.848940, forward nfe 17540, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 061, Runtime 14.619049, Loss 1.036729, forward nfe 17836, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 062, Runtime 15.045118, Loss 1.033926, forward nfe 18132, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 063, Runtime 14.977236, Loss 0.880685, forward nfe 18428, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 064, Runtime 15.075771, Loss 1.111040, forward nfe 18724, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 065, Runtime 15.164423, Loss 0.991399, forward nfe 19020, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 066, Runtime 15.915427, Loss 0.942953, forward nfe 19316, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 067, Runtime 16.013836, Loss 0.816897, forward nfe 19612, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 068, Runtime 16.674122, Loss 0.846226, forward nfe 19908, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 069, Runtime 16.702445, Loss 0.891344, forward nfe 20204, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 070, Runtime 17.180546, Loss 0.937807, forward nfe 20500, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 071, Runtime 16.601226, Loss 0.720322, forward nfe 20796, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 072, Runtime 16.890067, Loss 0.727089, forward nfe 21092, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 073, Runtime 16.891277, Loss 0.970525, forward nfe 21388, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 074, Runtime 18.049496, Loss 0.798195, forward nfe 21684, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 075, Runtime 17.563865, Loss 0.958032, forward nfe 21980, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 076, Runtime 18.072760, Loss 0.856577, forward nfe 22276, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 077, Runtime 18.362068, Loss 0.979779, forward nfe 22572, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 078, Runtime 18.354336, Loss 0.795141, forward nfe 22868, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 079, Runtime 18.594214, Loss 0.899726, forward nfe 23164, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 080, Runtime 18.658897, Loss 1.069085, forward nfe 23460, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 081, Runtime 18.033565, Loss 0.757954, forward nfe 23756, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 082, Runtime 18.252166, Loss 0.764484, forward nfe 24052, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 083, Runtime 17.887751, Loss 0.801183, forward nfe 24348, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 084, Runtime 18.368324, Loss 0.774903, forward nfe 24644, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 085, Runtime 18.358377, Loss 0.978992, forward nfe 24940, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 086, Runtime 18.511804, Loss 0.738514, forward nfe 25236, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 087, Runtime 18.745669, Loss 0.778625, forward nfe 25532, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 088, Runtime 18.864989, Loss 0.842873, forward nfe 25828, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 089, Runtime 18.750094, Loss 0.683501, forward nfe 26124, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 090, Runtime 19.145916, Loss 0.753537, forward nfe 26420, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 091, Runtime 14.317017, Loss 0.743871, forward nfe 26716, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 092, Runtime 13.704596, Loss 0.966411, forward nfe 27012, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 093, Runtime 12.947491, Loss 0.770855, forward nfe 27308, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 094, Runtime 13.690325, Loss 0.718110, forward nfe 27604, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 095, Runtime 13.312935, Loss 0.670835, forward nfe 27900, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 096, Runtime 13.632762, Loss 0.552542, forward nfe 28196, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 097, Runtime 13.315959, Loss 0.752410, forward nfe 28492, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 098, Runtime 13.652970, Loss 0.782613, forward nfe 28788, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
Epoch: 099, Runtime 13.320731, Loss 0.714156, forward nfe 29084, backward nfe 0, Train: 0.9071, Val: 0.8346, Test: 0.8254, Best time: 18.2948
best val accuracy 0.834559 with test accuracy 0.825381 at epoch 41 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.817258883248731
Entropy Threshold: 2 Test accuracy: 0.8071065989847716
Entropy Threshold: 1.6 Test accuracy: 0.8535414165666266
Entropy Threshold: 1.5 Test accuracy: 0.8629242819843342
Entropy Threshold: 1.4 Test accuracy: 0.8826086956521739
Entropy Threshold: 1.3 Test accuracy: 0.8881685575364667
Entropy Threshold: 1.2 Test accuracy: 0.9117117117117117
Entropy Threshold: 1.1 Test accuracy: 0.9259259259259259
Entropy Threshold: 0.9 Test accuracy: 0.941031941031941
Entropy Threshold: 0.8 Test accuracy: 0.9534246575342465
Entropy Threshold: 0.7 Test accuracy: 0.953125
Entropy Threshold: 0.6 Test accuracy: 0.9537366548042705
Entropy Threshold: 0.5 Test accuracy: 0.9707112970711297
Entropy Threshold: 0.4 Test accuracy: 0.968421052631579
Entropy Threshold: 0.3 Test accuracy: 0.9640718562874252
Entropy Threshold: 0.2 Test accuracy: 0.9621212121212122
Entropy Threshold: 0.1 Test accuracy: 0.979381443298969
