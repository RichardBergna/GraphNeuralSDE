[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 2.5
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 14.382858, Loss 2.907742, forward nfe 76, backward nfe 0, Train: 0.3857, Val: 0.2897, Test: 0.2701, Best time: 1.0000
Epoch: 002, Runtime 14.614681, Loss 3.278689, forward nfe 372, backward nfe 0, Train: 0.6214, Val: 0.3956, Test: 0.3990, Best time: 5.0000
Epoch: 003, Runtime 13.903676, Loss 2.714394, forward nfe 668, backward nfe 0, Train: 0.5214, Val: 0.3993, Test: 0.3929, Best time: 8.0000
Epoch: 004, Runtime 13.168466, Loss 2.228741, forward nfe 964, backward nfe 0, Train: 0.5857, Val: 0.4485, Test: 0.4508, Best time: 3.0000
Epoch: 005, Runtime 13.314930, Loss 2.062362, forward nfe 1260, backward nfe 0, Train: 0.6429, Val: 0.4765, Test: 0.4853, Best time: 4.0000
Epoch: 006, Runtime 12.779845, Loss 1.809298, forward nfe 1556, backward nfe 0, Train: 0.6857, Val: 0.5096, Test: 0.5269, Best time: 9.0000
Epoch: 007, Runtime 12.486088, Loss 1.606664, forward nfe 1852, backward nfe 0, Train: 0.7714, Val: 0.5699, Test: 0.5980, Best time: 15.0000
Epoch: 008, Runtime 12.579021, Loss 1.473046, forward nfe 2148, backward nfe 0, Train: 0.8071, Val: 0.6419, Test: 0.6650, Best time: 24.0000
Epoch: 009, Runtime 12.597102, Loss 1.333537, forward nfe 2444, backward nfe 0, Train: 0.8286, Val: 0.6765, Test: 0.7005, Best time: 23.0000
Epoch: 010, Runtime 12.416554, Loss 1.260285, forward nfe 2740, backward nfe 0, Train: 0.8500, Val: 0.7206, Test: 0.7269, Best time: 20.0000
Epoch: 011, Runtime 12.671492, Loss 1.200159, forward nfe 3036, backward nfe 0, Train: 0.8786, Val: 0.7485, Test: 0.7553, Best time: 17.0000
Epoch: 012, Runtime 12.421161, Loss 1.025475, forward nfe 3332, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 22.0000
Epoch: 013, Runtime 12.686648, Loss 0.934476, forward nfe 3628, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 014, Runtime 13.122262, Loss 0.975522, forward nfe 3924, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 015, Runtime 13.533407, Loss 0.790553, forward nfe 4220, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 016, Runtime 13.128777, Loss 0.781358, forward nfe 4516, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 017, Runtime 14.249900, Loss 0.737641, forward nfe 4812, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 018, Runtime 13.778358, Loss 0.720624, forward nfe 5108, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 019, Runtime 13.910337, Loss 0.714602, forward nfe 5404, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 020, Runtime 14.980803, Loss 0.737821, forward nfe 5700, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 021, Runtime 14.451117, Loss 0.547389, forward nfe 5996, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 022, Runtime 14.631532, Loss 0.639758, forward nfe 6292, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 023, Runtime 14.801192, Loss 0.608018, forward nfe 6588, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 024, Runtime 14.996532, Loss 0.651538, forward nfe 6884, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 025, Runtime 15.220452, Loss 0.582820, forward nfe 7180, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 026, Runtime 14.893164, Loss 0.737732, forward nfe 7476, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 027, Runtime 15.552170, Loss 0.757997, forward nfe 7772, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 028, Runtime 15.760438, Loss 0.614207, forward nfe 8068, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 029, Runtime 15.910239, Loss 0.615204, forward nfe 8364, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 030, Runtime 16.469631, Loss 0.614654, forward nfe 8660, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 031, Runtime 15.964628, Loss 0.604014, forward nfe 8956, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 032, Runtime 16.451467, Loss 0.583195, forward nfe 9252, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 033, Runtime 16.754194, Loss 0.704464, forward nfe 9548, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 034, Runtime 16.610970, Loss 0.461995, forward nfe 9844, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 035, Runtime 17.875303, Loss 0.649672, forward nfe 10140, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 036, Runtime 17.288710, Loss 0.442766, forward nfe 10436, backward nfe 0, Train: 0.9000, Val: 0.7706, Test: 0.7827, Best time: 18.2948
Epoch: 037, Runtime 17.695971, Loss 0.473484, forward nfe 10732, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 038, Runtime 13.974257, Loss 0.551131, forward nfe 11028, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 039, Runtime 14.352925, Loss 0.409968, forward nfe 11324, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 040, Runtime 13.757653, Loss 0.544148, forward nfe 11620, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 041, Runtime 14.493431, Loss 0.436173, forward nfe 11916, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 042, Runtime 14.115445, Loss 0.435027, forward nfe 12212, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 043, Runtime 14.606216, Loss 0.616627, forward nfe 12508, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 044, Runtime 14.606308, Loss 0.412750, forward nfe 12804, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 045, Runtime 14.795453, Loss 0.542800, forward nfe 13100, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 046, Runtime 15.244824, Loss 0.540924, forward nfe 13396, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 047, Runtime 15.057494, Loss 0.484507, forward nfe 13692, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 048, Runtime 15.653986, Loss 0.374408, forward nfe 13988, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 049, Runtime 15.819947, Loss 0.555057, forward nfe 14284, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 050, Runtime 15.742988, Loss 0.498700, forward nfe 14580, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 051, Runtime 16.441937, Loss 0.482342, forward nfe 14876, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 052, Runtime 15.897838, Loss 0.451854, forward nfe 15172, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 053, Runtime 15.897859, Loss 0.515970, forward nfe 15468, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 054, Runtime 15.948513, Loss 0.485012, forward nfe 15764, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 055, Runtime 15.662404, Loss 0.369734, forward nfe 16060, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 056, Runtime 16.192252, Loss 0.375650, forward nfe 16356, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 057, Runtime 16.120934, Loss 0.412046, forward nfe 16652, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 058, Runtime 16.282319, Loss 0.368445, forward nfe 16948, backward nfe 0, Train: 0.9000, Val: 0.7765, Test: 0.7716, Best time: 18.2948
Epoch: 059, Runtime 16.873886, Loss 0.323988, forward nfe 17244, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 28.0000
Epoch: 060, Runtime 13.611574, Loss 0.395115, forward nfe 17540, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 061, Runtime 14.093073, Loss 0.414720, forward nfe 17836, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 062, Runtime 13.585685, Loss 0.352276, forward nfe 18132, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 063, Runtime 13.734547, Loss 0.432238, forward nfe 18428, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 064, Runtime 13.857622, Loss 0.414649, forward nfe 18724, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 065, Runtime 13.701210, Loss 0.436446, forward nfe 19020, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 066, Runtime 14.451087, Loss 0.364152, forward nfe 19316, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 067, Runtime 14.238744, Loss 0.499714, forward nfe 19612, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 068, Runtime 14.881852, Loss 0.281189, forward nfe 19908, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 069, Runtime 14.838811, Loss 0.353306, forward nfe 20204, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 070, Runtime 14.761252, Loss 0.298794, forward nfe 20500, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 071, Runtime 15.415176, Loss 0.326028, forward nfe 20796, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 072, Runtime 15.161953, Loss 0.364913, forward nfe 21092, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 073, Runtime 15.881030, Loss 0.344392, forward nfe 21388, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 074, Runtime 15.562636, Loss 0.378288, forward nfe 21684, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 075, Runtime 15.512662, Loss 0.391719, forward nfe 21980, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 076, Runtime 15.718207, Loss 0.451246, forward nfe 22276, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 077, Runtime 15.724125, Loss 0.498723, forward nfe 22572, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 078, Runtime 15.752838, Loss 0.381848, forward nfe 22868, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 079, Runtime 15.971258, Loss 0.403228, forward nfe 23164, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 080, Runtime 16.410094, Loss 0.454718, forward nfe 23460, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 081, Runtime 16.258837, Loss 0.413443, forward nfe 23756, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 082, Runtime 16.580967, Loss 0.474640, forward nfe 24052, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 083, Runtime 16.374779, Loss 0.402761, forward nfe 24348, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 084, Runtime 16.816987, Loss 0.304171, forward nfe 24644, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 085, Runtime 17.149479, Loss 0.392192, forward nfe 24940, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 086, Runtime 16.645039, Loss 0.342180, forward nfe 25236, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 087, Runtime 16.910259, Loss 0.326636, forward nfe 25532, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 088, Runtime 16.906423, Loss 0.365363, forward nfe 25828, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 089, Runtime 16.927851, Loss 0.312529, forward nfe 26124, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 090, Runtime 16.982901, Loss 0.245920, forward nfe 26420, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 091, Runtime 17.440924, Loss 0.359200, forward nfe 26716, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 092, Runtime 17.327348, Loss 0.467137, forward nfe 27012, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 093, Runtime 16.844292, Loss 0.361181, forward nfe 27308, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 094, Runtime 17.025244, Loss 0.337184, forward nfe 27604, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 095, Runtime 16.873691, Loss 0.367291, forward nfe 27900, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 096, Runtime 16.680701, Loss 0.388120, forward nfe 28196, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 097, Runtime 17.073430, Loss 0.277694, forward nfe 28492, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 098, Runtime 16.937954, Loss 0.494315, forward nfe 28788, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
Epoch: 099, Runtime 16.921108, Loss 0.454862, forward nfe 29084, backward nfe 0, Train: 0.9643, Val: 0.7787, Test: 0.7888, Best time: 18.2948
best val accuracy 0.778676 with test accuracy 0.788832 at epoch 59 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8
Entropy Threshold: 2 Test accuracy: 0.7918781725888325
Entropy Threshold: 1.6 Test accuracy: 0.8016359918200409
Entropy Threshold: 1.5 Test accuracy: 0.8078512396694215
Entropy Threshold: 1.4 Test accuracy: 0.8008342022940563
Entropy Threshold: 1.3 Test accuracy: 0.8044397463002114
Entropy Threshold: 1.2 Test accuracy: 0.8122977346278317
Entropy Threshold: 1.1 Test accuracy: 0.834619625137817
Entropy Threshold: 0.9 Test accuracy: 0.8469750889679716
Entropy Threshold: 0.8 Test accuracy: 0.865211810012837
Entropy Threshold: 0.7 Test accuracy: 0.8799472295514512
Entropy Threshold: 0.6 Test accuracy: 0.8961593172119487
Entropy Threshold: 0.5 Test accuracy: 0.9107413010590015
Entropy Threshold: 0.4 Test accuracy: 0.9180064308681672
Entropy Threshold: 0.3 Test accuracy: 0.9267015706806283
Entropy Threshold: 0.2 Test accuracy: 0.9352941176470588
Entropy Threshold: 0.1 Test accuracy: 0.9411764705882353
