[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 10.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 17.918838, Loss 7.740875, forward nfe 76, backward nfe 0, Train: 0.3429, Val: 0.2294, Test: 0.2477, Best time: 4.0000
Epoch: 002, Runtime 18.461435, Loss 9.520985, forward nfe 372, backward nfe 0, Train: 0.3643, Val: 0.2713, Test: 0.2812, Best time: 1.0000
Epoch: 003, Runtime 17.195028, Loss 7.045740, forward nfe 668, backward nfe 0, Train: 0.4857, Val: 0.3235, Test: 0.3503, Best time: 2.0000
Epoch: 004, Runtime 18.002557, Loss 6.541270, forward nfe 964, backward nfe 0, Train: 0.5214, Val: 0.3493, Test: 0.3716, Best time: 3.0000
Epoch: 005, Runtime 18.027684, Loss 6.276486, forward nfe 1260, backward nfe 0, Train: 0.5714, Val: 0.3853, Test: 0.4010, Best time: 2.0000
Epoch: 006, Runtime 17.906646, Loss 5.162745, forward nfe 1556, backward nfe 0, Train: 0.5929, Val: 0.4103, Test: 0.4508, Best time: 21.0000
Epoch: 007, Runtime 18.320245, Loss 4.491962, forward nfe 1852, backward nfe 0, Train: 0.5929, Val: 0.4103, Test: 0.4508, Best time: 18.2948
Epoch: 008, Runtime 18.546801, Loss 4.263877, forward nfe 2148, backward nfe 0, Train: 0.5929, Val: 0.4103, Test: 0.4508, Best time: 18.2948
Epoch: 009, Runtime 18.682599, Loss 3.855619, forward nfe 2444, backward nfe 0, Train: 0.5929, Val: 0.4103, Test: 0.4508, Best time: 18.2948
Epoch: 010, Runtime 19.043979, Loss 3.999628, forward nfe 2740, backward nfe 0, Train: 0.5929, Val: 0.4103, Test: 0.4508, Best time: 18.2948
Epoch: 011, Runtime 19.521475, Loss 3.759562, forward nfe 3036, backward nfe 0, Train: 0.5357, Val: 0.4132, Test: 0.4437, Best time: 1.0000
Epoch: 012, Runtime 17.961329, Loss 3.477453, forward nfe 3332, backward nfe 0, Train: 0.5857, Val: 0.4471, Test: 0.4832, Best time: 1.0000
Epoch: 013, Runtime 17.576914, Loss 3.259497, forward nfe 3628, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 1.0000
Epoch: 014, Runtime 17.307215, Loss 3.071442, forward nfe 3924, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 015, Runtime 17.696370, Loss 2.893680, forward nfe 4220, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 016, Runtime 17.572164, Loss 2.730309, forward nfe 4516, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 017, Runtime 17.982348, Loss 2.647504, forward nfe 4812, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 018, Runtime 18.212184, Loss 2.566944, forward nfe 5108, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 019, Runtime 18.498098, Loss 2.544683, forward nfe 5404, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 020, Runtime 19.011457, Loss 2.384984, forward nfe 5700, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 021, Runtime 19.240272, Loss 2.358025, forward nfe 5996, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 022, Runtime 19.046213, Loss 2.369189, forward nfe 6292, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 023, Runtime 20.058763, Loss 2.378120, forward nfe 6588, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 024, Runtime 19.809506, Loss 2.472047, forward nfe 6884, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 025, Runtime 19.632581, Loss 2.332045, forward nfe 7180, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 026, Runtime 19.882457, Loss 2.302537, forward nfe 7476, backward nfe 0, Train: 0.6214, Val: 0.4581, Test: 0.4954, Best time: 18.2948
Epoch: 027, Runtime 19.657311, Loss 2.338715, forward nfe 7772, backward nfe 0, Train: 0.5357, Val: 0.4588, Test: 0.4924, Best time: 1.0000
Epoch: 028, Runtime 16.571187, Loss 2.147385, forward nfe 8068, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 1.0000
Epoch: 029, Runtime 16.225146, Loss 2.114870, forward nfe 8364, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 030, Runtime 17.152049, Loss 2.125755, forward nfe 8660, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 031, Runtime 16.889476, Loss 2.150629, forward nfe 8956, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 032, Runtime 17.141900, Loss 2.321614, forward nfe 9252, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 033, Runtime 17.056950, Loss 2.262981, forward nfe 9548, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 034, Runtime 17.182627, Loss 2.195252, forward nfe 9844, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 035, Runtime 17.915736, Loss 2.009113, forward nfe 10140, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 036, Runtime 17.406473, Loss 2.105055, forward nfe 10436, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 037, Runtime 17.728166, Loss 1.958338, forward nfe 10732, backward nfe 0, Train: 0.5286, Val: 0.4662, Test: 0.5107, Best time: 18.2948
Epoch: 038, Runtime 18.465032, Loss 2.225971, forward nfe 11028, backward nfe 0, Train: 0.5714, Val: 0.4853, Test: 0.5228, Best time: 3.0000
Epoch: 039, Runtime 15.720238, Loss 2.135552, forward nfe 11324, backward nfe 0, Train: 0.6500, Val: 0.5294, Test: 0.5736, Best time: 3.0000
Epoch: 040, Runtime 15.798496, Loss 1.885373, forward nfe 11620, backward nfe 0, Train: 0.7571, Val: 0.5581, Test: 0.5949, Best time: 3.0000
Epoch: 041, Runtime 15.689728, Loss 2.145701, forward nfe 11916, backward nfe 0, Train: 0.7571, Val: 0.5743, Test: 0.6091, Best time: 3.0000
Epoch: 042, Runtime 16.056373, Loss 2.005901, forward nfe 12212, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 3.0000
Epoch: 043, Runtime 15.157513, Loss 1.989302, forward nfe 12508, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 044, Runtime 15.404514, Loss 2.093821, forward nfe 12804, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 045, Runtime 15.317665, Loss 2.031931, forward nfe 13100, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 046, Runtime 15.587550, Loss 1.974414, forward nfe 13396, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 047, Runtime 15.449601, Loss 1.961844, forward nfe 13692, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 048, Runtime 14.846516, Loss 2.013235, forward nfe 13988, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 049, Runtime 14.674642, Loss 2.005002, forward nfe 14284, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 050, Runtime 14.969880, Loss 2.076796, forward nfe 14580, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 051, Runtime 15.763518, Loss 1.868900, forward nfe 14876, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 052, Runtime 15.318930, Loss 1.940783, forward nfe 15172, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 053, Runtime 15.572445, Loss 1.921776, forward nfe 15468, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 054, Runtime 16.018764, Loss 1.810257, forward nfe 15764, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 055, Runtime 16.429970, Loss 1.808566, forward nfe 16060, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 056, Runtime 16.693053, Loss 1.978492, forward nfe 16356, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 057, Runtime 16.322980, Loss 2.052341, forward nfe 16652, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 058, Runtime 16.717443, Loss 1.854065, forward nfe 16948, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 059, Runtime 15.935863, Loss 2.033746, forward nfe 17244, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 060, Runtime 16.078694, Loss 1.761259, forward nfe 17540, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 061, Runtime 16.503591, Loss 1.872019, forward nfe 17836, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 062, Runtime 15.890249, Loss 1.869378, forward nfe 18132, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 063, Runtime 17.043745, Loss 1.832778, forward nfe 18428, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 064, Runtime 16.192757, Loss 1.787411, forward nfe 18724, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 065, Runtime 16.822239, Loss 1.831854, forward nfe 19020, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 066, Runtime 16.702407, Loss 1.881621, forward nfe 19316, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 067, Runtime 16.490378, Loss 1.710186, forward nfe 19612, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 068, Runtime 16.578003, Loss 1.867068, forward nfe 19908, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 069, Runtime 16.359196, Loss 1.677328, forward nfe 20204, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 070, Runtime 17.230900, Loss 1.850668, forward nfe 20500, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 071, Runtime 16.964149, Loss 1.838874, forward nfe 20796, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 072, Runtime 17.088517, Loss 1.865917, forward nfe 21092, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 073, Runtime 17.345301, Loss 1.714519, forward nfe 21388, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 074, Runtime 17.129838, Loss 1.767068, forward nfe 21684, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 075, Runtime 17.190574, Loss 1.611659, forward nfe 21980, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 076, Runtime 16.695797, Loss 1.612184, forward nfe 22276, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 077, Runtime 16.435886, Loss 1.502251, forward nfe 22572, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 078, Runtime 16.859338, Loss 1.456278, forward nfe 22868, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 079, Runtime 16.855901, Loss 1.717392, forward nfe 23164, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 080, Runtime 17.342556, Loss 1.469327, forward nfe 23460, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 081, Runtime 16.573505, Loss 1.589523, forward nfe 23756, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 082, Runtime 17.001529, Loss 1.535588, forward nfe 24052, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 083, Runtime 17.650915, Loss 1.401476, forward nfe 24348, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 084, Runtime 17.739009, Loss 1.397587, forward nfe 24644, backward nfe 0, Train: 0.7643, Val: 0.5794, Test: 0.6081, Best time: 18.2948
Epoch: 085, Runtime 19.071535, Loss 1.339861, forward nfe 24940, backward nfe 0, Train: 0.7286, Val: 0.5860, Test: 0.6152, Best time: 1.0000
Epoch: 086, Runtime 12.918536, Loss 1.506996, forward nfe 25236, backward nfe 0, Train: 0.7643, Val: 0.5963, Test: 0.6315, Best time: 1.0000
Epoch: 087, Runtime 12.623056, Loss 1.398225, forward nfe 25532, backward nfe 0, Train: 0.7786, Val: 0.5993, Test: 0.6294, Best time: 1.0000
Epoch: 088, Runtime 13.145356, Loss 1.517400, forward nfe 25828, backward nfe 0, Train: 0.7786, Val: 0.5993, Test: 0.6294, Best time: 18.2948
Epoch: 089, Runtime 13.038666, Loss 1.457091, forward nfe 26124, backward nfe 0, Train: 0.7786, Val: 0.5993, Test: 0.6294, Best time: 18.2948
Epoch: 090, Runtime 13.483457, Loss 1.375884, forward nfe 26420, backward nfe 0, Train: 0.8000, Val: 0.6257, Test: 0.6589, Best time: 1.0000
Epoch: 091, Runtime 12.901847, Loss 1.290092, forward nfe 26716, backward nfe 0, Train: 0.8286, Val: 0.6419, Test: 0.6751, Best time: 1.0000
Epoch: 092, Runtime 13.051034, Loss 1.258763, forward nfe 27012, backward nfe 0, Train: 0.8071, Val: 0.6449, Test: 0.6741, Best time: 1.0000
Epoch: 093, Runtime 13.321966, Loss 1.315192, forward nfe 27308, backward nfe 0, Train: 0.8071, Val: 0.6449, Test: 0.6741, Best time: 18.2948
Epoch: 094, Runtime 13.494837, Loss 1.323267, forward nfe 27604, backward nfe 0, Train: 0.8071, Val: 0.6449, Test: 0.6741, Best time: 18.2948
Epoch: 095, Runtime 13.762108, Loss 1.233650, forward nfe 27900, backward nfe 0, Train: 0.8071, Val: 0.6449, Test: 0.6741, Best time: 18.2948
Epoch: 096, Runtime 14.490273, Loss 1.181260, forward nfe 28196, backward nfe 0, Train: 0.8143, Val: 0.6456, Test: 0.6711, Best time: 1.0000
Epoch: 097, Runtime 13.515965, Loss 1.171022, forward nfe 28492, backward nfe 0, Train: 0.8143, Val: 0.6456, Test: 0.6711, Best time: 18.2948
Epoch: 098, Runtime 13.798949, Loss 1.494244, forward nfe 28788, backward nfe 0, Train: 0.8143, Val: 0.6456, Test: 0.6711, Best time: 18.2948
Epoch: 099, Runtime 14.060384, Loss 1.410687, forward nfe 29084, backward nfe 0, Train: 0.8143, Val: 0.6456, Test: 0.6711, Best time: 18.2948
best val accuracy 0.645588 with test accuracy 0.671066 at epoch 96 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.650761421319797
Entropy Threshold: 2 Test accuracy: 0.6456852791878173
Entropy Threshold: 1.6 Test accuracy: 0.668141592920354
Entropy Threshold: 1.5 Test accuracy: 0.7045454545454546
Entropy Threshold: 1.4 Test accuracy: 0.7329032258064516
Entropy Threshold: 1.3 Test accuracy: 0.745269286754003
Entropy Threshold: 1.2 Test accuracy: 0.7717041800643086
Entropy Threshold: 1.1 Test accuracy: 0.7913669064748201
Entropy Threshold: 0.9 Test accuracy: 0.8433734939759037
Entropy Threshold: 0.8 Test accuracy: 0.8848314606741573
Entropy Threshold: 0.7 Test accuracy: 0.89937106918239
Entropy Threshold: 0.6 Test accuracy: 0.9007352941176471
Entropy Threshold: 0.5 Test accuracy: 0.9170305676855895
Entropy Threshold: 0.4 Test accuracy: 0.9213483146067416
Entropy Threshold: 0.3 Test accuracy: 0.9241379310344827
Entropy Threshold: 0.2 Test accuracy: 0.9142857142857143
Entropy Threshold: 0.1 Test accuracy: 0.927536231884058
