[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 4.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 21.011345, Loss 2.714151, forward nfe 76, backward nfe 0, Train: 0.2429, Val: 0.1676, Test: 0.1503, Best time: 1.0000
Epoch: 002, Runtime 40.169952, Loss 30.200937, forward nfe 372, backward nfe 0, Train: 0.2143, Val: 0.2000, Test: 0.2000, Best time: 1.0000
Epoch: 003, Runtime 17.970186, Loss 2.622758, forward nfe 668, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 2.0000
Epoch: 004, Runtime 17.446380, Loss 2.977682, forward nfe 964, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 005, Runtime 18.639639, Loss 3.221979, forward nfe 1260, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 006, Runtime 20.055282, Loss 3.205867, forward nfe 1556, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 007, Runtime 23.067011, Loss 3.240359, forward nfe 1852, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 008, Runtime 24.371883, Loss 3.144377, forward nfe 2148, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 009, Runtime 25.142689, Loss 3.087351, forward nfe 2444, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 010, Runtime 27.002042, Loss 2.984580, forward nfe 2740, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 011, Runtime 28.415534, Loss 3.050831, forward nfe 3036, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 012, Runtime 29.930745, Loss 2.993299, forward nfe 3332, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 013, Runtime 30.034773, Loss 2.794393, forward nfe 3628, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 014, Runtime 30.908261, Loss 2.939726, forward nfe 3924, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 015, Runtime 31.547070, Loss 2.854235, forward nfe 4220, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 016, Runtime 32.215436, Loss 2.659698, forward nfe 4516, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 017, Runtime 32.060966, Loss 2.606829, forward nfe 4812, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 018, Runtime 32.848627, Loss 2.346930, forward nfe 5108, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 019, Runtime 32.312975, Loss 2.788047, forward nfe 5404, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 020, Runtime 32.933331, Loss 2.553459, forward nfe 5700, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 021, Runtime 33.054670, Loss 2.647780, forward nfe 5996, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 022, Runtime 33.415123, Loss 2.682799, forward nfe 6292, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 023, Runtime 32.091883, Loss 2.630316, forward nfe 6588, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 024, Runtime 31.431454, Loss 2.766541, forward nfe 6884, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 025, Runtime 31.638947, Loss 2.670013, forward nfe 7180, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 026, Runtime 31.289347, Loss 2.514141, forward nfe 7476, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 027, Runtime 30.948395, Loss 2.569058, forward nfe 7772, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 028, Runtime 27.739304, Loss 2.701444, forward nfe 8068, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 029, Runtime 20.417957, Loss 2.617233, forward nfe 8364, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 030, Runtime 20.237962, Loss 2.617422, forward nfe 8660, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 031, Runtime 20.687348, Loss 2.617088, forward nfe 8956, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 032, Runtime 21.517568, Loss 2.576845, forward nfe 9252, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 033, Runtime 22.190136, Loss 2.443435, forward nfe 9548, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 034, Runtime 22.255299, Loss 2.420700, forward nfe 9844, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 035, Runtime 22.180199, Loss 2.501078, forward nfe 10140, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 036, Runtime 22.954917, Loss 2.634542, forward nfe 10436, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 037, Runtime 23.556985, Loss 2.546234, forward nfe 10732, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 038, Runtime 25.460281, Loss 2.541530, forward nfe 11028, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 039, Runtime 25.312313, Loss 2.467721, forward nfe 11324, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 040, Runtime 26.128480, Loss 2.379396, forward nfe 11620, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 041, Runtime 26.185632, Loss 2.607480, forward nfe 11916, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 042, Runtime 26.537673, Loss 2.461514, forward nfe 12212, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 043, Runtime 26.192533, Loss 2.530167, forward nfe 12508, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 044, Runtime 26.184890, Loss 2.472633, forward nfe 12804, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 045, Runtime 26.838919, Loss 2.335485, forward nfe 13100, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 046, Runtime 26.867808, Loss 2.608291, forward nfe 13396, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 047, Runtime 26.846738, Loss 2.566775, forward nfe 13692, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 048, Runtime 27.110952, Loss 2.542062, forward nfe 13988, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 049, Runtime 27.160995, Loss 2.362729, forward nfe 14284, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 050, Runtime 26.919385, Loss 2.465508, forward nfe 14580, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 051, Runtime 27.179171, Loss 2.469613, forward nfe 14876, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 052, Runtime 26.995256, Loss 2.540642, forward nfe 15172, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 053, Runtime 27.090320, Loss 2.412977, forward nfe 15468, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 054, Runtime 27.128379, Loss 2.489777, forward nfe 15764, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 055, Runtime 27.253836, Loss 2.512150, forward nfe 16060, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 056, Runtime 27.261535, Loss 2.392947, forward nfe 16356, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 057, Runtime 26.710471, Loss 2.271378, forward nfe 16652, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 058, Runtime 26.949231, Loss 2.389984, forward nfe 16948, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 059, Runtime 26.902620, Loss 2.446272, forward nfe 17244, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 060, Runtime 26.464007, Loss 2.347134, forward nfe 17540, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 061, Runtime 25.346135, Loss 2.338866, forward nfe 17836, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 062, Runtime 25.351421, Loss 2.300343, forward nfe 18132, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 063, Runtime 25.476851, Loss 2.247768, forward nfe 18428, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 064, Runtime 25.713132, Loss 2.298145, forward nfe 18724, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 065, Runtime 25.567833, Loss 2.426126, forward nfe 19020, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 066, Runtime 25.727145, Loss 2.301785, forward nfe 19316, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 067, Runtime 25.882174, Loss 2.336305, forward nfe 19612, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 068, Runtime 25.924740, Loss 2.427050, forward nfe 19908, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 069, Runtime 25.809330, Loss 2.275031, forward nfe 20204, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 070, Runtime 25.974555, Loss 2.235754, forward nfe 20500, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 071, Runtime 25.731193, Loss 2.342025, forward nfe 20796, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 072, Runtime 25.588315, Loss 2.344362, forward nfe 21092, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 073, Runtime 25.964498, Loss 2.426572, forward nfe 21388, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 074, Runtime 26.008886, Loss 2.444475, forward nfe 21684, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 075, Runtime 23.131458, Loss 2.269599, forward nfe 21980, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 076, Runtime 17.283621, Loss 2.193353, forward nfe 22276, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 077, Runtime 17.363877, Loss 2.342499, forward nfe 22572, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 078, Runtime 17.563754, Loss 2.382074, forward nfe 22868, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 079, Runtime 18.553672, Loss 2.166078, forward nfe 23164, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 080, Runtime 19.139233, Loss 2.366262, forward nfe 23460, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 081, Runtime 19.284684, Loss 2.155043, forward nfe 23756, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 082, Runtime 19.772444, Loss 2.224174, forward nfe 24052, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 083, Runtime 20.389899, Loss 2.238874, forward nfe 24348, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 084, Runtime 20.637725, Loss 2.212857, forward nfe 24644, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 085, Runtime 21.072134, Loss 2.180246, forward nfe 24940, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 086, Runtime 21.287870, Loss 2.304207, forward nfe 25236, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 087, Runtime 21.449963, Loss 2.300915, forward nfe 25532, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 088, Runtime 21.940568, Loss 2.355643, forward nfe 25828, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 089, Runtime 22.126475, Loss 2.331915, forward nfe 26124, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 090, Runtime 22.524525, Loss 2.311424, forward nfe 26420, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 091, Runtime 22.929623, Loss 2.277422, forward nfe 26716, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 092, Runtime 22.774790, Loss 2.141877, forward nfe 27012, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 093, Runtime 23.428821, Loss 2.290131, forward nfe 27308, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 094, Runtime 23.487593, Loss 2.304100, forward nfe 27604, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 095, Runtime 23.697639, Loss 2.154208, forward nfe 27900, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 096, Runtime 23.527106, Loss 2.194656, forward nfe 28196, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 097, Runtime 23.794213, Loss 2.245945, forward nfe 28492, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 098, Runtime 23.878040, Loss 2.335957, forward nfe 28788, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
Epoch: 099, Runtime 23.917253, Loss 2.303909, forward nfe 29084, backward nfe 0, Train: 0.2071, Val: 0.3404, Test: 0.3066, Best time: 18.2948
best val accuracy 0.340441 with test accuracy 0.306599 at epoch 3 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1766497461928934
Entropy Threshold: 2 Test accuracy: 0.19086294416243654
Entropy Threshold: 1.6 Test accuracy: 0.19432773109243698
Entropy Threshold: 1.5 Test accuracy: 0.18634423897581792
Entropy Threshold: 1.4 Test accuracy: 0.1453287197231834
Entropy Threshold: 1.3 Test accuracy: 0.20833333333333334
Entropy Threshold: 1.2 Test accuracy: 0.08823529411764706
Entropy Threshold: 1.1 Test accuracy: 0.07142857142857142
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
