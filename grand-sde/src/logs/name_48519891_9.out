[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 5.0
rtol 0.01
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 16.131851, Loss 4.321889, forward nfe 76, backward nfe 0, Train: 0.4500, Val: 0.3309, Test: 0.3360, Best time: 4.0000
Epoch: 002, Runtime 15.780706, Loss 4.866459, forward nfe 372, backward nfe 0, Train: 0.4500, Val: 0.3309, Test: 0.3360, Best time: 18.2948
Epoch: 003, Runtime 16.785393, Loss 4.311130, forward nfe 668, backward nfe 0, Train: 0.5500, Val: 0.4184, Test: 0.3980, Best time: 1.0000
Epoch: 004, Runtime 16.122489, Loss 3.615015, forward nfe 964, backward nfe 0, Train: 0.7071, Val: 0.5596, Test: 0.5695, Best time: 3.0000
Epoch: 005, Runtime 16.065511, Loss 3.310587, forward nfe 1260, backward nfe 0, Train: 0.7429, Val: 0.5735, Test: 0.5848, Best time: 4.0000
Epoch: 006, Runtime 16.050293, Loss 3.072725, forward nfe 1556, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 3.0000
Epoch: 007, Runtime 15.676671, Loss 2.920895, forward nfe 1852, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 18.2948
Epoch: 008, Runtime 16.434723, Loss 2.493725, forward nfe 2148, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 18.2948
Epoch: 009, Runtime 15.877771, Loss 2.346510, forward nfe 2444, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 18.2948
Epoch: 010, Runtime 16.254019, Loss 2.239483, forward nfe 2740, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 18.2948
Epoch: 011, Runtime 16.108686, Loss 2.408546, forward nfe 3036, backward nfe 0, Train: 0.7357, Val: 0.5838, Test: 0.5878, Best time: 18.2948
Epoch: 012, Runtime 16.391865, Loss 2.037198, forward nfe 3332, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 33.0000
Epoch: 013, Runtime 15.381329, Loss 1.815674, forward nfe 3628, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 014, Runtime 15.851898, Loss 1.891438, forward nfe 3924, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 015, Runtime 15.190769, Loss 1.922201, forward nfe 4220, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 016, Runtime 15.663122, Loss 1.619767, forward nfe 4516, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 017, Runtime 15.447013, Loss 1.802978, forward nfe 4812, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 018, Runtime 15.567639, Loss 1.637390, forward nfe 5108, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 019, Runtime 15.899398, Loss 1.581857, forward nfe 5404, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 020, Runtime 16.169968, Loss 1.474232, forward nfe 5700, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 021, Runtime 16.731603, Loss 1.506711, forward nfe 5996, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 022, Runtime 16.783737, Loss 1.404111, forward nfe 6292, backward nfe 0, Train: 0.7071, Val: 0.5860, Test: 0.6010, Best time: 18.2948
Epoch: 023, Runtime 17.312516, Loss 1.316013, forward nfe 6588, backward nfe 0, Train: 0.8071, Val: 0.6103, Test: 0.6041, Best time: 2.0000
Epoch: 024, Runtime 15.368387, Loss 1.272888, forward nfe 6884, backward nfe 0, Train: 0.8429, Val: 0.6478, Test: 0.6406, Best time: 4.0000
Epoch: 025, Runtime 15.550404, Loss 1.258634, forward nfe 7180, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 6.0000
Epoch: 026, Runtime 15.541058, Loss 1.309071, forward nfe 7476, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 027, Runtime 16.603005, Loss 1.139403, forward nfe 7772, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 028, Runtime 15.987286, Loss 1.157061, forward nfe 8068, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 029, Runtime 16.503044, Loss 1.297776, forward nfe 8364, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 030, Runtime 16.269305, Loss 1.216116, forward nfe 8660, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 031, Runtime 16.908172, Loss 0.988965, forward nfe 8956, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 032, Runtime 17.590358, Loss 0.986642, forward nfe 9252, backward nfe 0, Train: 0.8357, Val: 0.6544, Test: 0.6487, Best time: 18.2948
Epoch: 033, Runtime 18.144266, Loss 1.124007, forward nfe 9548, backward nfe 0, Train: 0.7786, Val: 0.6559, Test: 0.6497, Best time: 18.2948
Epoch: 034, Runtime 16.573031, Loss 0.953287, forward nfe 9844, backward nfe 0, Train: 0.7786, Val: 0.6559, Test: 0.6497, Best time: 18.2948
Epoch: 035, Runtime 16.879284, Loss 0.879950, forward nfe 10140, backward nfe 0, Train: 0.7786, Val: 0.6559, Test: 0.6497, Best time: 18.2948
Epoch: 036, Runtime 16.924140, Loss 1.058042, forward nfe 10436, backward nfe 0, Train: 0.8286, Val: 0.6632, Test: 0.6599, Best time: 18.2948
Epoch: 037, Runtime 16.399580, Loss 0.922955, forward nfe 10732, backward nfe 0, Train: 0.8643, Val: 0.6949, Test: 0.7005, Best time: 18.2948
Epoch: 038, Runtime 16.784823, Loss 0.905160, forward nfe 11028, backward nfe 0, Train: 0.9071, Val: 0.7059, Test: 0.7178, Best time: 18.2948
Epoch: 039, Runtime 16.705385, Loss 0.990247, forward nfe 11324, backward nfe 0, Train: 0.8429, Val: 0.7206, Test: 0.6964, Best time: 18.2948
Epoch: 040, Runtime 16.461226, Loss 1.031685, forward nfe 11620, backward nfe 0, Train: 0.8429, Val: 0.7206, Test: 0.6964, Best time: 18.2948
Epoch: 041, Runtime 16.134726, Loss 0.987479, forward nfe 11916, backward nfe 0, Train: 0.8429, Val: 0.7206, Test: 0.6964, Best time: 18.2948
Epoch: 042, Runtime 16.022000, Loss 0.873768, forward nfe 12212, backward nfe 0, Train: 0.8429, Val: 0.7206, Test: 0.6964, Best time: 18.2948
Epoch: 043, Runtime 16.592487, Loss 0.983520, forward nfe 12508, backward nfe 0, Train: 0.8429, Val: 0.7206, Test: 0.6964, Best time: 18.2948
Epoch: 044, Runtime 17.380862, Loss 0.841882, forward nfe 12804, backward nfe 0, Train: 0.8786, Val: 0.7397, Test: 0.7371, Best time: 18.2948
Epoch: 045, Runtime 16.021105, Loss 0.797748, forward nfe 13100, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 046, Runtime 16.067604, Loss 0.912348, forward nfe 13396, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 047, Runtime 16.122993, Loss 0.857120, forward nfe 13692, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 048, Runtime 16.137727, Loss 0.826923, forward nfe 13988, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 049, Runtime 15.999807, Loss 0.827846, forward nfe 14284, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 050, Runtime 16.193167, Loss 0.878550, forward nfe 14580, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 051, Runtime 16.566019, Loss 0.788253, forward nfe 14876, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 052, Runtime 16.054507, Loss 0.887533, forward nfe 15172, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 053, Runtime 16.019790, Loss 0.842394, forward nfe 15468, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 054, Runtime 16.226417, Loss 0.867519, forward nfe 15764, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 055, Runtime 16.556812, Loss 0.836953, forward nfe 16060, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 056, Runtime 16.733349, Loss 0.953122, forward nfe 16356, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 057, Runtime 16.883152, Loss 0.763893, forward nfe 16652, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 058, Runtime 16.527415, Loss 0.881852, forward nfe 16948, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 059, Runtime 16.741103, Loss 0.942678, forward nfe 17244, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 060, Runtime 16.760444, Loss 0.649721, forward nfe 17540, backward nfe 0, Train: 0.9000, Val: 0.7618, Test: 0.7513, Best time: 18.2948
Epoch: 061, Runtime 17.329623, Loss 0.731813, forward nfe 17836, backward nfe 0, Train: 0.9071, Val: 0.7831, Test: 0.7645, Best time: 18.2948
Epoch: 062, Runtime 14.226368, Loss 0.800926, forward nfe 18132, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 063, Runtime 13.895128, Loss 0.784495, forward nfe 18428, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 064, Runtime 13.928582, Loss 0.807751, forward nfe 18724, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 065, Runtime 13.841002, Loss 0.881796, forward nfe 19020, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 066, Runtime 14.360724, Loss 0.785839, forward nfe 19316, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 067, Runtime 14.250609, Loss 0.702626, forward nfe 19612, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 068, Runtime 14.362489, Loss 0.571278, forward nfe 19908, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 069, Runtime 14.652591, Loss 0.693726, forward nfe 20204, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 070, Runtime 15.368803, Loss 0.566324, forward nfe 20500, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 071, Runtime 14.974570, Loss 0.666573, forward nfe 20796, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 072, Runtime 15.341282, Loss 0.691665, forward nfe 21092, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 073, Runtime 15.669348, Loss 0.748501, forward nfe 21388, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 074, Runtime 15.437240, Loss 0.729867, forward nfe 21684, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 075, Runtime 15.599374, Loss 0.642902, forward nfe 21980, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 076, Runtime 15.761996, Loss 0.608772, forward nfe 22276, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 077, Runtime 16.095705, Loss 0.711503, forward nfe 22572, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 078, Runtime 16.441178, Loss 0.859500, forward nfe 22868, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 079, Runtime 15.871085, Loss 0.666696, forward nfe 23164, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 080, Runtime 16.442149, Loss 0.614906, forward nfe 23460, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 081, Runtime 15.732649, Loss 0.732945, forward nfe 23756, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 082, Runtime 15.746044, Loss 0.595586, forward nfe 24052, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 083, Runtime 16.192779, Loss 0.629345, forward nfe 24348, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 084, Runtime 16.119500, Loss 0.833356, forward nfe 24644, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 085, Runtime 16.243807, Loss 0.645943, forward nfe 24940, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 086, Runtime 16.331225, Loss 0.571532, forward nfe 25236, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 087, Runtime 16.604265, Loss 0.779776, forward nfe 25532, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 088, Runtime 16.124364, Loss 0.603312, forward nfe 25828, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 089, Runtime 16.773873, Loss 0.507901, forward nfe 26124, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 090, Runtime 16.113810, Loss 0.593669, forward nfe 26420, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 091, Runtime 16.325053, Loss 0.653934, forward nfe 26716, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 092, Runtime 16.471985, Loss 0.655995, forward nfe 27012, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 093, Runtime 16.413571, Loss 0.562004, forward nfe 27308, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 094, Runtime 16.764959, Loss 0.533083, forward nfe 27604, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 095, Runtime 16.558616, Loss 0.454337, forward nfe 27900, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 096, Runtime 16.669473, Loss 0.525859, forward nfe 28196, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 097, Runtime 17.041282, Loss 0.619265, forward nfe 28492, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 098, Runtime 17.224298, Loss 0.655614, forward nfe 28788, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
Epoch: 099, Runtime 17.328897, Loss 0.525358, forward nfe 29084, backward nfe 0, Train: 0.8786, Val: 0.7846, Test: 0.7848, Best time: 18.2948
best val accuracy 0.784559 with test accuracy 0.784772 at epoch 62 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8142131979695432
Entropy Threshold: 2 Test accuracy: 0.8213197969543147
Entropy Threshold: 1.6 Test accuracy: 0.8249744114636642
Entropy Threshold: 1.5 Test accuracy: 0.8245614035087719
Entropy Threshold: 1.4 Test accuracy: 0.8303477344573235
Entropy Threshold: 1.3 Test accuracy: 0.8392664509169363
Entropy Threshold: 1.2 Test accuracy: 0.8535242290748899
Entropy Threshold: 1.1 Test accuracy: 0.8581314878892734
Entropy Threshold: 0.9 Test accuracy: 0.8924870466321243
Entropy Threshold: 0.8 Test accuracy: 0.9074829931972789
Entropy Threshold: 0.7 Test accuracy: 0.9329446064139941
Entropy Threshold: 0.6 Test accuracy: 0.9424342105263158
Entropy Threshold: 0.5 Test accuracy: 0.9577464788732394
Entropy Threshold: 0.4 Test accuracy: 0.957169459962756
Entropy Threshold: 0.3 Test accuracy: 0.960167714884696
Entropy Threshold: 0.2 Test accuracy: 0.9582366589327146
Entropy Threshold: 0.1 Test accuracy: 0.9798850574712644
