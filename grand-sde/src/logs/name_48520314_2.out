[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 13.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 61.592628, Loss 21.441013, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.1301, Test: 0.1381, Best time: 18.2948
Epoch: 002, Runtime 78.814772, Loss 68.984573, forward nfe 372, backward nfe 0, Train: 0.1214, Val: 0.1353, Test: 0.1137, Best time: 18.2948
Epoch: 003, Runtime 31.358917, Loss 8.365022, forward nfe 668, backward nfe 0, Train: 0.1500, Val: 0.1368, Test: 0.1228, Best time: 18.2948
Epoch: 004, Runtime 30.800393, Loss 9.032079, forward nfe 964, backward nfe 0, Train: 0.1500, Val: 0.1368, Test: 0.1228, Best time: 18.2948
Epoch: 005, Runtime 30.282455, Loss 7.083174, forward nfe 1260, backward nfe 0, Train: 0.1500, Val: 0.1368, Test: 0.1228, Best time: 18.2948
Epoch: 006, Runtime 30.770559, Loss 5.955534, forward nfe 1556, backward nfe 0, Train: 0.1143, Val: 0.1441, Test: 0.1442, Best time: 50.0000
Epoch: 007, Runtime 27.393770, Loss 5.558973, forward nfe 1852, backward nfe 0, Train: 0.1357, Val: 0.2404, Test: 0.2447, Best time: 54.8843
Epoch: 008, Runtime 27.010503, Loss 4.809705, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.2904, Test: 0.2914, Best time: 54.0000
Epoch: 009, Runtime 26.931143, Loss 4.505629, forward nfe 2444, backward nfe 0, Train: 0.1357, Val: 0.2971, Test: 0.2975, Best time: 49.0000
Epoch: 010, Runtime 27.833976, Loss 4.210146, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.2985, Test: 0.3005, Best time: 49.0000
Epoch: 011, Runtime 27.223210, Loss 4.059186, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.2985, Test: 0.3005, Best time: 18.2948
Epoch: 012, Runtime 27.571926, Loss 4.362782, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.2985, Test: 0.3005, Best time: 18.2948
Epoch: 013, Runtime 29.543128, Loss 3.990312, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.2985, Test: 0.3005, Best time: 18.2948
Epoch: 014, Runtime 30.113327, Loss 4.452208, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.2993, Test: 0.3025, Best time: 40.0000
Epoch: 015, Runtime 26.853943, Loss 4.305395, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3000, Test: 0.3015, Best time: 38.0000
Epoch: 016, Runtime 25.847986, Loss 4.307722, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3000, Test: 0.3015, Best time: 18.2948
Epoch: 017, Runtime 27.337982, Loss 4.079971, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 35.0000
Epoch: 018, Runtime 25.727968, Loss 3.660022, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 019, Runtime 26.892719, Loss 3.713544, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 020, Runtime 28.070438, Loss 3.526649, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 021, Runtime 29.005950, Loss 3.973985, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 022, Runtime 29.949261, Loss 4.041786, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 023, Runtime 32.187054, Loss 3.981901, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 024, Runtime 32.870329, Loss 3.963444, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 025, Runtime 34.093208, Loss 3.760929, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 026, Runtime 35.250560, Loss 3.661696, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 027, Runtime 35.052291, Loss 3.543081, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 028, Runtime 32.270229, Loss 3.763716, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 029, Runtime 26.223267, Loss 3.575690, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 030, Runtime 26.910009, Loss 3.715980, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 031, Runtime 28.530442, Loss 3.858094, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 032, Runtime 28.414308, Loss 3.377145, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 033, Runtime 30.297011, Loss 4.078362, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 034, Runtime 32.032728, Loss 3.486354, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 035, Runtime 33.122358, Loss 3.444807, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 036, Runtime 33.949671, Loss 3.665611, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 037, Runtime 34.917229, Loss 3.425805, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 038, Runtime 35.503508, Loss 3.859084, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 039, Runtime 36.405781, Loss 3.615933, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 040, Runtime 24.821685, Loss 3.376282, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 041, Runtime 24.016676, Loss 3.678312, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 042, Runtime 24.657021, Loss 3.599499, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 043, Runtime 24.702397, Loss 3.731818, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 044, Runtime 24.678633, Loss 3.511714, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 045, Runtime 24.629703, Loss 3.802584, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 046, Runtime 24.483115, Loss 3.433663, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 047, Runtime 24.692126, Loss 3.902184, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 048, Runtime 25.370979, Loss 3.364786, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 049, Runtime 25.991157, Loss 3.649886, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 050, Runtime 27.571389, Loss 3.391774, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 051, Runtime 27.916800, Loss 3.696582, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 052, Runtime 29.565222, Loss 3.956913, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 053, Runtime 30.580033, Loss 3.640227, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 054, Runtime 31.788718, Loss 3.450474, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 055, Runtime 32.645221, Loss 3.413608, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 056, Runtime 33.433292, Loss 3.515656, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 057, Runtime 34.216413, Loss 3.448193, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 058, Runtime 35.156469, Loss 3.635208, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 059, Runtime 34.114070, Loss 3.967201, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 060, Runtime 34.553452, Loss 3.637959, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 061, Runtime 34.877455, Loss 3.743025, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 062, Runtime 34.514517, Loss 3.105667, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 063, Runtime 35.386847, Loss 4.028345, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 064, Runtime 30.189320, Loss 3.388577, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 065, Runtime 23.566508, Loss 3.445755, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 066, Runtime 24.771450, Loss 3.483912, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 067, Runtime 25.626662, Loss 3.648713, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 068, Runtime 26.583028, Loss 3.402602, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 069, Runtime 27.728009, Loss 3.620219, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 070, Runtime 28.809391, Loss 3.542198, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 071, Runtime 29.855035, Loss 3.509421, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 072, Runtime 30.341114, Loss 3.398378, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 073, Runtime 30.581131, Loss 3.479909, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 074, Runtime 30.344290, Loss 3.676602, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 075, Runtime 31.407605, Loss 3.410760, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 076, Runtime 31.785751, Loss 3.902847, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 077, Runtime 32.659279, Loss 3.207581, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 078, Runtime 32.948169, Loss 3.503159, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 079, Runtime 33.450451, Loss 2.908449, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 080, Runtime 34.176559, Loss 3.780560, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 081, Runtime 35.295609, Loss 3.328639, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 082, Runtime 31.380100, Loss 3.558687, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 083, Runtime 23.606338, Loss 3.545441, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 084, Runtime 24.105154, Loss 3.210689, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 085, Runtime 25.584090, Loss 3.665857, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 086, Runtime 25.537994, Loss 3.581639, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 087, Runtime 25.010208, Loss 3.579732, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 088, Runtime 25.828717, Loss 3.676032, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 089, Runtime 26.938690, Loss 3.271472, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 090, Runtime 27.504646, Loss 3.669453, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 091, Runtime 28.647743, Loss 3.032179, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 092, Runtime 29.318258, Loss 3.540979, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 093, Runtime 29.871017, Loss 3.871603, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 094, Runtime 33.975521, Loss 3.454761, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 095, Runtime 34.706537, Loss 3.175045, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 096, Runtime 33.105141, Loss 3.285532, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 097, Runtime 32.885073, Loss 3.491195, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 098, Runtime 32.346972, Loss 3.544779, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
Epoch: 099, Runtime 32.183209, Loss 3.557452, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3007, Test: 0.3025, Best time: 18.2948
best val accuracy 0.300735 with test accuracy 0.302538 at epoch 17 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.21116751269035533
Entropy Threshold: 2 Test accuracy: 0.1949238578680203
Entropy Threshold: 1.6 Test accuracy: 0.22083333333333333
Entropy Threshold: 1.5 Test accuracy: 0.21568627450980393
Entropy Threshold: 1.4 Test accuracy: 0.04
Entropy Threshold: 1.3 Test accuracy: 0.0
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
