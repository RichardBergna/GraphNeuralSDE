[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 10.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 44.176559, Loss 6.817527, forward nfe 76, backward nfe 0, Train: 0.1143, Val: 0.1471, Test: 0.1645, Best time: 18.2948
Epoch: 002, Runtime 86.525684, Loss 127.498856, forward nfe 372, backward nfe 0, Train: 0.1143, Val: 0.1471, Test: 0.1645, Best time: 18.2948
Epoch: 003, Runtime 26.099540, Loss 7.027711, forward nfe 668, backward nfe 0, Train: 0.1143, Val: 0.1471, Test: 0.1645, Best time: 18.2948
Epoch: 004, Runtime 25.901548, Loss 8.521722, forward nfe 964, backward nfe 0, Train: 0.1143, Val: 0.1471, Test: 0.1645, Best time: 18.2948
Epoch: 005, Runtime 28.151173, Loss 9.545508, forward nfe 1260, backward nfe 0, Train: 0.1143, Val: 0.1471, Test: 0.1645, Best time: 18.2948
Epoch: 006, Runtime 31.192167, Loss 9.535923, forward nfe 1556, backward nfe 0, Train: 0.1929, Val: 0.2360, Test: 0.2254, Best time: 54.8843
Epoch: 007, Runtime 29.227767, Loss 8.626923, forward nfe 1852, backward nfe 0, Train: 0.1643, Val: 0.3000, Test: 0.2812, Best time: 54.8843
Epoch: 008, Runtime 29.508964, Loss 7.782786, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.3066, Test: 0.2863, Best time: 53.0000
Epoch: 009, Runtime 28.234660, Loss 5.965864, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.3088, Test: 0.2873, Best time: 48.0000
Epoch: 010, Runtime 27.503393, Loss 4.804530, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2883, Best time: 40.0000
Epoch: 011, Runtime 26.622468, Loss 5.001248, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 28.0000
Epoch: 012, Runtime 26.564002, Loss 5.211089, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 18.2948
Epoch: 013, Runtime 27.343514, Loss 5.305496, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.3110, Test: 0.2853, Best time: 38.0000
Epoch: 014, Runtime 25.730444, Loss 5.081138, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 36.0000
Epoch: 015, Runtime 25.449169, Loss 5.203264, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 016, Runtime 26.005529, Loss 4.585338, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 017, Runtime 26.928677, Loss 4.273728, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 018, Runtime 27.494158, Loss 4.697490, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 019, Runtime 29.183633, Loss 4.291392, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 020, Runtime 28.975955, Loss 4.417251, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 021, Runtime 29.253331, Loss 4.034981, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 022, Runtime 29.587914, Loss 3.984789, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 023, Runtime 31.103656, Loss 3.813940, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 024, Runtime 32.040478, Loss 3.722320, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 025, Runtime 33.287378, Loss 3.897799, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 026, Runtime 33.892182, Loss 3.666394, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 027, Runtime 33.767077, Loss 3.894444, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 028, Runtime 34.816424, Loss 3.511357, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 029, Runtime 35.645295, Loss 3.843596, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 030, Runtime 36.763291, Loss 3.822968, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 031, Runtime 25.154495, Loss 3.855440, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 032, Runtime 23.478808, Loss 3.981802, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 033, Runtime 24.077829, Loss 3.669598, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 034, Runtime 24.602951, Loss 3.569459, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 035, Runtime 25.742460, Loss 3.743461, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 036, Runtime 26.777684, Loss 3.546723, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 037, Runtime 27.817719, Loss 3.704734, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 038, Runtime 28.572525, Loss 3.609041, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 039, Runtime 29.576208, Loss 3.319072, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 040, Runtime 30.238672, Loss 3.335625, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 041, Runtime 31.870265, Loss 3.755897, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 042, Runtime 32.290876, Loss 3.511157, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 043, Runtime 33.233323, Loss 3.245223, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 044, Runtime 33.378322, Loss 3.451724, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 045, Runtime 34.076126, Loss 3.660779, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 046, Runtime 33.590696, Loss 3.500009, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 047, Runtime 34.640234, Loss 3.529288, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 048, Runtime 35.986199, Loss 3.474341, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 049, Runtime 35.965914, Loss 3.554939, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 050, Runtime 36.395409, Loss 3.447410, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 051, Runtime 36.544969, Loss 3.077808, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 052, Runtime 32.798565, Loss 3.177078, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 053, Runtime 24.039298, Loss 3.437454, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 054, Runtime 24.747617, Loss 3.470919, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 055, Runtime 25.411992, Loss 3.454449, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 056, Runtime 25.080320, Loss 3.482771, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 057, Runtime 25.754619, Loss 3.453697, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 058, Runtime 27.364556, Loss 3.283591, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 059, Runtime 28.914669, Loss 3.361302, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 060, Runtime 29.613448, Loss 3.040059, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 061, Runtime 29.570311, Loss 3.014315, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 062, Runtime 31.438094, Loss 3.208822, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 063, Runtime 32.802232, Loss 3.438450, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 064, Runtime 33.247626, Loss 3.391450, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 065, Runtime 33.981188, Loss 3.128179, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 066, Runtime 35.418948, Loss 2.902485, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 067, Runtime 35.362868, Loss 3.122782, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 068, Runtime 36.286001, Loss 3.201391, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 069, Runtime 35.999585, Loss 3.131231, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 070, Runtime 36.365874, Loss 2.947001, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 071, Runtime 37.337356, Loss 3.227221, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 072, Runtime 37.864772, Loss 3.302032, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 073, Runtime 38.211268, Loss 3.122134, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 074, Runtime 34.127322, Loss 3.282860, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 075, Runtime 24.811547, Loss 3.012936, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 076, Runtime 26.309802, Loss 2.942323, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 077, Runtime 26.930163, Loss 2.966030, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 078, Runtime 27.637442, Loss 3.073661, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 079, Runtime 28.324346, Loss 3.079882, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 080, Runtime 29.744473, Loss 3.143284, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 081, Runtime 30.138841, Loss 3.253356, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 082, Runtime 31.389459, Loss 2.829835, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 083, Runtime 32.238231, Loss 3.219197, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 084, Runtime 33.118526, Loss 3.372698, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 085, Runtime 33.775755, Loss 3.270185, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 086, Runtime 34.563892, Loss 2.999220, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 087, Runtime 34.871503, Loss 3.028146, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 088, Runtime 35.198516, Loss 3.209761, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 089, Runtime 35.680885, Loss 3.012269, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 090, Runtime 35.587292, Loss 2.872522, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 091, Runtime 36.341810, Loss 2.837612, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 092, Runtime 37.332265, Loss 2.863396, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 093, Runtime 24.494162, Loss 2.810667, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 094, Runtime 23.866443, Loss 3.100077, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 095, Runtime 24.636566, Loss 2.913987, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 096, Runtime 25.646136, Loss 2.873085, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 097, Runtime 26.469039, Loss 2.833824, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 098, Runtime 28.295192, Loss 2.938825, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
Epoch: 099, Runtime 28.717615, Loss 2.976021, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3118, Test: 0.2843, Best time: 18.2948
best val accuracy 0.311765 with test accuracy 0.284264 at epoch 14 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.25888324873096447
Entropy Threshold: 2 Test accuracy: 0.22842639593908629
Entropy Threshold: 1.6 Test accuracy: 0.24273858921161826
Entropy Threshold: 1.5 Test accuracy: 0.2582216808769793
Entropy Threshold: 1.4 Test accuracy: 0.2706333973128599
Entropy Threshold: 1.3 Test accuracy: 0.27074235807860264
Entropy Threshold: 1.2 Test accuracy: 0.19047619047619047
Entropy Threshold: 1.1 Test accuracy: 0.25925925925925924
Entropy Threshold: 0.9 Test accuracy: 0.5
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
