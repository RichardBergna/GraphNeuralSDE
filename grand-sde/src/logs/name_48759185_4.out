[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.4
t1 1.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 10.731353, Loss 2.044893, forward nfe 76, backward nfe 0, Train: 0.2786, Val: 0.3618, Test: 0.3523, Best time: 2.0000
Epoch: 002, Runtime 9.710622, Loss 2.594959, forward nfe 372, backward nfe 0, Train: 0.5786, Val: 0.4015, Test: 0.4112, Best time: 3.0000
Epoch: 003, Runtime 9.676282, Loss 2.099046, forward nfe 668, backward nfe 0, Train: 0.6571, Val: 0.5066, Test: 0.5117, Best time: 3.0000
Epoch: 004, Runtime 9.641124, Loss 1.978835, forward nfe 964, backward nfe 0, Train: 0.7000, Val: 0.6382, Test: 0.6569, Best time: 5.0000
Epoch: 005, Runtime 9.615745, Loss 1.886895, forward nfe 1260, backward nfe 0, Train: 0.7786, Val: 0.7037, Test: 0.7127, Best time: 4.0000
Epoch: 006, Runtime 9.618967, Loss 1.773291, forward nfe 1556, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 12.0000
Epoch: 007, Runtime 9.537488, Loss 1.708600, forward nfe 1852, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 008, Runtime 10.867800, Loss 1.535786, forward nfe 2148, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 009, Runtime 10.844153, Loss 1.393895, forward nfe 2444, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 010, Runtime 11.640229, Loss 1.324479, forward nfe 2740, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 011, Runtime 12.005573, Loss 1.164136, forward nfe 3036, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 012, Runtime 11.951102, Loss 1.080497, forward nfe 3332, backward nfe 0, Train: 0.8643, Val: 0.7456, Test: 0.7604, Best time: 18.2948
Epoch: 013, Runtime 12.136454, Loss 0.932359, forward nfe 3628, backward nfe 0, Train: 0.9143, Val: 0.7596, Test: 0.7635, Best time: 8.0000
Epoch: 014, Runtime 11.417611, Loss 0.833245, forward nfe 3924, backward nfe 0, Train: 0.9000, Val: 0.7846, Test: 0.7970, Best time: 6.0000
Epoch: 015, Runtime 11.387726, Loss 0.833698, forward nfe 4220, backward nfe 0, Train: 0.9357, Val: 0.7904, Test: 0.8020, Best time: 15.0000
Epoch: 016, Runtime 11.450987, Loss 0.745711, forward nfe 4516, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.0000
Epoch: 017, Runtime 11.308875, Loss 0.717080, forward nfe 4812, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 018, Runtime 11.719453, Loss 0.694273, forward nfe 5108, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 019, Runtime 11.669462, Loss 0.683939, forward nfe 5404, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 020, Runtime 11.604639, Loss 0.632929, forward nfe 5700, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 021, Runtime 11.985183, Loss 0.672567, forward nfe 5996, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 022, Runtime 11.942345, Loss 0.651124, forward nfe 6292, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 023, Runtime 12.053038, Loss 0.648366, forward nfe 6588, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 024, Runtime 12.394651, Loss 0.542790, forward nfe 6884, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 025, Runtime 12.104882, Loss 0.585244, forward nfe 7180, backward nfe 0, Train: 0.9214, Val: 0.7926, Test: 0.8061, Best time: 18.2948
Epoch: 026, Runtime 12.314207, Loss 0.527064, forward nfe 7476, backward nfe 0, Train: 0.9357, Val: 0.7934, Test: 0.7929, Best time: 30.0000
Epoch: 027, Runtime 11.038758, Loss 0.470981, forward nfe 7772, backward nfe 0, Train: 0.9357, Val: 0.7934, Test: 0.7929, Best time: 18.2948
Epoch: 028, Runtime 11.249955, Loss 0.500335, forward nfe 8068, backward nfe 0, Train: 0.9357, Val: 0.7934, Test: 0.7929, Best time: 18.2948
Epoch: 029, Runtime 10.932138, Loss 0.444959, forward nfe 8364, backward nfe 0, Train: 0.9357, Val: 0.7934, Test: 0.7929, Best time: 18.2948
Epoch: 030, Runtime 11.171665, Loss 0.525663, forward nfe 8660, backward nfe 0, Train: 0.9500, Val: 0.7941, Test: 0.8051, Best time: 35.0000
Epoch: 031, Runtime 10.556718, Loss 0.477212, forward nfe 8956, backward nfe 0, Train: 0.9500, Val: 0.7941, Test: 0.8051, Best time: 18.2948
Epoch: 032, Runtime 10.985167, Loss 0.508543, forward nfe 9252, backward nfe 0, Train: 0.9500, Val: 0.7941, Test: 0.8051, Best time: 18.2948
Epoch: 033, Runtime 10.847648, Loss 0.423122, forward nfe 9548, backward nfe 0, Train: 0.9500, Val: 0.7941, Test: 0.8051, Best time: 18.2948
Epoch: 034, Runtime 10.836502, Loss 0.440766, forward nfe 9844, backward nfe 0, Train: 0.9500, Val: 0.7941, Test: 0.8051, Best time: 18.2948
Epoch: 035, Runtime 11.170577, Loss 0.497782, forward nfe 10140, backward nfe 0, Train: 0.9500, Val: 0.7956, Test: 0.7919, Best time: 50.0000
Epoch: 036, Runtime 10.339926, Loss 0.475790, forward nfe 10436, backward nfe 0, Train: 0.9500, Val: 0.8015, Test: 0.8051, Best time: 35.0000
Epoch: 037, Runtime 10.162291, Loss 0.542020, forward nfe 10732, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 42.0000
Epoch: 038, Runtime 10.090848, Loss 0.437547, forward nfe 11028, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 18.2948
Epoch: 039, Runtime 10.467711, Loss 0.388742, forward nfe 11324, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 18.2948
Epoch: 040, Runtime 10.340296, Loss 0.418304, forward nfe 11620, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 18.2948
Epoch: 041, Runtime 10.244820, Loss 0.466189, forward nfe 11916, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 18.2948
Epoch: 042, Runtime 10.628251, Loss 0.407312, forward nfe 12212, backward nfe 0, Train: 0.9571, Val: 0.8037, Test: 0.8081, Best time: 18.2948
Epoch: 043, Runtime 10.697349, Loss 0.381375, forward nfe 12508, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 47.0000
Epoch: 044, Runtime 9.938278, Loss 0.417908, forward nfe 12804, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 045, Runtime 11.284557, Loss 0.393087, forward nfe 13100, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 046, Runtime 11.613442, Loss 0.353131, forward nfe 13396, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 047, Runtime 11.675666, Loss 0.369738, forward nfe 13692, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 048, Runtime 12.011480, Loss 0.327752, forward nfe 13988, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 049, Runtime 11.911781, Loss 0.453126, forward nfe 14284, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 050, Runtime 12.041594, Loss 0.442844, forward nfe 14580, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 051, Runtime 12.466670, Loss 0.386774, forward nfe 14876, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 052, Runtime 12.259415, Loss 0.318050, forward nfe 15172, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 053, Runtime 12.301161, Loss 0.308609, forward nfe 15468, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 054, Runtime 12.651999, Loss 0.300693, forward nfe 15764, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 055, Runtime 12.573303, Loss 0.332396, forward nfe 16060, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 056, Runtime 12.673907, Loss 0.363957, forward nfe 16356, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 057, Runtime 12.894037, Loss 0.354089, forward nfe 16652, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 058, Runtime 12.872983, Loss 0.299811, forward nfe 16948, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 059, Runtime 12.833298, Loss 0.292095, forward nfe 17244, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 060, Runtime 13.031123, Loss 0.345868, forward nfe 17540, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 061, Runtime 13.084894, Loss 0.288949, forward nfe 17836, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 062, Runtime 13.028270, Loss 0.384789, forward nfe 18132, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 063, Runtime 13.291759, Loss 0.295875, forward nfe 18428, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 064, Runtime 13.235632, Loss 0.230376, forward nfe 18724, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 065, Runtime 13.377979, Loss 0.265789, forward nfe 19020, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 066, Runtime 13.413875, Loss 0.324305, forward nfe 19316, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 067, Runtime 13.491583, Loss 0.346668, forward nfe 19612, backward nfe 0, Train: 0.9429, Val: 0.8066, Test: 0.8122, Best time: 18.2948
Epoch: 068, Runtime 13.550853, Loss 0.297542, forward nfe 19908, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 28.0000
Epoch: 069, Runtime 11.204015, Loss 0.346429, forward nfe 20204, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 070, Runtime 11.529476, Loss 0.228562, forward nfe 20500, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 071, Runtime 11.488825, Loss 0.267300, forward nfe 20796, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 072, Runtime 10.826023, Loss 0.353196, forward nfe 21092, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 073, Runtime 10.356947, Loss 0.187484, forward nfe 21388, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 074, Runtime 10.214881, Loss 0.273771, forward nfe 21684, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 075, Runtime 10.247288, Loss 0.200584, forward nfe 21980, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 076, Runtime 10.547626, Loss 0.267582, forward nfe 22276, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 077, Runtime 10.454116, Loss 0.290861, forward nfe 22572, backward nfe 0, Train: 0.9786, Val: 0.8154, Test: 0.8112, Best time: 18.2948
Epoch: 078, Runtime 10.644524, Loss 0.272528, forward nfe 22868, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 40.0000
Epoch: 079, Runtime 9.536598, Loss 0.298961, forward nfe 23164, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 080, Runtime 9.812848, Loss 0.361057, forward nfe 23460, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 081, Runtime 9.774722, Loss 0.344736, forward nfe 23756, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 082, Runtime 9.872970, Loss 0.358358, forward nfe 24052, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 083, Runtime 10.079442, Loss 0.265859, forward nfe 24348, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 084, Runtime 9.906687, Loss 0.274258, forward nfe 24644, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 085, Runtime 9.963021, Loss 0.141576, forward nfe 24940, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 086, Runtime 9.746324, Loss 0.213784, forward nfe 25236, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 087, Runtime 9.487310, Loss 0.312746, forward nfe 25532, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 088, Runtime 9.237908, Loss 0.258260, forward nfe 25828, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 089, Runtime 9.798540, Loss 0.214566, forward nfe 26124, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 090, Runtime 9.858143, Loss 0.263008, forward nfe 26420, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 091, Runtime 9.977588, Loss 0.328401, forward nfe 26716, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 092, Runtime 10.004746, Loss 0.234909, forward nfe 27012, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 093, Runtime 10.078181, Loss 0.226012, forward nfe 27308, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 094, Runtime 10.276286, Loss 0.279686, forward nfe 27604, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 095, Runtime 10.402622, Loss 0.259415, forward nfe 27900, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 096, Runtime 10.296122, Loss 0.186780, forward nfe 28196, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 097, Runtime 10.174406, Loss 0.308168, forward nfe 28492, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 098, Runtime 10.407546, Loss 0.264984, forward nfe 28788, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
Epoch: 099, Runtime 10.322429, Loss 0.197924, forward nfe 29084, backward nfe 0, Train: 0.9714, Val: 0.8272, Test: 0.8203, Best time: 18.2948
best val accuracy 0.827206 with test accuracy 0.820305 at epoch 78 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8406091370558376
Entropy Threshold: 2 Test accuracy: 0.8426395939086294
Entropy Threshold: 1.6 Test accuracy: 0.8389398572884812
Entropy Threshold: 1.5 Test accuracy: 0.8411885245901639
Entropy Threshold: 1.4 Test accuracy: 0.8549060542797495
Entropy Threshold: 1.3 Test accuracy: 0.857293868921776
Entropy Threshold: 1.2 Test accuracy: 0.8540772532188842
Entropy Threshold: 1.1 Test accuracy: 0.8605664488017429
Entropy Threshold: 0.9 Test accuracy: 0.8686046511627907
Entropy Threshold: 0.8 Test accuracy: 0.8863636363636364
Entropy Threshold: 0.7 Test accuracy: 0.9053708439897699
Entropy Threshold: 0.6 Test accuracy: 0.918809201623816
Entropy Threshold: 0.5 Test accuracy: 0.9246088193456614
Entropy Threshold: 0.4 Test accuracy: 0.9296407185628742
Entropy Threshold: 0.3 Test accuracy: 0.9321192052980133
Entropy Threshold: 0.2 Test accuracy: 0.9389587073608617
Entropy Threshold: 0.1 Test accuracy: 0.9449152542372882
