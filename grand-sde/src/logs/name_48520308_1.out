[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 8.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 32.455545, Loss 5.502775, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1441, Test: 0.1299, Best time: 18.2948
Epoch: 002, Runtime 52.673817, Loss 75.691406, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 54.0000
Epoch: 003, Runtime 20.792110, Loss 4.056531, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 004, Runtime 20.454991, Loss 3.746594, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 005, Runtime 19.991262, Loss 4.071532, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 006, Runtime 21.248245, Loss 3.922465, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 007, Runtime 21.790143, Loss 3.849635, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 008, Runtime 23.220289, Loss 4.080190, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 009, Runtime 23.885025, Loss 3.634310, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.1566, Test: 0.1472, Best time: 18.2948
Epoch: 010, Runtime 24.817052, Loss 3.449060, forward nfe 2740, backward nfe 0, Train: 0.1786, Val: 0.2434, Test: 0.2457, Best time: 54.8843
Epoch: 011, Runtime 20.411023, Loss 3.537635, forward nfe 3036, backward nfe 0, Train: 0.1500, Val: 0.2750, Test: 0.2985, Best time: 54.8843
Epoch: 012, Runtime 20.508900, Loss 3.229363, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.2794, Test: 0.2964, Best time: 53.0000
Epoch: 013, Runtime 20.213287, Loss 3.088695, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.2794, Test: 0.2964, Best time: 18.2948
Epoch: 014, Runtime 20.775620, Loss 3.076097, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 49.0000
Epoch: 015, Runtime 20.106008, Loss 3.173663, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 016, Runtime 20.299931, Loss 3.015781, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 017, Runtime 20.277187, Loss 3.076550, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 018, Runtime 20.804572, Loss 2.795839, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 019, Runtime 21.577123, Loss 3.102947, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 020, Runtime 22.929069, Loss 2.781240, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 021, Runtime 23.400641, Loss 3.308045, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 022, Runtime 23.083086, Loss 2.850027, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 023, Runtime 23.590210, Loss 3.034311, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 024, Runtime 24.349395, Loss 2.847456, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 025, Runtime 23.857112, Loss 2.893777, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 026, Runtime 25.186328, Loss 3.045303, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 027, Runtime 25.487021, Loss 2.977538, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 028, Runtime 25.806033, Loss 2.743387, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 029, Runtime 25.477133, Loss 2.974421, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 030, Runtime 26.125217, Loss 2.793956, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 031, Runtime 26.099071, Loss 2.776986, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 032, Runtime 26.416853, Loss 2.790627, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 033, Runtime 26.727172, Loss 3.075669, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 034, Runtime 26.888399, Loss 2.659835, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 035, Runtime 26.577400, Loss 2.747567, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 036, Runtime 27.073840, Loss 2.640948, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 037, Runtime 27.005706, Loss 3.033319, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 038, Runtime 27.512341, Loss 2.997424, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 039, Runtime 27.330626, Loss 2.971281, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 040, Runtime 27.539062, Loss 2.839342, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 041, Runtime 27.350528, Loss 2.556578, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 042, Runtime 27.041093, Loss 2.707825, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 043, Runtime 26.984356, Loss 2.614766, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 044, Runtime 27.001123, Loss 2.946932, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 045, Runtime 27.004693, Loss 2.697740, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 046, Runtime 27.110114, Loss 2.386396, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 047, Runtime 27.331024, Loss 2.771209, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 048, Runtime 24.018792, Loss 2.723402, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 049, Runtime 18.333146, Loss 2.783434, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 050, Runtime 18.846181, Loss 2.802049, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 051, Runtime 19.297932, Loss 2.622051, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 052, Runtime 19.729563, Loss 2.752975, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 053, Runtime 20.675609, Loss 2.835069, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 054, Runtime 20.856130, Loss 2.894755, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 055, Runtime 21.036004, Loss 2.758100, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 056, Runtime 21.723490, Loss 2.527896, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 057, Runtime 22.025302, Loss 2.761723, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 058, Runtime 22.573592, Loss 2.754755, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 059, Runtime 23.322507, Loss 2.668963, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 060, Runtime 23.641039, Loss 2.696186, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 061, Runtime 23.990195, Loss 2.717211, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 062, Runtime 24.022315, Loss 2.707792, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 063, Runtime 24.075287, Loss 2.431499, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 064, Runtime 24.284038, Loss 2.546199, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 065, Runtime 24.585641, Loss 2.726268, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 066, Runtime 24.863776, Loss 2.547340, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 067, Runtime 24.941967, Loss 2.594430, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 068, Runtime 24.968674, Loss 2.876373, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 069, Runtime 25.511423, Loss 2.724883, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 070, Runtime 25.259700, Loss 2.491322, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 071, Runtime 25.989193, Loss 2.448561, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 072, Runtime 25.998173, Loss 2.687357, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 073, Runtime 26.122164, Loss 2.539433, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 074, Runtime 26.326273, Loss 2.590954, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 075, Runtime 23.079455, Loss 2.617661, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 076, Runtime 17.450687, Loss 2.665673, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 077, Runtime 17.581834, Loss 2.624655, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 078, Runtime 17.861370, Loss 2.549003, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 079, Runtime 18.165006, Loss 2.638009, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 080, Runtime 18.316077, Loss 2.661716, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 081, Runtime 18.327295, Loss 2.600608, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 082, Runtime 18.813654, Loss 2.788228, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 083, Runtime 18.537001, Loss 2.632055, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 084, Runtime 18.160399, Loss 2.623038, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 085, Runtime 18.283099, Loss 2.434601, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 086, Runtime 18.421812, Loss 2.462561, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 087, Runtime 18.615642, Loss 2.578313, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 088, Runtime 19.191264, Loss 2.535602, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 089, Runtime 18.835365, Loss 2.649422, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 090, Runtime 19.393158, Loss 2.560736, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 091, Runtime 19.752744, Loss 2.560825, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 092, Runtime 19.801621, Loss 2.632033, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 093, Runtime 19.984155, Loss 2.735945, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 094, Runtime 20.219739, Loss 2.486043, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 095, Runtime 20.412928, Loss 2.721703, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 096, Runtime 20.653377, Loss 2.564448, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 097, Runtime 20.977067, Loss 2.636100, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 098, Runtime 20.911554, Loss 2.652427, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
Epoch: 099, Runtime 21.183455, Loss 2.707280, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.2824, Test: 0.2964, Best time: 18.2948
best val accuracy 0.282353 with test accuracy 0.296447 at epoch 14 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.14416243654822336
Entropy Threshold: 2 Test accuracy: 0.14213197969543148
Entropy Threshold: 1.6 Test accuracy: 0.12403100775193798
Entropy Threshold: 1.5 Test accuracy: 0.16216216216216217
Entropy Threshold: 1.4 Test accuracy: 0.07692307692307693
Entropy Threshold: 1.3 Test accuracy: 0.0
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
