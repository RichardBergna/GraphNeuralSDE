[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 3.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 17.491877, Loss 2.603526, forward nfe 76, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 3.0000
Epoch: 002, Runtime 24.212643, Loss 5.140860, forward nfe 372, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 003, Runtime 15.429046, Loss 2.614539, forward nfe 668, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 004, Runtime 15.303868, Loss 2.852466, forward nfe 964, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 005, Runtime 16.577488, Loss 2.737554, forward nfe 1260, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 006, Runtime 17.534092, Loss 2.902852, forward nfe 1556, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 007, Runtime 18.255329, Loss 2.996572, forward nfe 1852, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 008, Runtime 19.357099, Loss 2.855206, forward nfe 2148, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 009, Runtime 19.507171, Loss 2.691666, forward nfe 2444, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 010, Runtime 19.259022, Loss 2.586202, forward nfe 2740, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 011, Runtime 19.443261, Loss 2.357085, forward nfe 3036, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 012, Runtime 19.520510, Loss 2.549970, forward nfe 3332, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 013, Runtime 19.502212, Loss 2.589259, forward nfe 3628, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 014, Runtime 19.681785, Loss 2.439717, forward nfe 3924, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 015, Runtime 19.867945, Loss 2.535087, forward nfe 4220, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 016, Runtime 19.944036, Loss 2.546097, forward nfe 4516, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 017, Runtime 20.114794, Loss 2.455084, forward nfe 4812, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 018, Runtime 20.642899, Loss 2.385229, forward nfe 5108, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 019, Runtime 20.609838, Loss 2.389491, forward nfe 5404, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 020, Runtime 20.793989, Loss 2.240520, forward nfe 5700, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 021, Runtime 20.611714, Loss 2.241609, forward nfe 5996, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 022, Runtime 20.677764, Loss 2.364689, forward nfe 6292, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 023, Runtime 20.522430, Loss 2.225563, forward nfe 6588, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 024, Runtime 21.181269, Loss 2.280594, forward nfe 6884, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 025, Runtime 21.270774, Loss 2.275270, forward nfe 7180, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 026, Runtime 21.364172, Loss 2.262521, forward nfe 7476, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 027, Runtime 21.268462, Loss 2.344648, forward nfe 7772, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 028, Runtime 21.670768, Loss 2.164930, forward nfe 8068, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 029, Runtime 21.644611, Loss 2.181183, forward nfe 8364, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 030, Runtime 21.785659, Loss 2.175833, forward nfe 8660, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 031, Runtime 21.809078, Loss 2.207622, forward nfe 8956, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 032, Runtime 21.913504, Loss 2.166484, forward nfe 9252, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 033, Runtime 22.055492, Loss 2.208324, forward nfe 9548, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 034, Runtime 21.858103, Loss 2.289710, forward nfe 9844, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 035, Runtime 22.076387, Loss 2.188811, forward nfe 10140, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 036, Runtime 22.762896, Loss 2.302639, forward nfe 10436, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 037, Runtime 22.697726, Loss 2.096630, forward nfe 10732, backward nfe 0, Train: 0.3286, Val: 0.2301, Test: 0.2396, Best time: 18.2948
Epoch: 038, Runtime 22.980575, Loss 2.275265, forward nfe 11028, backward nfe 0, Train: 0.3286, Val: 0.2507, Test: 0.2548, Best time: 1.0000
Epoch: 039, Runtime 15.165967, Loss 2.292184, forward nfe 11324, backward nfe 0, Train: 0.3857, Val: 0.2684, Test: 0.2751, Best time: 2.0000
Epoch: 040, Runtime 15.450038, Loss 2.278057, forward nfe 11620, backward nfe 0, Train: 0.3929, Val: 0.2978, Test: 0.3066, Best time: 4.0000
Epoch: 041, Runtime 15.236852, Loss 2.096783, forward nfe 11916, backward nfe 0, Train: 0.4286, Val: 0.3243, Test: 0.3421, Best time: 5.0000
Epoch: 042, Runtime 15.348791, Loss 2.201805, forward nfe 12212, backward nfe 0, Train: 0.4929, Val: 0.3456, Test: 0.3807, Best time: 3.0000
Epoch: 043, Runtime 15.205868, Loss 2.178491, forward nfe 12508, backward nfe 0, Train: 0.5143, Val: 0.3654, Test: 0.3909, Best time: 3.0000
Epoch: 044, Runtime 15.475483, Loss 2.284568, forward nfe 12804, backward nfe 0, Train: 0.5214, Val: 0.3757, Test: 0.4010, Best time: 6.0000
Epoch: 045, Runtime 15.469849, Loss 2.075532, forward nfe 13100, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 6.0000
Epoch: 046, Runtime 15.331203, Loss 2.180182, forward nfe 13396, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 047, Runtime 15.624175, Loss 2.142977, forward nfe 13692, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 048, Runtime 16.008626, Loss 2.138941, forward nfe 13988, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 049, Runtime 16.422465, Loss 2.187015, forward nfe 14284, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 050, Runtime 17.177286, Loss 2.198430, forward nfe 14580, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 051, Runtime 17.875519, Loss 2.091206, forward nfe 14876, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 052, Runtime 18.184747, Loss 2.132157, forward nfe 15172, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 053, Runtime 18.701249, Loss 2.110927, forward nfe 15468, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 054, Runtime 19.448230, Loss 2.144407, forward nfe 15764, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 055, Runtime 19.762800, Loss 2.096032, forward nfe 16060, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 056, Runtime 19.984577, Loss 2.076681, forward nfe 16356, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 057, Runtime 20.726336, Loss 1.993823, forward nfe 16652, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 058, Runtime 21.049140, Loss 2.020039, forward nfe 16948, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 059, Runtime 21.208192, Loss 2.122092, forward nfe 17244, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 060, Runtime 22.104778, Loss 2.084697, forward nfe 17540, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 061, Runtime 22.385181, Loss 2.139659, forward nfe 17836, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 062, Runtime 22.590572, Loss 2.040385, forward nfe 18132, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 063, Runtime 23.034720, Loss 2.048814, forward nfe 18428, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 064, Runtime 23.186576, Loss 2.046044, forward nfe 18724, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 065, Runtime 23.374847, Loss 2.038162, forward nfe 19020, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 066, Runtime 23.429324, Loss 2.106173, forward nfe 19316, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 067, Runtime 23.685230, Loss 2.090627, forward nfe 19612, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 068, Runtime 23.748685, Loss 2.065587, forward nfe 19908, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 069, Runtime 24.131502, Loss 2.027305, forward nfe 20204, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 070, Runtime 24.107605, Loss 2.089273, forward nfe 20500, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 071, Runtime 24.159444, Loss 2.057371, forward nfe 20796, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 072, Runtime 24.519197, Loss 2.089712, forward nfe 21092, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 073, Runtime 24.767851, Loss 1.966477, forward nfe 21388, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 074, Runtime 24.735667, Loss 1.983379, forward nfe 21684, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 075, Runtime 25.108655, Loss 2.023618, forward nfe 21980, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 076, Runtime 25.270777, Loss 1.994480, forward nfe 22276, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 077, Runtime 25.397778, Loss 2.001095, forward nfe 22572, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 078, Runtime 25.555046, Loss 2.018210, forward nfe 22868, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 079, Runtime 21.829509, Loss 2.107432, forward nfe 23164, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 080, Runtime 16.715915, Loss 2.072007, forward nfe 23460, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 081, Runtime 17.440656, Loss 2.004675, forward nfe 23756, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 082, Runtime 18.094527, Loss 2.052052, forward nfe 24052, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 083, Runtime 18.299338, Loss 2.063880, forward nfe 24348, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 084, Runtime 18.966803, Loss 1.974000, forward nfe 24644, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 085, Runtime 19.429570, Loss 2.084050, forward nfe 24940, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 086, Runtime 19.823092, Loss 1.967331, forward nfe 25236, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 087, Runtime 20.680382, Loss 2.073808, forward nfe 25532, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 088, Runtime 20.819468, Loss 2.077612, forward nfe 25828, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 089, Runtime 21.167169, Loss 2.021842, forward nfe 26124, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 090, Runtime 21.672251, Loss 1.979839, forward nfe 26420, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 091, Runtime 22.042092, Loss 2.024939, forward nfe 26716, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 092, Runtime 22.224718, Loss 1.952069, forward nfe 27012, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 093, Runtime 22.708626, Loss 1.981268, forward nfe 27308, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 094, Runtime 23.031008, Loss 1.968888, forward nfe 27604, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 095, Runtime 23.415055, Loss 1.987446, forward nfe 27900, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 096, Runtime 23.862166, Loss 2.025354, forward nfe 28196, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 097, Runtime 24.127273, Loss 2.003384, forward nfe 28492, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 098, Runtime 24.478273, Loss 1.944526, forward nfe 28788, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
Epoch: 099, Runtime 24.774162, Loss 1.964909, forward nfe 29084, backward nfe 0, Train: 0.5214, Val: 0.3787, Test: 0.4071, Best time: 18.2948
best val accuracy 0.378676 with test accuracy 0.407107 at epoch 45 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.12284263959390863
Entropy Threshold: 2 Test accuracy: 0.10456852791878173
Entropy Threshold: 1.6 Test accuracy: 0.0
Entropy Threshold: 1.5 Test accuracy: 0.0
Entropy Threshold: 1.4 Test accuracy: 0.0
Entropy Threshold: 1.3 Test accuracy: None
Entropy Threshold: 1.2 Test accuracy: None
Entropy Threshold: 1.1 Test accuracy: None
Entropy Threshold: 0.9 Test accuracy: None
Entropy Threshold: 0.8 Test accuracy: None
Entropy Threshold: 0.7 Test accuracy: None
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
