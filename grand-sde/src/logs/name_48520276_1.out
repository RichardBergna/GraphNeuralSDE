[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 7.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 31.802429, Loss 4.225892, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1206, Test: 0.1025, Best time: 18.2948
Epoch: 002, Runtime 40.965562, Loss 21.860025, forward nfe 372, backward nfe 0, Train: 0.1857, Val: 0.1654, Test: 0.1543, Best time: 8.0000
Epoch: 003, Runtime 21.394575, Loss 3.746629, forward nfe 668, backward nfe 0, Train: 0.2643, Val: 0.2404, Test: 0.2091, Best time: 4.0000
Epoch: 004, Runtime 20.744663, Loss 3.526877, forward nfe 964, backward nfe 0, Train: 0.2643, Val: 0.2404, Test: 0.2091, Best time: 18.2948
Epoch: 005, Runtime 20.929098, Loss 3.151442, forward nfe 1260, backward nfe 0, Train: 0.2643, Val: 0.2404, Test: 0.2091, Best time: 18.2948
Epoch: 006, Runtime 21.381030, Loss 2.925787, forward nfe 1556, backward nfe 0, Train: 0.2643, Val: 0.2404, Test: 0.2091, Best time: 18.2948
Epoch: 007, Runtime 23.020677, Loss 2.996438, forward nfe 1852, backward nfe 0, Train: 0.2643, Val: 0.2404, Test: 0.2091, Best time: 18.2948
Epoch: 008, Runtime 24.628532, Loss 3.003775, forward nfe 2148, backward nfe 0, Train: 0.1571, Val: 0.2441, Test: 0.2629, Best time: 13.0000
Epoch: 009, Runtime 22.562969, Loss 2.797935, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.2596, Test: 0.2772, Best time: 13.0000
Epoch: 010, Runtime 22.494640, Loss 2.879011, forward nfe 2740, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 13.0000
Epoch: 011, Runtime 22.364226, Loss 3.041530, forward nfe 3036, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 012, Runtime 22.951013, Loss 3.274102, forward nfe 3332, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 013, Runtime 22.302993, Loss 3.021748, forward nfe 3628, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 014, Runtime 22.897830, Loss 3.046058, forward nfe 3924, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 015, Runtime 23.141700, Loss 2.814003, forward nfe 4220, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 016, Runtime 23.551216, Loss 2.863791, forward nfe 4516, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 017, Runtime 24.160745, Loss 2.905425, forward nfe 4812, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 018, Runtime 24.734584, Loss 2.676937, forward nfe 5108, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 019, Runtime 24.785120, Loss 3.142876, forward nfe 5404, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 020, Runtime 25.927470, Loss 2.778620, forward nfe 5700, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 021, Runtime 25.638243, Loss 2.898333, forward nfe 5996, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 022, Runtime 26.132659, Loss 2.793435, forward nfe 6292, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 023, Runtime 26.775045, Loss 2.867754, forward nfe 6588, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 024, Runtime 26.800709, Loss 2.769055, forward nfe 6884, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 025, Runtime 26.877467, Loss 2.736427, forward nfe 7180, backward nfe 0, Train: 0.1357, Val: 0.2647, Test: 0.2751, Best time: 18.2948
Epoch: 026, Runtime 26.906009, Loss 2.768450, forward nfe 7476, backward nfe 0, Train: 0.1571, Val: 0.2728, Test: 0.2751, Best time: 20.0000
Epoch: 027, Runtime 18.748944, Loss 2.974558, forward nfe 7772, backward nfe 0, Train: 0.1357, Val: 0.2809, Test: 0.2883, Best time: 21.0000
Epoch: 028, Runtime 18.653196, Loss 2.622659, forward nfe 8068, backward nfe 0, Train: 0.1571, Val: 0.2868, Test: 0.2883, Best time: 21.0000
Epoch: 029, Runtime 18.198723, Loss 2.836268, forward nfe 8364, backward nfe 0, Train: 0.1500, Val: 0.2882, Test: 0.2883, Best time: 21.0000
Epoch: 030, Runtime 18.093557, Loss 2.781615, forward nfe 8660, backward nfe 0, Train: 0.1357, Val: 0.2904, Test: 0.2883, Best time: 22.0000
Epoch: 031, Runtime 17.174963, Loss 2.791807, forward nfe 8956, backward nfe 0, Train: 0.1357, Val: 0.2904, Test: 0.2883, Best time: 18.2948
Epoch: 032, Runtime 17.859087, Loss 2.696810, forward nfe 9252, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 23.0000
Epoch: 033, Runtime 17.063934, Loss 2.683470, forward nfe 9548, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 034, Runtime 17.117070, Loss 2.760172, forward nfe 9844, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 035, Runtime 17.403975, Loss 2.493598, forward nfe 10140, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 036, Runtime 18.221800, Loss 2.780147, forward nfe 10436, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 037, Runtime 18.655020, Loss 2.815261, forward nfe 10732, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 038, Runtime 19.411676, Loss 2.733653, forward nfe 11028, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 039, Runtime 20.369910, Loss 2.701903, forward nfe 11324, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 040, Runtime 20.898877, Loss 2.590613, forward nfe 11620, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 041, Runtime 21.177795, Loss 2.582996, forward nfe 11916, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 042, Runtime 21.470597, Loss 2.580174, forward nfe 12212, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 043, Runtime 21.853356, Loss 2.536125, forward nfe 12508, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 044, Runtime 22.080851, Loss 2.502245, forward nfe 12804, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 045, Runtime 22.666491, Loss 2.691592, forward nfe 13100, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 046, Runtime 22.758635, Loss 2.567930, forward nfe 13396, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 047, Runtime 23.058918, Loss 2.655341, forward nfe 13692, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 048, Runtime 24.200698, Loss 2.531844, forward nfe 13988, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 049, Runtime 25.051265, Loss 2.551927, forward nfe 14284, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 050, Runtime 25.409035, Loss 2.605860, forward nfe 14580, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 051, Runtime 25.269278, Loss 2.499918, forward nfe 14876, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 052, Runtime 25.607259, Loss 2.552491, forward nfe 15172, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 053, Runtime 25.586696, Loss 2.643257, forward nfe 15468, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 054, Runtime 24.785641, Loss 2.603333, forward nfe 15764, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 055, Runtime 24.781093, Loss 2.629202, forward nfe 16060, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 056, Runtime 24.850475, Loss 2.489619, forward nfe 16356, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 057, Runtime 25.398996, Loss 2.635724, forward nfe 16652, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 058, Runtime 25.174596, Loss 2.562732, forward nfe 16948, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 059, Runtime 25.729316, Loss 2.538538, forward nfe 17244, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 060, Runtime 26.070593, Loss 2.534483, forward nfe 17540, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 061, Runtime 26.321938, Loss 2.436521, forward nfe 17836, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 062, Runtime 27.254937, Loss 2.291754, forward nfe 18132, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 063, Runtime 27.612164, Loss 2.384264, forward nfe 18428, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 064, Runtime 23.695456, Loss 2.482617, forward nfe 18724, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 065, Runtime 18.189427, Loss 2.365254, forward nfe 19020, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 066, Runtime 18.606909, Loss 2.447356, forward nfe 19316, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 067, Runtime 19.127804, Loss 2.323141, forward nfe 19612, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 068, Runtime 19.217508, Loss 2.532360, forward nfe 19908, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 069, Runtime 20.026125, Loss 2.444920, forward nfe 20204, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 070, Runtime 20.688799, Loss 2.501548, forward nfe 20500, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 071, Runtime 21.445915, Loss 2.478983, forward nfe 20796, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 072, Runtime 22.144093, Loss 2.290012, forward nfe 21092, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 073, Runtime 22.196162, Loss 2.391792, forward nfe 21388, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 074, Runtime 22.721178, Loss 2.348648, forward nfe 21684, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 075, Runtime 23.366298, Loss 2.342557, forward nfe 21980, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 076, Runtime 23.644073, Loss 2.456345, forward nfe 22276, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 077, Runtime 24.172040, Loss 2.351001, forward nfe 22572, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 078, Runtime 24.382918, Loss 2.480258, forward nfe 22868, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 079, Runtime 24.788277, Loss 2.379261, forward nfe 23164, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 080, Runtime 24.898996, Loss 2.435923, forward nfe 23460, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 081, Runtime 25.452135, Loss 2.429042, forward nfe 23756, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 082, Runtime 25.587141, Loss 2.429918, forward nfe 24052, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 083, Runtime 25.218166, Loss 2.588352, forward nfe 24348, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 084, Runtime 25.262913, Loss 2.242841, forward nfe 24644, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 085, Runtime 25.627485, Loss 2.373624, forward nfe 24940, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 086, Runtime 25.664355, Loss 2.393060, forward nfe 25236, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 087, Runtime 25.722824, Loss 2.403988, forward nfe 25532, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 088, Runtime 25.822767, Loss 2.488426, forward nfe 25828, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 089, Runtime 25.691101, Loss 2.477497, forward nfe 26124, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 090, Runtime 26.480273, Loss 2.502592, forward nfe 26420, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 091, Runtime 22.944288, Loss 2.386705, forward nfe 26716, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 092, Runtime 17.732196, Loss 2.278128, forward nfe 27012, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 093, Runtime 17.757807, Loss 2.502316, forward nfe 27308, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 094, Runtime 18.186800, Loss 2.124972, forward nfe 27604, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 095, Runtime 18.456743, Loss 2.455215, forward nfe 27900, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 096, Runtime 18.814411, Loss 2.424313, forward nfe 28196, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 097, Runtime 19.032701, Loss 2.394855, forward nfe 28492, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 098, Runtime 19.795532, Loss 2.417396, forward nfe 28788, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
Epoch: 099, Runtime 19.501368, Loss 2.341867, forward nfe 29084, backward nfe 0, Train: 0.1357, Val: 0.2912, Test: 0.2893, Best time: 18.2948
best val accuracy 0.291176 with test accuracy 0.289340 at epoch 32 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.05786802030456853
Entropy Threshold: 2 Test accuracy: 0.08527918781725888
Entropy Threshold: 1.6 Test accuracy: 0.07894736842105263
Entropy Threshold: 1.5 Test accuracy: 0.0967741935483871
Entropy Threshold: 1.4 Test accuracy: 0.1
Entropy Threshold: 1.3 Test accuracy: 0.08695652173913043
Entropy Threshold: 1.2 Test accuracy: 0.0
Entropy Threshold: 1.1 Test accuracy: 0.0
Entropy Threshold: 0.9 Test accuracy: 0.0
Entropy Threshold: 0.8 Test accuracy: 0.0
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: None
Entropy Threshold: 0.5 Test accuracy: None
Entropy Threshold: 0.4 Test accuracy: None
Entropy Threshold: 0.3 Test accuracy: None
Entropy Threshold: 0.2 Test accuracy: None
Entropy Threshold: 0.1 Test accuracy: None
