[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 8.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 32.806284, Loss 4.504721, forward nfe 76, backward nfe 0, Train: 0.1786, Val: 0.1522, Test: 0.1401, Best time: 22.0000
Epoch: 002, Runtime 63.994658, Loss 69.326042, forward nfe 372, backward nfe 0, Train: 0.1857, Val: 0.1699, Test: 0.1391, Best time: 18.2948
Epoch: 003, Runtime 21.637866, Loss 5.217162, forward nfe 668, backward nfe 0, Train: 0.1857, Val: 0.1699, Test: 0.1391, Best time: 18.2948
Epoch: 004, Runtime 22.476990, Loss 4.965367, forward nfe 964, backward nfe 0, Train: 0.1857, Val: 0.1699, Test: 0.1391, Best time: 18.2948
Epoch: 005, Runtime 23.194191, Loss 4.389148, forward nfe 1260, backward nfe 0, Train: 0.1429, Val: 0.1713, Test: 0.1797, Best time: 18.2948
Epoch: 006, Runtime 23.034248, Loss 4.251058, forward nfe 1556, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 007, Runtime 23.596811, Loss 4.038311, forward nfe 1852, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 008, Runtime 26.876569, Loss 3.744979, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 009, Runtime 27.622017, Loss 4.230055, forward nfe 2444, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 010, Runtime 28.896769, Loss 3.583835, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 011, Runtime 31.230302, Loss 3.477635, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 012, Runtime 32.328676, Loss 3.530145, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 013, Runtime 33.152372, Loss 3.542782, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 014, Runtime 33.545197, Loss 3.291974, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 015, Runtime 35.013745, Loss 3.326383, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 016, Runtime 34.605584, Loss 3.267711, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 017, Runtime 34.925822, Loss 3.309399, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 018, Runtime 35.368346, Loss 3.075109, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 019, Runtime 36.328089, Loss 3.133168, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 020, Runtime 36.633121, Loss 3.076942, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 021, Runtime 32.807487, Loss 3.243060, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 022, Runtime 24.867617, Loss 3.058806, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 023, Runtime 25.277925, Loss 2.959255, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 024, Runtime 26.797275, Loss 2.768427, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 025, Runtime 27.280652, Loss 2.886586, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 026, Runtime 27.870933, Loss 2.970180, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 027, Runtime 26.801960, Loss 3.152699, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 028, Runtime 26.853823, Loss 2.842533, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 029, Runtime 28.125734, Loss 3.106734, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 030, Runtime 28.658974, Loss 3.077002, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 031, Runtime 29.517488, Loss 2.709914, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 032, Runtime 30.014457, Loss 3.067839, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 033, Runtime 30.346993, Loss 2.646012, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 034, Runtime 29.935620, Loss 2.877500, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 035, Runtime 31.205493, Loss 2.949738, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 036, Runtime 31.455902, Loss 2.981573, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 037, Runtime 31.571649, Loss 2.953619, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 038, Runtime 31.834143, Loss 2.953863, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 039, Runtime 32.037987, Loss 2.821168, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 040, Runtime 31.183356, Loss 2.859561, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 041, Runtime 32.831270, Loss 2.906086, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 042, Runtime 29.766120, Loss 3.119475, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 043, Runtime 22.051517, Loss 2.942572, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 044, Runtime 22.083792, Loss 2.956203, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 045, Runtime 21.980068, Loss 3.051141, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 046, Runtime 21.768651, Loss 2.886503, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 047, Runtime 23.181931, Loss 2.919211, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 048, Runtime 24.034125, Loss 3.150996, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 049, Runtime 25.046641, Loss 2.943941, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 050, Runtime 25.524321, Loss 3.061754, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 051, Runtime 25.739953, Loss 3.018246, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 052, Runtime 26.193137, Loss 2.817766, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 053, Runtime 26.860177, Loss 2.779410, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 054, Runtime 27.281393, Loss 2.947559, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 055, Runtime 26.770612, Loss 3.404186, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 056, Runtime 27.569516, Loss 3.132022, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 057, Runtime 27.922615, Loss 2.786285, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 058, Runtime 28.297445, Loss 2.713857, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 059, Runtime 28.582865, Loss 2.857852, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 060, Runtime 28.716940, Loss 3.072230, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 061, Runtime 28.960139, Loss 2.749115, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 062, Runtime 29.556529, Loss 2.930848, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 063, Runtime 29.897014, Loss 2.775162, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 064, Runtime 30.026769, Loss 2.874924, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 065, Runtime 29.808103, Loss 2.593931, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 066, Runtime 30.053989, Loss 2.720802, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 067, Runtime 30.084726, Loss 2.866214, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 068, Runtime 30.367458, Loss 2.660841, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 069, Runtime 30.498300, Loss 2.910999, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 070, Runtime 30.135168, Loss 2.657042, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 071, Runtime 30.424688, Loss 2.824940, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 072, Runtime 30.258959, Loss 2.843139, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 073, Runtime 30.802665, Loss 2.813462, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 074, Runtime 31.152117, Loss 2.734120, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 075, Runtime 30.109073, Loss 2.739387, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 076, Runtime 30.158803, Loss 2.664982, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 077, Runtime 26.737004, Loss 2.957494, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 078, Runtime 19.729228, Loss 2.728573, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 079, Runtime 19.773134, Loss 2.623296, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 080, Runtime 20.260047, Loss 2.617918, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 081, Runtime 21.128078, Loss 2.677811, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 082, Runtime 22.150045, Loss 2.842460, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 083, Runtime 22.501918, Loss 2.822425, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 084, Runtime 23.036052, Loss 2.851406, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 085, Runtime 23.892261, Loss 2.722760, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 086, Runtime 24.350999, Loss 2.783227, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 087, Runtime 24.445081, Loss 2.657820, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 088, Runtime 24.874690, Loss 2.683014, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 089, Runtime 25.568290, Loss 3.010617, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 090, Runtime 26.309585, Loss 2.615429, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 091, Runtime 26.202610, Loss 2.651487, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 092, Runtime 27.002711, Loss 2.694104, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 093, Runtime 27.491356, Loss 2.889252, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 094, Runtime 28.173751, Loss 2.774456, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 095, Runtime 28.176892, Loss 2.683525, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 096, Runtime 28.545490, Loss 2.765077, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 097, Runtime 28.294425, Loss 2.654897, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 098, Runtime 28.697308, Loss 2.715157, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
Epoch: 099, Runtime 28.688506, Loss 2.820047, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.1816, Test: 0.1716, Best time: 18.2948
best val accuracy 0.181618 with test accuracy 0.171574 at epoch 6 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.166497461928934
Entropy Threshold: 2 Test accuracy: 0.18071065989847715
Entropy Threshold: 1.6 Test accuracy: 0.16274089935760172
Entropy Threshold: 1.5 Test accuracy: 0.17475728155339806
Entropy Threshold: 1.4 Test accuracy: 0.1490280777537797
Entropy Threshold: 1.3 Test accuracy: 0.1606425702811245
Entropy Threshold: 1.2 Test accuracy: 0.13043478260869565
Entropy Threshold: 1.1 Test accuracy: 0.1
Entropy Threshold: 0.9 Test accuracy: 0.06896551724137931
Entropy Threshold: 0.8 Test accuracy: 0.09090909090909091
Entropy Threshold: 0.7 Test accuracy: 0.0
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.0
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: None
