[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 0.01
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 7.585521, Loss 1.947455, forward nfe 76, backward nfe 0, Train: 0.6357, Val: 0.4801, Test: 0.4782, Best time: 3.0000
Epoch: 002, Runtime 7.455303, Loss 1.896351, forward nfe 372, backward nfe 0, Train: 0.7571, Val: 0.5882, Test: 0.5878, Best time: 4.0000
Epoch: 003, Runtime 7.534078, Loss 1.743156, forward nfe 668, backward nfe 0, Train: 0.8714, Val: 0.6566, Test: 0.6569, Best time: 4.0000
Epoch: 004, Runtime 7.363271, Loss 1.507687, forward nfe 964, backward nfe 0, Train: 0.8929, Val: 0.7228, Test: 0.7178, Best time: 11.0000
Epoch: 005, Runtime 7.599595, Loss 1.236408, forward nfe 1260, backward nfe 0, Train: 0.8786, Val: 0.7831, Test: 0.7695, Best time: 18.0000
Epoch: 006, Runtime 7.581365, Loss 0.965629, forward nfe 1556, backward nfe 0, Train: 0.8786, Val: 0.8206, Test: 0.8010, Best time: 47.0000
Epoch: 007, Runtime 7.651730, Loss 0.698138, forward nfe 1852, backward nfe 0, Train: 0.9214, Val: 0.8390, Test: 0.8122, Best time: 35.0000
Epoch: 008, Runtime 7.165375, Loss 0.477259, forward nfe 2148, backward nfe 0, Train: 0.9214, Val: 0.8390, Test: 0.8122, Best time: 18.2948
Epoch: 009, Runtime 7.395458, Loss 0.414289, forward nfe 2444, backward nfe 0, Train: 0.9214, Val: 0.8390, Test: 0.8122, Best time: 18.2948
Epoch: 010, Runtime 7.270590, Loss 0.306278, forward nfe 2740, backward nfe 0, Train: 0.9214, Val: 0.8390, Test: 0.8122, Best time: 18.2948
Epoch: 011, Runtime 7.718651, Loss 0.289309, forward nfe 3036, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 012, Runtime 7.251037, Loss 0.280006, forward nfe 3332, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 013, Runtime 7.330205, Loss 0.207932, forward nfe 3628, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 014, Runtime 7.451834, Loss 0.217434, forward nfe 3924, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 015, Runtime 7.529270, Loss 0.199196, forward nfe 4220, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 016, Runtime 7.621220, Loss 0.182931, forward nfe 4516, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 017, Runtime 7.711248, Loss 0.212560, forward nfe 4812, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 018, Runtime 7.637784, Loss 0.216055, forward nfe 5108, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 019, Runtime 7.616632, Loss 0.173565, forward nfe 5404, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 020, Runtime 7.659151, Loss 0.229189, forward nfe 5700, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 021, Runtime 7.649104, Loss 0.236585, forward nfe 5996, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 022, Runtime 7.508869, Loss 0.197045, forward nfe 6292, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 023, Runtime 7.271142, Loss 0.182666, forward nfe 6588, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 024, Runtime 7.415148, Loss 0.205879, forward nfe 6884, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 025, Runtime 7.447815, Loss 0.155588, forward nfe 7180, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 026, Runtime 7.561960, Loss 0.174012, forward nfe 7476, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 027, Runtime 7.626350, Loss 0.185961, forward nfe 7772, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 028, Runtime 7.697343, Loss 0.190111, forward nfe 8068, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 029, Runtime 7.619409, Loss 0.172584, forward nfe 8364, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 030, Runtime 7.752035, Loss 0.171689, forward nfe 8660, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 031, Runtime 7.630372, Loss 0.198023, forward nfe 8956, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 032, Runtime 7.726094, Loss 0.143993, forward nfe 9252, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 033, Runtime 7.771702, Loss 0.223918, forward nfe 9548, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 034, Runtime 7.290883, Loss 0.183919, forward nfe 9844, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 035, Runtime 7.359557, Loss 0.184311, forward nfe 10140, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 036, Runtime 7.258446, Loss 0.156718, forward nfe 10436, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 037, Runtime 7.417706, Loss 0.165068, forward nfe 10732, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 038, Runtime 7.456157, Loss 0.159239, forward nfe 11028, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 039, Runtime 7.462260, Loss 0.162415, forward nfe 11324, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 040, Runtime 7.570409, Loss 0.142046, forward nfe 11620, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 041, Runtime 7.672796, Loss 0.175981, forward nfe 11916, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 042, Runtime 7.617409, Loss 0.188434, forward nfe 12212, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 043, Runtime 7.640489, Loss 0.166839, forward nfe 12508, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 044, Runtime 7.627878, Loss 0.171075, forward nfe 12804, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 045, Runtime 7.629035, Loss 0.179329, forward nfe 13100, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 046, Runtime 7.329560, Loss 0.159021, forward nfe 13396, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 047, Runtime 7.282350, Loss 0.135960, forward nfe 13692, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 048, Runtime 7.365232, Loss 0.147824, forward nfe 13988, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 049, Runtime 7.372408, Loss 0.134179, forward nfe 14284, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 050, Runtime 7.395469, Loss 0.137177, forward nfe 14580, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 051, Runtime 7.518419, Loss 0.141537, forward nfe 14876, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 052, Runtime 7.451070, Loss 0.153080, forward nfe 15172, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 053, Runtime 7.491853, Loss 0.175593, forward nfe 15468, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 054, Runtime 7.627771, Loss 0.120836, forward nfe 15764, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 055, Runtime 7.613068, Loss 0.178724, forward nfe 16060, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 056, Runtime 7.649474, Loss 0.147224, forward nfe 16356, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 057, Runtime 7.694609, Loss 0.155256, forward nfe 16652, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 058, Runtime 7.419037, Loss 0.111867, forward nfe 16948, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 059, Runtime 7.353225, Loss 0.124781, forward nfe 17244, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 060, Runtime 7.388818, Loss 0.114802, forward nfe 17540, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 061, Runtime 7.422682, Loss 0.155145, forward nfe 17836, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 062, Runtime 7.448630, Loss 0.126598, forward nfe 18132, backward nfe 0, Train: 0.8929, Val: 0.8412, Test: 0.8122, Best time: 18.2948
Epoch: 063, Runtime 7.718949, Loss 0.133347, forward nfe 18428, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 064, Runtime 7.025858, Loss 0.145726, forward nfe 18724, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 065, Runtime 6.923253, Loss 0.133521, forward nfe 19020, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 066, Runtime 7.177638, Loss 0.094590, forward nfe 19316, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 067, Runtime 7.158393, Loss 0.114308, forward nfe 19612, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 068, Runtime 7.232093, Loss 0.128002, forward nfe 19908, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 069, Runtime 7.259942, Loss 0.127540, forward nfe 20204, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 070, Runtime 7.333421, Loss 0.106356, forward nfe 20500, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 071, Runtime 7.389227, Loss 0.102681, forward nfe 20796, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 072, Runtime 7.298084, Loss 0.112514, forward nfe 21092, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 073, Runtime 7.440649, Loss 0.091718, forward nfe 21388, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 074, Runtime 7.055134, Loss 0.105316, forward nfe 21684, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 075, Runtime 7.109316, Loss 0.100321, forward nfe 21980, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 076, Runtime 7.053027, Loss 0.117470, forward nfe 22276, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 077, Runtime 7.289333, Loss 0.128240, forward nfe 22572, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 078, Runtime 7.194796, Loss 0.126202, forward nfe 22868, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 079, Runtime 7.340089, Loss 0.108400, forward nfe 23164, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 080, Runtime 7.279067, Loss 0.092941, forward nfe 23460, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 081, Runtime 7.402032, Loss 0.119001, forward nfe 23756, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 082, Runtime 7.342008, Loss 0.099802, forward nfe 24052, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 083, Runtime 7.420282, Loss 0.087497, forward nfe 24348, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 084, Runtime 7.432112, Loss 0.091073, forward nfe 24644, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 085, Runtime 7.600660, Loss 0.108773, forward nfe 24940, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 086, Runtime 7.199305, Loss 0.117957, forward nfe 25236, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 087, Runtime 7.025734, Loss 0.131250, forward nfe 25532, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 088, Runtime 7.238242, Loss 0.127684, forward nfe 25828, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 089, Runtime 7.096684, Loss 0.122791, forward nfe 26124, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 090, Runtime 7.221236, Loss 0.086870, forward nfe 26420, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 091, Runtime 7.278373, Loss 0.128334, forward nfe 26716, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 092, Runtime 7.284254, Loss 0.077712, forward nfe 27012, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 093, Runtime 7.289141, Loss 0.121100, forward nfe 27308, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 094, Runtime 7.439586, Loss 0.094375, forward nfe 27604, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 095, Runtime 7.359471, Loss 0.068907, forward nfe 27900, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 096, Runtime 7.394787, Loss 0.121561, forward nfe 28196, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 097, Runtime 7.481905, Loss 0.068378, forward nfe 28492, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 098, Runtime 7.111627, Loss 0.086999, forward nfe 28788, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
Epoch: 099, Runtime 7.142656, Loss 0.121010, forward nfe 29084, backward nfe 0, Train: 0.9500, Val: 0.8434, Test: 0.8274, Best time: 18.2948
best val accuracy 0.843382 with test accuracy 0.827411 at epoch 63 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.8263959390862944
Entropy Threshold: 2 Test accuracy: 0.8304568527918782
Entropy Threshold: 1.6 Test accuracy: 0.8253807106598985
Entropy Threshold: 1.5 Test accuracy: 0.8307849133537207
Entropy Threshold: 1.4 Test accuracy: 0.8319672131147541
Entropy Threshold: 1.3 Test accuracy: 0.8326488706365504
Entropy Threshold: 1.2 Test accuracy: 0.8371134020618557
Entropy Threshold: 1.1 Test accuracy: 0.8407908428720083
Entropy Threshold: 0.9 Test accuracy: 0.8491978609625669
Entropy Threshold: 0.8 Test accuracy: 0.8558951965065502
Entropy Threshold: 0.7 Test accuracy: 0.8707865168539326
Entropy Threshold: 0.6 Test accuracy: 0.886150234741784
Entropy Threshold: 0.5 Test accuracy: 0.8946107784431138
Entropy Threshold: 0.4 Test accuracy: 0.9049382716049382
Entropy Threshold: 0.3 Test accuracy: 0.9134860050890585
Entropy Threshold: 0.2 Test accuracy: 0.9182305630026809
Entropy Threshold: 0.1 Test accuracy: 0.9379615952732644
