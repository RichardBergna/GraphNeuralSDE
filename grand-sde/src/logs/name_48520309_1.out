[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 9.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 41.583560, Loss 7.970038, forward nfe 76, backward nfe 0, Train: 0.1500, Val: 0.1537, Test: 0.1452, Best time: 47.0000
Epoch: 002, Runtime 67.800428, Loss 99.308929, forward nfe 372, backward nfe 0, Train: 0.1286, Val: 0.1544, Test: 0.1259, Best time: 23.0000
Epoch: 003, Runtime 25.394309, Loss 5.284852, forward nfe 668, backward nfe 0, Train: 0.1571, Val: 0.1559, Test: 0.1411, Best time: 23.0000
Epoch: 004, Runtime 25.899410, Loss 5.666759, forward nfe 964, backward nfe 0, Train: 0.1643, Val: 0.1699, Test: 0.1533, Best time: 21.0000
Epoch: 005, Runtime 25.921536, Loss 5.110393, forward nfe 1260, backward nfe 0, Train: 0.1643, Val: 0.1699, Test: 0.1533, Best time: 18.2948
Epoch: 006, Runtime 28.381432, Loss 5.014191, forward nfe 1556, backward nfe 0, Train: 0.1357, Val: 0.1772, Test: 0.1574, Best time: 18.0000
Epoch: 007, Runtime 27.586962, Loss 4.761456, forward nfe 1852, backward nfe 0, Train: 0.1357, Val: 0.1963, Test: 0.1736, Best time: 17.0000
Epoch: 008, Runtime 28.556675, Loss 4.721052, forward nfe 2148, backward nfe 0, Train: 0.1429, Val: 0.2221, Test: 0.2081, Best time: 16.0000
Epoch: 009, Runtime 29.144018, Loss 5.076734, forward nfe 2444, backward nfe 0, Train: 0.1571, Val: 0.2331, Test: 0.2213, Best time: 15.0000
Epoch: 010, Runtime 28.586210, Loss 4.705864, forward nfe 2740, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 011, Runtime 28.852102, Loss 4.706837, forward nfe 3036, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 012, Runtime 31.166722, Loss 4.464597, forward nfe 3332, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 013, Runtime 32.103856, Loss 4.209072, forward nfe 3628, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 014, Runtime 32.591252, Loss 3.820724, forward nfe 3924, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 015, Runtime 33.778529, Loss 3.644898, forward nfe 4220, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 016, Runtime 35.413743, Loss 3.760520, forward nfe 4516, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 017, Runtime 35.725965, Loss 3.608694, forward nfe 4812, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 018, Runtime 35.868435, Loss 4.029688, forward nfe 5108, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 019, Runtime 37.402289, Loss 3.833678, forward nfe 5404, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 020, Runtime 37.899001, Loss 3.445373, forward nfe 5700, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 021, Runtime 37.899651, Loss 3.629963, forward nfe 5996, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 022, Runtime 38.020622, Loss 3.453592, forward nfe 6292, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 023, Runtime 39.358374, Loss 3.423500, forward nfe 6588, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 024, Runtime 39.762674, Loss 3.561955, forward nfe 6884, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 025, Runtime 34.927185, Loss 3.826929, forward nfe 7180, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 026, Runtime 26.303896, Loss 3.367095, forward nfe 7476, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 027, Runtime 27.991215, Loss 3.355671, forward nfe 7772, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 028, Runtime 28.860664, Loss 3.654343, forward nfe 8068, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 029, Runtime 29.949984, Loss 3.644948, forward nfe 8364, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 030, Runtime 30.884133, Loss 3.534874, forward nfe 8660, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 031, Runtime 31.927860, Loss 3.353247, forward nfe 8956, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 032, Runtime 32.852540, Loss 3.266901, forward nfe 9252, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 033, Runtime 33.550231, Loss 3.426292, forward nfe 9548, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 034, Runtime 34.037880, Loss 3.475684, forward nfe 9844, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 035, Runtime 35.241295, Loss 3.223715, forward nfe 10140, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 036, Runtime 35.360972, Loss 2.998904, forward nfe 10436, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 037, Runtime 36.127105, Loss 2.938175, forward nfe 10732, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 038, Runtime 36.505823, Loss 3.247373, forward nfe 11028, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 039, Runtime 37.417438, Loss 3.037750, forward nfe 11324, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 040, Runtime 37.170701, Loss 3.053884, forward nfe 11620, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 041, Runtime 37.286391, Loss 3.003087, forward nfe 11916, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 042, Runtime 30.286424, Loss 2.953775, forward nfe 12212, backward nfe 0, Train: 0.1286, Val: 0.2382, Test: 0.2325, Best time: 18.2948
Epoch: 043, Runtime 24.926115, Loss 3.057749, forward nfe 12508, backward nfe 0, Train: 0.1357, Val: 0.2485, Test: 0.2173, Best time: 21.0000
Epoch: 044, Runtime 24.248048, Loss 3.079202, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.2551, Test: 0.2234, Best time: 21.0000
Epoch: 045, Runtime 24.239890, Loss 2.813239, forward nfe 13100, backward nfe 0, Train: 0.1643, Val: 0.2610, Test: 0.2315, Best time: 21.0000
Epoch: 046, Runtime 23.666141, Loss 3.265758, forward nfe 13396, backward nfe 0, Train: 0.1643, Val: 0.2662, Test: 0.2345, Best time: 21.0000
Epoch: 047, Runtime 23.996807, Loss 3.324698, forward nfe 13692, backward nfe 0, Train: 0.1929, Val: 0.2706, Test: 0.2609, Best time: 18.0000
Epoch: 048, Runtime 23.458236, Loss 2.692513, forward nfe 13988, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.0000
Epoch: 049, Runtime 22.356579, Loss 2.942710, forward nfe 14284, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 050, Runtime 23.603261, Loss 3.021076, forward nfe 14580, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 051, Runtime 24.302367, Loss 2.879600, forward nfe 14876, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 052, Runtime 24.471648, Loss 2.760992, forward nfe 15172, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 053, Runtime 25.115106, Loss 2.958496, forward nfe 15468, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 054, Runtime 26.060436, Loss 3.000595, forward nfe 15764, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 055, Runtime 27.541693, Loss 2.981340, forward nfe 16060, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 056, Runtime 28.060478, Loss 3.010484, forward nfe 16356, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 057, Runtime 29.494280, Loss 3.028968, forward nfe 16652, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 058, Runtime 29.165534, Loss 3.009752, forward nfe 16948, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 059, Runtime 30.186429, Loss 3.085640, forward nfe 17244, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 060, Runtime 30.556970, Loss 3.040044, forward nfe 17540, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 061, Runtime 31.552831, Loss 2.923972, forward nfe 17836, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 062, Runtime 31.884200, Loss 2.904341, forward nfe 18132, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 063, Runtime 31.841270, Loss 2.760042, forward nfe 18428, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 064, Runtime 32.369301, Loss 2.791147, forward nfe 18724, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 065, Runtime 33.106916, Loss 2.759272, forward nfe 19020, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 066, Runtime 33.373649, Loss 3.283047, forward nfe 19316, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 067, Runtime 33.659925, Loss 2.786713, forward nfe 19612, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 068, Runtime 34.443575, Loss 3.063235, forward nfe 19908, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 069, Runtime 31.139263, Loss 2.903749, forward nfe 20204, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 070, Runtime 23.521107, Loss 3.156970, forward nfe 20500, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 071, Runtime 24.716517, Loss 2.742056, forward nfe 20796, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 072, Runtime 25.896008, Loss 2.818011, forward nfe 21092, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 073, Runtime 26.863662, Loss 2.677958, forward nfe 21388, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 074, Runtime 27.023841, Loss 2.832596, forward nfe 21684, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 075, Runtime 27.193512, Loss 3.004003, forward nfe 21980, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 076, Runtime 27.902670, Loss 2.928691, forward nfe 22276, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 077, Runtime 29.008002, Loss 2.803187, forward nfe 22572, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 078, Runtime 30.818832, Loss 2.993545, forward nfe 22868, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 079, Runtime 31.679082, Loss 3.190060, forward nfe 23164, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 080, Runtime 32.414131, Loss 2.863231, forward nfe 23460, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 081, Runtime 32.920253, Loss 2.882562, forward nfe 23756, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 082, Runtime 33.056334, Loss 2.850637, forward nfe 24052, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 083, Runtime 33.188389, Loss 2.682504, forward nfe 24348, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 084, Runtime 33.350069, Loss 2.990973, forward nfe 24644, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 085, Runtime 32.503339, Loss 2.728187, forward nfe 24940, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 086, Runtime 32.360004, Loss 2.788253, forward nfe 25236, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 087, Runtime 32.788751, Loss 2.829464, forward nfe 25532, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 088, Runtime 33.077415, Loss 2.712313, forward nfe 25828, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 089, Runtime 34.805254, Loss 2.896731, forward nfe 26124, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 090, Runtime 35.144322, Loss 2.935181, forward nfe 26420, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 091, Runtime 34.697951, Loss 2.992197, forward nfe 26716, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 092, Runtime 31.795027, Loss 3.094118, forward nfe 27012, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 093, Runtime 23.871392, Loss 2.819256, forward nfe 27308, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 094, Runtime 25.055851, Loss 2.878768, forward nfe 27604, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 095, Runtime 24.728632, Loss 2.939233, forward nfe 27900, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 096, Runtime 25.389518, Loss 2.662568, forward nfe 28196, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 097, Runtime 25.908335, Loss 2.952652, forward nfe 28492, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 098, Runtime 27.294966, Loss 2.824729, forward nfe 28788, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
Epoch: 099, Runtime 28.352176, Loss 2.837641, forward nfe 29084, backward nfe 0, Train: 0.1857, Val: 0.2721, Test: 0.2629, Best time: 18.2948
best val accuracy 0.272059 with test accuracy 0.262944 at epoch 48 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.11269035532994924
Entropy Threshold: 2 Test accuracy: 0.11269035532994924
Entropy Threshold: 1.6 Test accuracy: 0.10576923076923077
Entropy Threshold: 1.5 Test accuracy: 0.1296875
Entropy Threshold: 1.4 Test accuracy: 0.12873563218390804
Entropy Threshold: 1.3 Test accuracy: 0.1214574898785425
Entropy Threshold: 1.2 Test accuracy: 0.13821138211382114
Entropy Threshold: 1.1 Test accuracy: 0.19402985074626866
Entropy Threshold: 0.9 Test accuracy: 0.15151515151515152
Entropy Threshold: 0.8 Test accuracy: 0.18181818181818182
Entropy Threshold: 0.7 Test accuracy: 0.047619047619047616
Entropy Threshold: 0.6 Test accuracy: 0.0
Entropy Threshold: 0.5 Test accuracy: 0.08333333333333333
Entropy Threshold: 0.4 Test accuracy: 0.0
Entropy Threshold: 0.3 Test accuracy: 0.0
Entropy Threshold: 0.2 Test accuracy: 0.0
Entropy Threshold: 0.1 Test accuracy: 0.0
