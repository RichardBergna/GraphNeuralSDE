[KeOps] Warning : cuda was detected, but driver API could not be initialized. Switching to cpu only.
Folder already exists: results/cora
experiment: 0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
sigma 1.0
rtol 0.01
t1 6.0
Dataset size (num_nodes): 2485, Intended development set size (num_development): 1500
Dataset size (num_nodes): 2485, Actual development set size (num_development): 1500
rations: train 140, val 1360, test 985
GNSDEEarly
qy0_mean
torch.Size([1, 80])
qy0_logvar
torch.Size([1, 80])
m1.weight
torch.Size([80, 1433])
m1.bias
torch.Size([80])
m2.weight
torch.Size([7, 80])
m2.bias
torch.Size([7])
gnsde_drift_net.0.layer.weight
torch.Size([80, 81])
gnsde_drift_net.0.layer.bias
torch.Size([80])
gnsde_drift_net.1.layer.weight
torch.Size([80, 80])
gnsde_drift_net.1.layer.bias
torch.Size([80])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
Epoch: 001, Runtime 30.393677, Loss 3.647092, forward nfe 76, backward nfe 0, Train: 0.1429, Val: 0.1662, Test: 0.1645, Best time: 1.0000
Epoch: 002, Runtime 60.735490, Loss 78.164772, forward nfe 372, backward nfe 0, Train: 0.1429, Val: 0.1662, Test: 0.1645, Best time: 18.2948
Epoch: 003, Runtime 21.636604, Loss 3.122182, forward nfe 668, backward nfe 0, Train: 0.1429, Val: 0.1662, Test: 0.1645, Best time: 18.2948
Epoch: 004, Runtime 22.569957, Loss 3.564269, forward nfe 964, backward nfe 0, Train: 0.1429, Val: 0.1662, Test: 0.1645, Best time: 18.2948
Epoch: 005, Runtime 24.175637, Loss 4.048612, forward nfe 1260, backward nfe 0, Train: 0.1571, Val: 0.1743, Test: 0.1766, Best time: 1.0000
Epoch: 006, Runtime 23.645858, Loss 4.074465, forward nfe 1556, backward nfe 0, Train: 0.1929, Val: 0.2110, Test: 0.2234, Best time: 3.0000
Epoch: 007, Runtime 25.524601, Loss 4.796255, forward nfe 1852, backward nfe 0, Train: 0.1929, Val: 0.2110, Test: 0.2234, Best time: 18.2948
Epoch: 008, Runtime 28.121032, Loss 4.585088, forward nfe 2148, backward nfe 0, Train: 0.1929, Val: 0.2110, Test: 0.2234, Best time: 18.2948
Epoch: 009, Runtime 31.116246, Loss 4.210060, forward nfe 2444, backward nfe 0, Train: 0.1143, Val: 0.2647, Test: 0.2609, Best time: 14.0000
Epoch: 010, Runtime 29.123347, Loss 3.808471, forward nfe 2740, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 9.0000
Epoch: 011, Runtime 29.235703, Loss 4.024054, forward nfe 3036, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 012, Runtime 30.228123, Loss 3.700593, forward nfe 3332, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 013, Runtime 31.207250, Loss 3.862162, forward nfe 3628, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 014, Runtime 31.707201, Loss 3.737687, forward nfe 3924, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 015, Runtime 33.420625, Loss 3.739266, forward nfe 4220, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 016, Runtime 33.874160, Loss 3.647361, forward nfe 4516, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 017, Runtime 35.336003, Loss 3.915733, forward nfe 4812, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 018, Runtime 36.306909, Loss 3.694091, forward nfe 5108, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 019, Runtime 37.605279, Loss 3.466939, forward nfe 5404, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 020, Runtime 36.621004, Loss 3.123831, forward nfe 5700, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 021, Runtime 37.137524, Loss 3.345543, forward nfe 5996, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 022, Runtime 37.528481, Loss 2.973275, forward nfe 6292, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 023, Runtime 33.889004, Loss 3.308921, forward nfe 6588, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 024, Runtime 25.703246, Loss 2.949305, forward nfe 6884, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 025, Runtime 26.358255, Loss 3.042504, forward nfe 7180, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 026, Runtime 28.120214, Loss 3.123704, forward nfe 7476, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 027, Runtime 29.245586, Loss 2.683237, forward nfe 7772, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 028, Runtime 29.335327, Loss 2.843410, forward nfe 8068, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 029, Runtime 30.540404, Loss 3.066661, forward nfe 8364, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 030, Runtime 30.881437, Loss 2.801480, forward nfe 8660, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 031, Runtime 30.231706, Loss 2.787710, forward nfe 8956, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 032, Runtime 30.149042, Loss 2.800995, forward nfe 9252, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 033, Runtime 31.287727, Loss 2.743921, forward nfe 9548, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 034, Runtime 32.662655, Loss 2.641546, forward nfe 9844, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 035, Runtime 32.479444, Loss 2.925890, forward nfe 10140, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 036, Runtime 33.155911, Loss 2.585182, forward nfe 10436, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 037, Runtime 34.088341, Loss 2.735473, forward nfe 10732, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 038, Runtime 34.087287, Loss 2.668429, forward nfe 11028, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 039, Runtime 34.255242, Loss 2.743995, forward nfe 11324, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 040, Runtime 31.152975, Loss 2.839102, forward nfe 11620, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 041, Runtime 23.485592, Loss 2.584157, forward nfe 11916, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 042, Runtime 23.804768, Loss 2.607240, forward nfe 12212, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 043, Runtime 23.926490, Loss 2.581252, forward nfe 12508, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 044, Runtime 23.679946, Loss 2.700006, forward nfe 12804, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 045, Runtime 25.491125, Loss 2.630065, forward nfe 13100, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 046, Runtime 26.703648, Loss 2.737986, forward nfe 13396, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 047, Runtime 27.188001, Loss 2.605556, forward nfe 13692, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 048, Runtime 28.014385, Loss 2.593983, forward nfe 13988, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 049, Runtime 28.175507, Loss 2.710979, forward nfe 14284, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 050, Runtime 28.754621, Loss 2.670152, forward nfe 14580, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 051, Runtime 29.023016, Loss 2.680080, forward nfe 14876, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 052, Runtime 29.403880, Loss 2.604935, forward nfe 15172, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 053, Runtime 30.778210, Loss 2.577168, forward nfe 15468, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 054, Runtime 30.896605, Loss 2.856369, forward nfe 15764, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 055, Runtime 30.786325, Loss 2.712215, forward nfe 16060, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 056, Runtime 31.014587, Loss 2.638914, forward nfe 16356, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 057, Runtime 31.647309, Loss 2.718215, forward nfe 16652, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 058, Runtime 32.389188, Loss 2.789819, forward nfe 16948, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 059, Runtime 33.061908, Loss 2.589480, forward nfe 17244, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 060, Runtime 33.256185, Loss 2.498013, forward nfe 17540, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 061, Runtime 34.016758, Loss 2.661793, forward nfe 17836, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 062, Runtime 33.836917, Loss 2.565611, forward nfe 18132, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 063, Runtime 33.647100, Loss 2.423539, forward nfe 18428, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 064, Runtime 34.522238, Loss 2.653720, forward nfe 18724, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 065, Runtime 34.776980, Loss 2.489653, forward nfe 19020, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 066, Runtime 35.218048, Loss 2.624693, forward nfe 19316, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 067, Runtime 35.303002, Loss 2.626923, forward nfe 19612, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 068, Runtime 35.294213, Loss 2.530766, forward nfe 19908, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 069, Runtime 31.136458, Loss 2.497659, forward nfe 20204, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 070, Runtime 22.770648, Loss 2.563419, forward nfe 20500, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 071, Runtime 23.851129, Loss 2.695890, forward nfe 20796, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 072, Runtime 24.856985, Loss 2.476225, forward nfe 21092, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 073, Runtime 25.082364, Loss 2.284997, forward nfe 21388, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 074, Runtime 25.840235, Loss 2.544060, forward nfe 21684, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 075, Runtime 26.151822, Loss 2.606609, forward nfe 21980, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 076, Runtime 27.108081, Loss 2.464766, forward nfe 22276, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 077, Runtime 27.933837, Loss 2.420203, forward nfe 22572, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 078, Runtime 28.874115, Loss 2.710933, forward nfe 22868, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 079, Runtime 29.320613, Loss 2.562874, forward nfe 23164, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 080, Runtime 29.826647, Loss 2.554579, forward nfe 23460, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 081, Runtime 30.522889, Loss 2.551928, forward nfe 23756, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 082, Runtime 31.251430, Loss 2.805718, forward nfe 24052, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 083, Runtime 31.786824, Loss 2.662413, forward nfe 24348, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 084, Runtime 32.413961, Loss 2.550875, forward nfe 24644, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 085, Runtime 32.474786, Loss 2.645996, forward nfe 24940, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 086, Runtime 33.204367, Loss 2.598583, forward nfe 25236, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 087, Runtime 32.647105, Loss 2.598592, forward nfe 25532, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 088, Runtime 33.225322, Loss 2.554842, forward nfe 25828, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 089, Runtime 33.940360, Loss 2.512148, forward nfe 26124, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 090, Runtime 22.863662, Loss 2.610388, forward nfe 26420, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 091, Runtime 22.562072, Loss 2.608757, forward nfe 26716, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 092, Runtime 23.085863, Loss 2.394820, forward nfe 27012, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 093, Runtime 23.581824, Loss 2.477826, forward nfe 27308, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 094, Runtime 24.993919, Loss 2.749950, forward nfe 27604, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 095, Runtime 26.010919, Loss 2.443057, forward nfe 27900, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 096, Runtime 25.885733, Loss 2.527637, forward nfe 28196, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 097, Runtime 26.358115, Loss 2.498401, forward nfe 28492, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 098, Runtime 26.893260, Loss 2.613281, forward nfe 28788, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
Epoch: 099, Runtime 27.967367, Loss 2.508513, forward nfe 29084, backward nfe 0, Train: 0.1429, Val: 0.3096, Test: 0.2863, Best time: 18.2948
best val accuracy 0.309559 with test accuracy 0.286294 at epoch 10 and best time 18.294754
best_model.odeblock.t tensor([ 0.0000, 18.2948])
Entropy Threshold: inf Test accuracy: 0.1431472081218274
Entropy Threshold: 2 Test accuracy: 0.1431472081218274
Entropy Threshold: 1.6 Test accuracy: 0.1431472081218274
Entropy Threshold: 1.5 Test accuracy: 0.1431472081218274
Entropy Threshold: 1.4 Test accuracy: 0.1431472081218274
Entropy Threshold: 1.3 Test accuracy: 0.14343845371312308
Entropy Threshold: 1.2 Test accuracy: 0.14315569487983282
Entropy Threshold: 1.1 Test accuracy: 0.1431693989071038
Entropy Threshold: 0.9 Test accuracy: 0.15117891816920942
Entropy Threshold: 0.8 Test accuracy: 0.13879598662207357
Entropy Threshold: 0.7 Test accuracy: 0.1482213438735178
Entropy Threshold: 0.6 Test accuracy: 0.15555555555555556
Entropy Threshold: 0.5 Test accuracy: 0.14193548387096774
Entropy Threshold: 0.4 Test accuracy: 0.16363636363636364
Entropy Threshold: 0.3 Test accuracy: 0.16352201257861634
Entropy Threshold: 0.2 Test accuracy: 0.17543859649122806
Entropy Threshold: 0.1 Test accuracy: 0.23333333333333334
